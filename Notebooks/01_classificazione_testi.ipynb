{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificazione dei Testi nel Customer Care\n",
    "\n",
    "Questo notebook illustra come implementare un sistema di classificazione automatica delle richieste dei clienti utilizzando tecniche di Natural Language Processing (NLP). Ci concentreremo su un caso d'uso tipico del customer care: la categorizzazione automatica delle email o messaggi dei clienti in diverse categorie di problemi o richieste.\n",
    "\n",
    "## Obiettivi del Notebook\n",
    "\n",
    "- Creare un dataset di esempio di richieste di customer care\n",
    "- Preprocessare i testi per l'analisi NLP\n",
    "- Implementare e confrontare diversi approcci di classificazione\n",
    "- Valutare le performance dei modelli\n",
    "- Applicare il modello a nuovi dati\n",
    "\n",
    "## Caso d'uso: Classificazione delle Richieste dei Clienti\n",
    "\n",
    "In un contesto di customer care, le aziende ricevono quotidianamente numerose richieste attraverso vari canali (email, chat, social media). Classificare automaticamente queste richieste permette di:\n",
    "\n",
    "- Indirizzarle al reparto o all'operatore più appropriato\n",
    "- Prioritizzarle in base all'urgenza o alla tipologia\n",
    "- Monitorare i tipi di problemi più frequenti\n",
    "- Automatizzare risposte per richieste comuni\n",
    "\n",
    "In questo notebook, creeremo un classificatore che può categorizzare le richieste dei clienti in diverse classi come:\n",
    "- Problemi tecnici\n",
    "- Domande su fatturazione\n",
    "- Richieste di informazioni\n",
    "- Reclami\n",
    "- Richieste di assistenza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup e Importazione delle Librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importazione delle librerie necessarie\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Librerie per il preprocessing del testo\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Download the 'punkt_tab' resource\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Librerie per la feature extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Librerie per la modellazione\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Librerie per la valutazione\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Impostazioni di visualizzazione\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Download delle risorse NLTK necessarie\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creazione di un Dataset di Esempio\n",
    "\n",
    "Per questo notebook, creeremo un dataset sintetico di richieste di customer care. In un contesto reale, utilizzeresti dati storici delle comunicazioni con i clienti, opportunamente anonimizzati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione di un dataset di esempio\n",
    "data = {\n",
    "    'testo': [\n",
    "        # Problemi tecnici\n",
    "        \"Il mio router non si connette a internet da ieri sera. Ho già provato a riavviarlo ma non funziona.\",\n",
    "        \"L'app continua a bloccarsi ogni volta che provo ad accedere alla sezione account. È frustrante!\",\n",
    "        \"Non riesco ad accedere al mio account, dice che la password è errata ma sono sicuro sia corretta.\",\n",
    "        \"La connessione internet è molto lenta negli ultimi giorni, è un problema della vostra rete?\",\n",
    "        \"Il vostro sito web non carica correttamente le immagini dei prodotti, ho provato con diversi browser.\",\n",
    "        \"Ho problemi con la configurazione del nuovo modem, le istruzioni non sono chiare.\",\n",
    "        \"La TV on demand si blocca continuamente durante la riproduzione dei film.\",\n",
    "        \"Non riesco a configurare la mail sul mio nuovo smartphone, potete aiutarmi?\",\n",
    "        \"Il segnale della linea telefonica è disturbato, si sente un fruscio continuo durante le chiamate.\",\n",
    "        \"L'app non si aggiorna all'ultima versione, rimane bloccata al 50% del download.\",\n",
    "        \n",
    "        # Domande su fatturazione\n",
    "        \"Ho ricevuto una fattura con un importo superiore al solito, potete spiegarmi il motivo?\",\n",
    "        \"Non capisco alcune voci nella mia ultima bolletta, in particolare il costo aggiuntivo di 15 euro.\",\n",
    "        \"Vorrei passare alla fatturazione elettronica, come posso fare?\",\n",
    "        \"Non ho ancora ricevuto la fattura di marzo, quando verrà emessa?\",\n",
    "        \"Ho notato un addebito duplicato nell'estratto conto, vorrei un rimborso.\",\n",
    "        \"Quali sono le modalità di pagamento accettate per le fatture mensili?\",\n",
    "        \"Vorrei modificare l'indirizzo di fatturazione, ho recentemente cambiato casa.\",\n",
    "        \"C'è un errore nel mio codice fiscale sulla fattura, come posso correggerlo?\",\n",
    "        \"Posso rateizzare il pagamento della mia ultima bolletta? È più alta del previsto.\",\n",
    "        \"Non ho ricevuto la conferma del pagamento dell'ultima fattura, potete verificare?\",\n",
    "        \n",
    "        # Richieste di informazioni\n",
    "        \"Vorrei sapere quali sono le offerte attualmente disponibili per la fibra ottica.\",\n",
    "        \"Quali sono gli orari di apertura del vostro negozio in centro città?\",\n",
    "        \"Sto valutando di cambiare operatore, potete dirmi quali vantaggi offrite rispetto ai concorrenti?\",\n",
    "        \"Il vostro servizio è disponibile anche nella mia zona? Abito a Monza.\",\n",
    "        \"Vorrei informazioni sul nuovo smartphone appena uscito, lo avete disponibile?\",\n",
    "        \"Quali documenti servono per attivare un nuovo contratto a nome di un'azienda?\",\n",
    "        \"Avete un servizio di assistenza tecnica a domicilio? Quali sono i costi?\",\n",
    "        \"Quanto tempo richiede mediamente l'attivazione di una nuova linea fissa?\",\n",
    "        \"Vorrei sapere se è possibile mantenere il mio numero attuale cambiando piano tariffario.\",\n",
    "        \"Quali sono le condizioni di recesso anticipato dal contratto?\",\n",
    "        \n",
    "        # Reclami\n",
    "        \"Sono molto insoddisfatto del servizio clienti, ho atteso in linea per oltre 40 minuti!\",\n",
    "        \"È la terza volta questo mese che la connessione si interrompe, è inaccettabile per un servizio premium.\",\n",
    "        \"Ho pagato per un servizio che non funziona correttamente, voglio un rimborso immediato.\",\n",
    "        \"Il tecnico non si è presentato all'appuntamento e nessuno mi ha avvisato, ho perso mezza giornata di lavoro.\",\n",
    "        \"La qualità del servizio è peggiorata drasticamente negli ultimi mesi, sto valutando di cambiare operatore.\",\n",
    "        \"Nonostante le numerose segnalazioni, il problema persiste. Questa è l'ultima possibilità prima di rivolgermi alle associazioni consumatori.\",\n",
    "        \"Sono stato trattato in modo scortese dall'operatore al telefono, pretendo delle scuse.\",\n",
    "        \"Mi avete addebitato costi non previsti dal contratto, è una pratica commerciale scorretta.\",\n",
    "        \"La pubblicità del vostro servizio è ingannevole, le prestazioni reali sono molto inferiori a quelle promesse.\",\n",
    "        \"Ho atteso tre settimane per l'installazione, ben oltre i 5 giorni lavorativi garantiti.\",\n",
    "        \n",
    "        # Richieste di assistenza\n",
    "        \"Come posso configurare la casella email sul mio nuovo iPhone?\",\n",
    "        \"Ho bisogno di aiuto per impostare il parental control sul decoder TV.\",\n",
    "        \"Non riesco a trovare come attivare il roaming sul mio telefono, potete guidarmi?\",\n",
    "        \"Vorrei assistenza per trasferire i contatti dal vecchio al nuovo telefono.\",\n",
    "        \"Come posso verificare il credito residuo della mia SIM?\",\n",
    "        \"Ho bisogno di assistenza per configurare la VPN aziendale sul mio laptop.\",\n",
    "        \"Potete aiutarmi a ripristinare la password del mio account online?\",\n",
    "        \"Come si imposta la segreteria telefonica sul nuovo sistema?\",\n",
    "        \"Ho bisogno di aiuto per collegare il mio smart TV alla rete Wi-Fi di casa.\",\n",
    "        \"Non so come attivare la funzione di risparmio dati sul mio piano mobile, potete spiegarmi?\"\n",
    "    ],\n",
    "    'categoria': [\n",
    "        # 10 problemi tecnici\n",
    "        'Problema tecnico', 'Problema tecnico', 'Problema tecnico', 'Problema tecnico', 'Problema tecnico',\n",
    "        'Problema tecnico', 'Problema tecnico', 'Problema tecnico', 'Problema tecnico', 'Problema tecnico',\n",
    "        \n",
    "        # 10 domande su fatturazione\n",
    "        'Fatturazione', 'Fatturazione', 'Fatturazione', 'Fatturazione', 'Fatturazione',\n",
    "        'Fatturazione', 'Fatturazione', 'Fatturazione', 'Fatturazione', 'Fatturazione',\n",
    "        \n",
    "        # 10 richieste di informazioni\n",
    "        'Informazioni', 'Informazioni', 'Informazioni', 'Informazioni', 'Informazioni',\n",
    "        'Informazioni', 'Informazioni', 'Informazioni', 'Informazioni', 'Informazioni',\n",
    "        \n",
    "        # 10 reclami\n",
    "        'Reclamo', 'Reclamo', 'Reclamo', 'Reclamo', 'Reclamo',\n",
    "        'Reclamo', 'Reclamo', 'Reclamo', 'Reclamo', 'Reclamo',\n",
    "        \n",
    "        # 10 richieste di assistenza\n",
    "        'Assistenza', 'Assistenza', 'Assistenza', 'Assistenza', 'Assistenza',\n",
    "        'Assistenza', 'Assistenza', 'Assistenza', 'Assistenza', 'Assistenza'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Creazione del DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Visualizzazione delle prime righe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esploriamo la distribuzione delle categorie\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(y='categoria', data=df, order=df['categoria'].value_counts().index)\n",
    "plt.title('Distribuzione delle Categorie')\n",
    "plt.xlabel('Numero di Richieste')\n",
    "plt.ylabel('Categoria')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing del Testo\n",
    "\n",
    "Prima di addestrare i modelli di classificazione, dobbiamo preprocessare i testi per renderli più adatti all'analisi. Il preprocessing tipicamente include:\n",
    "\n",
    "- Conversione in minuscolo\n",
    "- Rimozione della punteggiatura\n",
    "- Tokenizzazione (divisione del testo in parole)\n",
    "- Rimozione delle stopwords (parole comuni come \"e\", \"il\", \"la\" che non aggiungono significato)\n",
    "- Stemming o lemmatizzazione (riduzione delle parole alla loro forma base)\n",
    "\n",
    "Implementiamo una funzione di preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inizializzazione dello stemmer per l'italiano\n",
    "stemmer = SnowballStemmer('italian')\n",
    "stop_words = set(stopwords.words('italian'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Conversione in minuscolo\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Rimozione della punteggiatura\n",
    "    text = re.sub(f'[{string.punctuation}]', ' ', text)\n",
    "    \n",
    "    # Tokenizzazione\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Rimozione delle stopwords e stemming\n",
    "    processed_tokens = [stemmer.stem(token) for token in tokens if token not in stop_words and len(token) > 2]\n",
    "    \n",
    "    # Ricostruzione del testo\n",
    "    processed_text = ' '.join(processed_tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Applicazione del preprocessing ai testi\n",
    "df['testo_preprocessato'] = df['testo'].apply(preprocess_text)\n",
    "\n",
    "# Visualizzazione di un esempio prima e dopo il preprocessing\n",
    "esempio_idx = 0\n",
    "print(f\"Testo originale:\\n{df['testo'][esempio_idx]}\\n\")\n",
    "print(f\"Testo preprocessato:\\n{df['testo_preprocessato'][esempio_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Extraction\n",
    "\n",
    "Per addestrare modelli di machine learning su testi, dobbiamo convertire i testi in rappresentazioni numeriche. Due approcci comuni sono:\n",
    "\n",
    "1. **Bag of Words (BoW)**: Conta semplicemente quante volte ogni parola appare in un documento.\n",
    "2. **Term Frequency-Inverse Document Frequency (TF-IDF)**: Pesa le parole in base alla loro frequenza nel documento e alla loro rarità nel corpus.\n",
    "\n",
    "Implementiamo entrambi gli approcci e confrontiamoli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisione in training e test set\n",
    "X = df['testo_preprocessato']\n",
    "y = df['categoria']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Bag of Words\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_bow = count_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = count_vectorizer.transform(X_test)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Visualizzazione delle dimensioni delle feature\n",
    "print(f\"Dimensioni BoW: {X_train_bow.shape}\")\n",
    "print(f\"Dimensioni TF-IDF: {X_train_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Addestramento e Valutazione dei Modelli\n",
    "\n",
    "Ora addestreremo diversi modelli di classificazione e valuteremo le loro performance. Utilizzeremo:\n",
    "\n",
    "1. Naive Bayes\n",
    "2. Regressione Logistica\n",
    "3. Support Vector Machine (SVM)\n",
    "4. Random Forest\n",
    "\n",
    "Confronteremo le performance sia con BoW che con TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per addestrare e valutare un modello\n",
    "def train_and_evaluate(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    # Addestramento\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predizione\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Valutazione\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Modello: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    # Matrice di confusione\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=sorted(y.unique()), \n",
    "                yticklabels=sorted(y.unique()))\n",
    "    plt.title(f'Matrice di Confusione - {model_name}')\n",
    "    plt.ylabel('Valore Reale')\n",
    "    plt.xlabel('Valore Predetto')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return model, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelli da testare\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Regressione Logistica': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'SVM': LinearSVC(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Risultati per confronto\n",
    "results_bow = []\n",
    "results_tfidf = []\n",
    "\n",
    "# Addestramento e valutazione con BoW\n",
    "print(\"\\n=== Risultati con Bag of Words ===\\n\")\n",
    "for name, model in models.items():\n",
    "    _, accuracy = train_and_evaluate(model, X_train_bow, X_test_bow, y_train, y_test, f\"{name} (BoW)\")\n",
    "    results_bow.append((name, accuracy))\n",
    "\n",
    "# Addestramento e valutazione con TF-IDF\n",
    "print(\"\\n=== Risultati con TF-IDF ===\\n\")\n",
    "for name, model in models.items():\n",
    "    _, accuracy = train_and_evaluate(model, X_train_tfidf, X_test_tfidf, y_train, y_test, f\"{name} (TF-IDF)\")\n",
    "    results_tfidf.append((name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confronto dei risultati\n",
    "results_df = pd.DataFrame({\n",
    "    'Modello': [r[0] for r in results_bow],\n",
    "    'Accuracy (BoW)': [r[1] for r in results_bow],\n",
    "    'Accuracy (TF-IDF)': [r[1] for r in results_tfidf]\n",
    "})\n",
    "\n",
    "# Visualizzazione dei risultati\n",
    "plt.figure(figsize=(12, 6))\n",
    "results_df.set_index('Modello').plot(kind='bar')\n",
    "plt.title('Confronto delle Performance dei Modelli')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tabella dei risultati\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ottimizzazione del Modello Migliore\n",
    "\n",
    "Basandoci sui risultati precedenti, selezioniamo il modello con le migliori performance e ottimizziamo i suoi iperparametri utilizzando GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supponiamo che SVM con TF-IDF abbia ottenuto i migliori risultati\n",
    "# Ottimizziamo i suoi iperparametri\n",
    "\n",
    "# Definizione dei parametri da testare\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'dual': [True, False]\n",
    "}\n",
    "\n",
    "# Inizializzazione di GridSearchCV\n",
    "grid_search = GridSearchCV(LinearSVC(random_state=42), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Addestramento\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Migliori parametri\n",
    "print(f\"Migliori parametri: {grid_search.best_params_}\")\n",
    "print(f\"Miglior accuracy in cross-validation: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Valutazione sul test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy sul test set: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Matrice di confusione\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=sorted(y.unique()), \n",
    "            yticklabels=sorted(y.unique()))\n",
    "plt.title('Matrice di Confusione - Modello Ottimizzato')\n",
    "plt.ylabel('Valore Reale')\n",
    "plt.xlabel('Valore Predetto')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analisi delle Feature Importanti\n",
    "\n",
    "Analizziamo quali parole o termini sono più importanti per ciascuna categoria. Questo può fornire insights preziosi sul linguaggio utilizzato dai clienti per diverse tipologie di richieste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per visualizzare le parole più importanti per ogni categoria\n",
    "def plot_important_features(vectorizer, model, class_names, n_top_features=10):\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # Per SVM, i coefficienti rappresentano l'importanza delle feature\n",
    "    if hasattr(model, 'coef_'):\n",
    "        coefs = model.coef_\n",
    "    else:\n",
    "        # Per altri modelli, potremmo dover usare approcci diversi\n",
    "        print(\"Il modello non supporta l'estrazione diretta dell'importanza delle feature.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(15, 20))\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        # Otteniamo i coefficienti per questa classe\n",
    "        class_coefs = coefs[i]\n",
    "        \n",
    "        # Troviamo le feature più importanti (con i coefficienti più alti)\n",
    "        top_positive_indices = np.argsort(class_coefs)[-n_top_features:]\n",
    "        top_positive_features = [feature_names[j] for j in top_positive_indices]\n",
    "        top_positive_values = [class_coefs[j] for j in top_positive_indices]\n",
    "        \n",
    "        # Creiamo un subplot per questa classe\n",
    "        plt.subplot(len(class_names), 1, i+1)\n",
    "        plt.barh(range(n_top_features), top_positive_values[::-1])\n",
    "        plt.yticks(range(n_top_features), top_positive_features[::-1])\n",
    "        plt.title(f'Top {n_top_features} parole per la categoria \"{class_name}\"')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    plt.tight_layout(pad=3.0)\n",
    "    plt.show()\n",
    "\n",
    "# Visualizzazione delle parole più importanti\n",
    "plot_important_features(tfidf_vectorizer, best_model, sorted(y.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Applicazione del Modello a Nuovi Dati\n",
    "\n",
    "Ora che abbiamo un modello addestrato e ottimizzato, possiamo utilizzarlo per classificare nuove richieste dei clienti. Creiamo una funzione che prende in input un testo e restituisce la categoria prevista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per classificare nuove richieste\n",
    "def classify_request(text, model, vectorizer):\n",
    "    # Preprocessing del testo\n",
    "    processed_text = preprocess_text(text)\n",
    "    \n",
    "    # Trasformazione in feature\n",
    "    features = vectorizer.transform([processed_text])\n",
    "    \n",
    "    # Predizione\n",
    "    category = model.predict(features)[0]\n",
    "    \n",
    "    # Probabilità (se disponibili)\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        probabilities = model.predict_proba(features)[0]\n",
    "        confidence = probabilities.max()\n",
    "    else:\n",
    "        # Per modelli che non supportano predict_proba, come LinearSVC\n",
    "        # Possiamo usare decision_function come approssimazione\n",
    "        if hasattr(model, 'decision_function'):\n",
    "            decision_scores = model.decision_function(features)[0]\n",
    "            confidence = np.abs(decision_scores).max() / np.sum(np.abs(decision_scores))\n",
    "        else:\n",
    "            confidence = None\n",
    "    \n",
    "    return {\n",
    "        'categoria': category,\n",
    "        'confidenza': confidence\n",
    "    }\n",
    "\n",
    "# Testiamo la funzione con alcuni esempi\n",
    "esempi = [\n",
    "    \"Non riesco a configurare la mia email sul nuovo telefono, potete aiutarmi?\",\n",
    "    \"Ho ricevuto una fattura con importi non corretti, vorrei un chiarimento.\",\n",
    "    \"Sono molto deluso dal vostro servizio, continuo ad avere problemi di connessione.\",\n",
    "    \"Vorrei sapere se avete offerte speciali per i clienti esistenti.\",\n",
    "    \"Il tecnico doveva venire stamattina ma non si è presentato, è inaccettabile!\"\n",
    "]\n",
    "\n",
    "for esempio in esempi:\n",
    "    risultato = classify_request(esempio, best_model, tfidf_vectorizer)\n",
    "    print(f\"Testo: {esempio}\")\n",
    "    print(f\"Categoria prevista: {risultato['categoria']}\")\n",
    "    if risultato['confidenza'] is not None:\n",
    "        print(f\"Confidenza: {risultato['confidenza']:.4f}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Implementazione di un Sistema di Classificazione in Produzione\n",
    "\n",
    "In un ambiente di produzione, potremmo voler salvare il modello addestrato e il vectorizer per utilizzarli successivamente. Ecco come farlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Salvataggio del modello e del vectorizer\n",
    "joblib.dump(best_model, 'modello_classificazione.pkl')\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "# Per caricare il modello e il vectorizer in un'applicazione di produzione:\n",
    "# model = joblib.load('modello_classificazione.pkl')\n",
    "# vectorizer = joblib.load('tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusioni e Considerazioni Finali\n",
    "\n",
    "In questo notebook, abbiamo sviluppato un sistema di classificazione automatica delle richieste dei clienti utilizzando tecniche di NLP. Abbiamo:\n",
    "\n",
    "1. Creato un dataset di esempio di richieste di customer care\n",
    "2. Preprocessato i testi per l'analisi NLP\n",
    "3. Implementato e confrontato diversi approcci di classificazione (Naive Bayes, Regressione Logistica, SVM, Random Forest)\n",
    "4. Valutato le performance dei modelli utilizzando metriche come accuracy e classification report\n",
    "5. Ottimizzato il modello migliore utilizzando GridSearchCV\n",
    "6. Analizzato le feature più importanti per ciascuna categoria\n",
    "7. Creato una funzione per classificare nuove richieste\n",
    "8. Mostrato come salvare il modello per un'implementazione in produzione\n",
    "\n",
    "### Considerazioni per l'Implementazione Reale\n",
    "\n",
    "In un contesto aziendale reale, ci sono ulteriori considerazioni da tenere in mente:\n",
    "\n",
    "- **Qualità e Quantità dei Dati**: Un dataset più ampio e rappresentativo porterebbe a performance migliori. Idealmente, si dovrebbero utilizzare migliaia di esempi reali per ciascuna categoria.\n",
    "\n",
    "- **Evoluzione del Linguaggio**: Il linguaggio dei clienti evolve nel tempo, così come i prodotti e i servizi dell'azienda. È importante aggiornare periodicamente il modello con nuovi dati.\n",
    "\n",
    "- **Multilingualità**: Se l'azienda serve clienti in diverse lingue, potrebbe essere necessario sviluppare modelli specifici per ciascuna lingua o utilizzare approcci multilingue.\n",
    "\n",
    "- **Integrazione con i Sistemi Esistenti**: Il sistema di classificazione dovrebbe integrarsi con i sistemi CRM, ticketing o di gestione delle email esistenti.\n",
    "\n",
    "- **Supervisione Umana**: È consigliabile mantenere un certo grado di supervisione umana, specialmente per richieste classificate con bassa confidenza o per categorie particolarmente critiche.\n",
    "\n",
    "- **Feedback Loop**: Implementare un meccanismo per raccogliere feedback dagli operatori sulle classificazioni errate, utilizzando questi dati per migliorare continuamente il modello.\n",
    "\n",
    "- **Approcci Più Avanzati**: Per casi d'uso più complessi, si potrebbero considerare approcci più avanzati come l'utilizzo di modelli pre-addestrati (BERT, GPT) o tecniche di transfer learning.\n",
    "\n",
    "La classificazione automatica delle richieste dei clienti può portare a significativi miglioramenti nell'efficienza operativa e nella qualità del servizio, permettendo agli operatori di concentrarsi sugli aspetti più complessi e a valore aggiunto del customer care."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
