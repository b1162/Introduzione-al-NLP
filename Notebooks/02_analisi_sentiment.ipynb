{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi del Sentiment nel Customer Care\n",
    "\n",
    "Questo notebook illustra come implementare un sistema di analisi del sentiment per le comunicazioni dei clienti utilizzando tecniche di Natural Language Processing (NLP). Ci concentreremo su un caso d'uso tipico del customer care: l'identificazione automatica del tono emotivo nei messaggi dei clienti.\n",
    "\n",
    "## Obiettivi del Notebook\n",
    "\n",
    "- Creare un dataset di esempio di comunicazioni di customer care\n",
    "- Preprocessare i testi per l'analisi del sentiment\n",
    "- Implementare e confrontare diversi approcci di analisi del sentiment\n",
    "- Valutare le performance dei modelli\n",
    "- Applicare il modello a nuovi dati\n",
    "- Visualizzare e interpretare i risultati\n",
    "\n",
    "## Caso d'uso: Analisi del Sentiment nel Customer Care\n",
    "\n",
    "L'analisi del sentiment nel customer care permette di:\n",
    "\n",
    "- Identificare rapidamente clienti insoddisfatti che potrebbero richiedere attenzione immediata\n",
    "- Monitorare la soddisfazione generale dei clienti nel tempo\n",
    "- Valutare l'efficacia degli operatori nel migliorare il sentiment durante le interazioni\n",
    "- Identificare prodotti, servizi o processi che generano feedback negativi\n",
    "- Riconoscere e valorizzare feedback positivi\n",
    "\n",
    "In questo notebook, svilupperemo un sistema che può classificare le comunicazioni dei clienti in tre categorie di sentiment:\n",
    "- Positivo\n",
    "- Neutro\n",
    "- Negativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup e Importazione delle Librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importazione delle librerie necessarie\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Librerie per il preprocessing del testo\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Librerie per la feature extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Librerie per la modellazione\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Librerie per la valutazione\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Librerie per l'analisi del sentiment\n",
    "from textblob import TextBlob\n",
    "import nltk.sentiment.vader as vader\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Librerie per modelli avanzati\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Impostazioni di visualizzazione\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Download delle risorse NLTK necessarie\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creazione di un Dataset di Esempio\n",
    "\n",
    "Per questo notebook, creeremo un dataset sintetico di comunicazioni di customer care con sentiment etichettati. In un contesto reale, utilizzeresti dati storici delle comunicazioni con i clienti, opportunamente anonimizzati e etichettati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione di un dataset di esempio\n",
    "data = {\n",
    "    'testo': [\n",
    "        # Sentiment positivo\n",
    "        \"Grazie mille per la rapida risposta! Il problema è stato risolto perfettamente.\",\n",
    "        \"Sono molto soddisfatto del vostro servizio clienti, l'operatore è stato gentilissimo e competente.\",\n",
    "        \"Ottimo lavoro! Il tecnico ha risolto il problema in pochissimo tempo e con grande professionalità.\",\n",
    "        \"Volevo complimentarmi per l'efficienza del vostro servizio, non mi aspettavo una soluzione così rapida.\",\n",
    "        \"La nuova app è fantastica, molto più intuitiva e veloce della precedente. Complimenti!\",\n",
    "        \"Esperienza d'acquisto eccellente, dalla consulenza alla consegna tutto è stato impeccabile.\",\n",
    "        \"Il vostro operatore Mario è stato estremamente disponibile e paziente, merita un riconoscimento.\",\n",
    "        \"Finalmente un servizio clienti che funziona! Problema risolto al primo contatto, incredibile.\",\n",
    "        \"Sono rimasto piacevolmente sorpreso dalla qualità del prodotto, supera le mie aspettative.\",\n",
    "        \"La procedura di reso è stata semplicissima e il rimborso è arrivato in tempi record. Grazie!\",\n",
    "        \"Apprezzo molto la trasparenza e l'onestà con cui avete gestito il mio reclamo.\",\n",
    "        \"Il vostro servizio clienti è il migliore con cui abbia mai avuto a che fare, continuate così!\",\n",
    "        \"Grazie per aver risolto il problema anche se era fuori garanzia, avete guadagnato un cliente fedele.\",\n",
    "        \"La qualità del supporto tecnico è eccezionale, l'operatore ha risolto un problema che mi affliggeva da mesi.\",\n",
    "        \"Sono felicissimo della nuova offerta, il rapporto qualità-prezzo è imbattibile.\",\n",
    "        \n",
    "        # Sentiment neutro\n",
    "        \"Vorrei informazioni sul processo di attivazione del nuovo servizio.\",\n",
    "        \"Ho ricevuto la fattura del mese di marzo, potete confermare la data di scadenza?\",\n",
    "        \"Come posso modificare l'indirizzo di spedizione per il mio prossimo ordine?\",\n",
    "        \"Quali documenti sono necessari per completare la registrazione?\",\n",
    "        \"Ho bisogno di assistenza per configurare il nuovo dispositivo.\",\n",
    "        \"Vorrei sapere se è possibile rateizzare il pagamento dell'ultimo acquisto.\",\n",
    "        \"Quali sono gli orari di apertura del centro assistenza di Milano?\",\n",
    "        \"Ho una domanda riguardo le specifiche tecniche del prodotto XYZ.\",\n",
    "        \"Sto valutando l'acquisto del vostro servizio, quali sono le differenze tra i vari piani?\",\n",
    "        \"Ho notato che il mio abbonamento scade il prossimo mese, quali sono le opzioni di rinnovo?\",\n",
    "        \"Potete fornirmi il tracking number della mia spedizione?\",\n",
    "        \"Vorrei verificare lo stato del mio ordine #12345.\",\n",
    "        \"È possibile parlare con un operatore per una consulenza sul prodotto?\",\n",
    "        \"Quali sono i tempi di consegna previsti per la mia zona?\",\n",
    "        \"Ho bisogno di una copia della mia ultima fattura per la contabilità aziendale.\",\n",
    "        \n",
    "        # Sentiment negativo\n",
    "        \"Sono estremamente deluso dal vostro servizio, è la terza volta che segnalo lo stesso problema!\",\n",
    "        \"Il prodotto che ho ricevuto è difettoso e nessuno risponde alle mie email di reclamo.\",\n",
    "        \"È inaccettabile attendere due settimane per una risposta, pessimo servizio clienti!\",\n",
    "        \"Ho parlato con tre operatori diversi e ognuno mi ha dato informazioni contrastanti, è assurdo!\",\n",
    "        \"La qualità del prodotto è nettamente inferiore a quanto pubblicizzato, mi sento truffato.\",\n",
    "        \"Non funziona nulla come dovrebbe, sto valutando seriamente di cambiare fornitore.\",\n",
    "        \"Sono molto arrabbiato per come è stata gestita la mia pratica, pretendo un rimborso immediato.\",\n",
    "        \"Il vostro servizio clienti è il peggiore che abbia mai incontrato, completamente inutile.\",\n",
    "        \"È vergognoso far pagare così tanto per un servizio così scadente!\",\n",
    "        \"Ho atteso un tecnico per l'intera giornata e non si è presentato nessuno, senza nemmeno una chiamata.\",\n",
    "        \"Questa è l'ultima possibilità che vi do prima di rivolgermi alle associazioni consumatori.\",\n",
    "        \"Non comprerò mai più un vostro prodotto, esperienza terribile dall'inizio alla fine.\",\n",
    "        \"Il vostro operatore è stato scortese e poco professionale, pretendo delle scuse formali.\",\n",
    "        \"Dopo tre tentativi falliti di risolvere il problema, sono completamente frustrato e insoddisfatto.\",\n",
    "        \"La connessione continua a cadere nonostante le vostre rassicurazioni che il problema era stato risolto.\"\n",
    "    ],\n",
    "    'sentiment': [\n",
    "        # 15 positivi\n",
    "        'positivo', 'positivo', 'positivo', 'positivo', 'positivo',\n",
    "        'positivo', 'positivo', 'positivo', 'positivo', 'positivo',\n",
    "        'positivo', 'positivo', 'positivo', 'positivo', 'positivo',\n",
    "        \n",
    "        # 15 neutri\n",
    "        'neutro', 'neutro', 'neutro', 'neutro', 'neutro',\n",
    "        'neutro', 'neutro', 'neutro', 'neutro', 'neutro',\n",
    "        'neutro', 'neutro', 'neutro', 'neutro', 'neutro',\n",
    "        \n",
    "        # 15 negativi\n",
    "        'negativo', 'negativo', 'negativo', 'negativo', 'negativo',\n",
    "        'negativo', 'negativo', 'negativo', 'negativo', 'negativo',\n",
    "        'negativo', 'negativo', 'negativo', 'negativo', 'negativo'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Creazione del DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Visualizzazione delle prime righe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esploriamo la distribuzione dei sentiment\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(y='sentiment', data=df, order=df['sentiment'].value_counts().index)\n",
    "plt.title('Distribuzione dei Sentiment')\n",
    "plt.xlabel('Numero di Messaggi')\n",
    "plt.ylabel('Sentiment')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing del Testo\n",
    "\n",
    "Prima di procedere con l'analisi del sentiment, dobbiamo preprocessare i testi. Il preprocessing per l'analisi del sentiment può essere leggermente diverso rispetto ad altri compiti NLP, poiché elementi come la punteggiatura o certe stopwords possono essere indicativi del sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inizializzazione dello stemmer per l'italiano\n",
    "stemmer = SnowballStemmer('italian')\n",
    "stop_words = set(stopwords.words('italian'))\n",
    "\n",
    "# Rimuoviamo alcune stopwords che possono essere indicative del sentiment\n",
    "sentiment_stopwords = {'non', 'né', 'no', 'mai', 'poco', 'troppo', 'molto', 'più', 'meno'}\n",
    "filtered_stop_words = stop_words - sentiment_stopwords\n",
    "\n",
    "def preprocess_text(text, remove_stopwords=True, stemming=True):\n",
    "    # Conversione in minuscolo\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Rimozione della punteggiatura (manteniamo ! e ? che possono indicare sentiment)\n",
    "    text = re.sub(r'[#%&()\\*\\+/<=>@\\[\\\\\\]^_`{|}~]', ' ', text)\n",
    "    \n",
    "    # Tokenizzazione\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Rimozione delle stopwords (opzionale)\n",
    "    if remove_stopwords:\n",
    "        tokens = [token for token in tokens if token not in filtered_stop_words]\n",
    "    \n",
    "    # Stemming (opzionale)\n",
    "    if stemming:\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Ricostruzione del testo\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Applicazione del preprocessing ai testi\n",
    "df['testo_preprocessato'] = df['testo'].apply(lambda x: preprocess_text(x, remove_stopwords=True, stemming=True))\n",
    "\n",
    "# Visualizzazione di un esempio prima e dopo il preprocessing\n",
    "esempio_idx = 0\n",
    "print(f\"Testo originale:\\n{df['testo'][esempio_idx]}\\n\")\n",
    "print(f\"Testo preprocessato:\\n{df['testo_preprocessato'][esempio_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Approcci all'Analisi del Sentiment\n",
    "\n",
    "Esploreremo diversi approcci all'analisi del sentiment, dai più semplici ai più avanzati:\n",
    "\n",
    "1. **Approcci basati su lessico**: Utilizzano dizionari di parole con punteggi di sentiment predefiniti\n",
    "2. **Approcci basati su machine learning tradizionale**: Addestrano classificatori su dati etichettati\n",
    "3. **Approcci basati su deep learning**: Utilizzano modelli pre-addestrati come BERT\n",
    "\n",
    "### 4.1 Approcci basati su lessico\n",
    "\n",
    "Iniziamo con approcci basati su lessico, che sono relativamente semplici ma possono essere sorprendentemente efficaci in molti casi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per tradurre il testo in inglese (necessario per alcuni strumenti di sentiment analysis)\n",
    "from googletrans import Translator\n",
    "\n",
    "def translate_to_english(text):\n",
    "    translator = Translator()\n",
    "    try:\n",
    "        translation = translator.translate(text, src='it', dest='en')\n",
    "        return translation.text\n",
    "    except Exception as e:\n",
    "        print(f\"Errore nella traduzione: {e}\")\n",
    "        return text\n",
    "\n",
    "# Traduciamo un sottoinsieme di testi per testare gli strumenti in inglese\n",
    "# Nota: in un'applicazione reale, potresti voler utilizzare strumenti specifici per l'italiano\n",
    "sample_indices = [0, 15, 30]  # Un esempio per ogni categoria\n",
    "for idx in sample_indices:\n",
    "    print(f\"Originale ({df['sentiment'][idx]}): {df['testo'][idx]}\")\n",
    "    translated = translate_to_english(df['testo'][idx])\n",
    "    print(f\"Tradotto: {translated}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizziamo VADER per l'analisi del sentiment\n",
    "# VADER è specificamente progettato per i social media e funziona bene con testi informali\n",
    "# Nota: VADER è progettato per l'inglese, quindi utilizziamo i testi tradotti\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyze_sentiment_vader(text):\n",
    "    # Traduciamo il testo in inglese\n",
    "    english_text = translate_to_english(text)\n",
    "    \n",
    "    # Otteniamo i punteggi di sentiment\n",
    "    scores = sid.polarity_scores(english_text)\n",
    "    \n",
    "    # Determiniamo la categoria di sentiment\n",
    "    if scores['compound'] >= 0.05:\n",
    "        sentiment = 'positivo'\n",
    "    elif scores['compound'] <= -0.05:\n",
    "        sentiment = 'negativo'\n",
    "    else:\n",
    "        sentiment = 'neutro'\n",
    "    \n",
    "    return {\n",
    "        'sentiment': sentiment,\n",
    "        'compound': scores['compound'],\n",
    "        'pos': scores['pos'],\n",
    "        'neu': scores['neu'],\n",
    "        'neg': scores['neg']\n",
    "    }\n",
    "\n",
    "# Testiamo VADER su alcuni esempi\n",
    "for idx in sample_indices:\n",
    "    text = df['testo'][idx]\n",
    "    true_sentiment = df['sentiment'][idx]\n",
    "    result = analyze_sentiment_vader(text)\n",
    "    \n",
    "    print(f\"Testo: {text}\")\n",
    "    print(f\"Sentiment reale: {true_sentiment}\")\n",
    "    print(f\"Sentiment predetto: {result['sentiment']}\")\n",
    "    print(f\"Punteggi: Compound={result['compound']:.4f}, Pos={result['pos']:.4f}, Neu={result['neu']:.4f}, Neg={result['neg']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizziamo TextBlob per l'analisi del sentiment\n",
    "# TextBlob offre un'API semplice per compiti NLP comuni\n",
    "# Nota: TextBlob è progettato principalmente per l'inglese\n",
    "\n",
    "def analyze_sentiment_textblob(text):\n",
    "    # Traduciamo il testo in inglese\n",
    "    english_text = translate_to_english(text)\n",
    "    \n",
    "    # Creiamo un oggetto TextBlob\n",
    "    blob = TextBlob(english_text)\n",
    "    \n",
    "    # Otteniamo il punteggio di polarità (-1 a 1)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    \n",
    "    # Determiniamo la categoria di sentiment\n",
    "    if polarity > 0.1:\n",
    "        sentiment = 'positivo'\n",
    "    elif polarity < -0.1:\n",
    "        sentiment = 'negativo'\n",
    "    else:\n",
    "        sentiment = 'neutro'\n",
    "    \n",
    "    return {\n",
    "        'sentiment': sentiment,\n",
    "        'polarity': polarity,\n",
    "        'subjectivity': blob.sentiment.subjectivity\n",
    "    }\n",
    "\n",
    "# Testiamo TextBlob su alcuni esempi\n",
    "for idx in sample_indices:\n",
    "    text = df['testo'][idx]\n",
    "    true_sentiment = df['sentiment'][idx]\n",
    "    result = analyze_sentiment_textblob(text)\n",
    "    \n",
    "    print(f\"Testo: {text}\")\n",
    "    print(f\"Sentiment reale: {true_sentiment}\")\n",
    "    print(f\"Sentiment predetto: {result['sentiment']}\")\n",
    "    print(f\"Punteggi: Polarità={result['polarity']:.4f}, Soggettività={result['subjectivity']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Approcci basati su machine learning tradizionale\n",
    "\n",
    "Ora passiamo agli approcci basati su machine learning, che addestrano classificatori su dati etichettati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisione in training e test set\n",
    "X = df['testo_preprocessato']\n",
    "y = df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Visualizzazione delle dimensioni delle feature\n",
    "print(f\"Dimensioni TF-IDF: {X_train_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per addestrare e valutare un modello\n",
    "def train_and_evaluate(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    # Addestramento\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predizione\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Valutazione\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Modello: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    # Matrice di confusione\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=sorted(y.unique()), \n",
    "                yticklabels=sorted(y.unique()))\n",
    "    plt.title(f'Matrice di Confusione - {model_name}')\n",
    "    plt.ylabel('Valore Reale')\n",
    "    plt.xlabel('Valore Predetto')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return model, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelli da testare\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Regressione Logistica': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'SVM': LinearSVC(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Risultati per confronto\n",
    "results = []\n",
    "\n",
    "# Addestramento e valutazione\n",
    "for name, model in models.items():\n",
    "    _, accuracy = train_and_evaluate(model, X_train_tfidf, X_test_tfidf, y_train, y_test, name)\n",
    "    results.append((name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confronto dei risultati\n",
    "results_df = pd.DataFrame({\n",
    "    'Modello': [r[0] for r in results],\n",
    "    'Accuracy': [r[1] for r in results]\n",
    "})\n",
    "\n",
    "# Visualizzazione dei risultati\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Modello', y='Accuracy', data=results_df)\n",
    "plt.title('Confronto delle Performance dei Modelli')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tabella dei risultati\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Approcci basati su deep learning\n",
    "\n",
    "Infine, esploriamo approcci basati su deep learning, utilizzando modelli pre-addestrati come BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizziamo un modello pre-addestrato per l'analisi del sentiment\n",
    "# Nota: questo richiede una connessione internet per scaricare il modello\n",
    "\n",
    "# Inizializziamo il pipeline di sentiment analysis\n",
    "# Utilizziamo un modello multilingue che supporta l'italiano\n",
    "sentiment_analyzer = pipeline('sentiment-analysis', model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "def analyze_sentiment_bert(text):\n",
    "    # Il modello restituisce un punteggio da 1 (molto negativo) a 5 (molto positivo)\n",
    "    result = sentiment_analyzer(text)[0]\n",
    "    score = int(result['label'].split()[0])  # Estrae il numero dal label (es. \"5 stars\")\n",
    "    \n",
    "    # Mappiamo il punteggio alle nostre categorie\n",
    "    if score >= 4:\n",
    "        sentiment = 'positivo'\n",
    "    elif score <= 2:\n",
    "        sentiment = 'negativo'\n",
    "    else:\n",
    "        sentiment = 'neutro'\n",
    "    \n",
    "    return {\n",
    "        'sentiment': sentiment,\n",
    "        'score': score,\n",
    "        'confidence': result['score']\n",
    "    }\n",
    "\n",
    "# Testiamo il modello BERT su alcuni esempi\n",
    "for idx in sample_indices:\n",
    "    text = df['testo'][idx]\n",
    "    true_sentiment = df['sentiment'][idx]\n",
    "    result = analyze_sentiment_bert(text)\n",
    "    \n",
    "    print(f\"Testo: {text}\")\n",
    "    print(f\"Sentiment reale: {true_sentiment}\")\n",
    "    print(f\"Sentiment predetto: {result['sentiment']}\")\n",
    "    print(f\"Punteggio: {result['score']}/5 (Confidenza: {result['confidence']:.4f})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutiamo il modello BERT sull'intero dataset\n",
    "def evaluate_bert_model(texts, true_labels):\n",
    "    predictions = []\n",
    "    for text in texts:\n",
    "        result = analyze_sentiment_bert(text)\n",
    "        predictions.append(result['sentiment'])\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    report = classification_report(true_labels, predictions)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    # Matrice di confusione\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=sorted(set(true_labels)), \n",
    "                yticklabels=sorted(set(true_labels)))\n",
    "    plt.title('Matrice di Confusione - BERT')\n",
    "    plt.ylabel('Valore Reale')\n",
    "    plt.xlabel('Valore Predetto')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return predictions, accuracy\n",
    "\n",
    "# Per risparmiare tempo, valutiamo solo sul test set\n",
    "bert_predictions, bert_accuracy = evaluate_bert_model(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiungiamo il risultato di BERT al confronto\n",
    "results_df = pd.concat([results_df, pd.DataFrame({'Modello': ['BERT'], 'Accuracy': [bert_accuracy]})])\n",
    "\n",
    "# Visualizzazione dei risultati aggiornati\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Modello', y='Accuracy', data=results_df)\n",
    "plt.title('Confronto delle Performance dei Modelli (incluso BERT)')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tabella dei risultati aggiornata\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analisi degli Errori\n",
    "\n",
    "Analizziamo alcuni esempi in cui il modello ha commesso errori, per comprendere meglio le sue limitazioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supponiamo di utilizzare il modello SVM come riferimento\n",
    "svm_model = LinearSVC(random_state=42)\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Identifichiamo gli errori\n",
    "errors = []\n",
    "for i, (true, pred) in enumerate(zip(y_test, y_pred_svm)):\n",
    "    if true != pred:\n",
    "        errors.append({\n",
    "            'testo': df['testo'].iloc[X_test.index[i]],\n",
    "            'sentiment_reale': true,\n",
    "            'sentiment_predetto': pred\n",
    "        })\n",
    "\n",
    "# Visualizziamo alcuni errori\n",
    "pd.DataFrame(errors).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Applicazione a Nuovi Dati\n",
    "\n",
    "Ora che abbiamo esplorato diversi approcci, creiamo una funzione che combina i risultati di più modelli per un'analisi del sentiment più robusta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per l'analisi del sentiment che combina più approcci\n",
    "def analyze_sentiment_ensemble(text):\n",
    "    results = {}\n",
    "    \n",
    "    # Approccio basato su lessico (VADER)\n",
    "    vader_result = analyze_sentiment_vader(text)\n",
    "    results['vader'] = vader_result['sentiment']\n",
    "    \n",
    "    # Approccio basato su lessico (TextBlob)\n",
    "    textblob_result = analyze_sentiment_textblob(text)\n",
    "    results['textblob'] = textblob_result['sentiment']\n",
    "    \n",
    "    # Approccio basato su machine learning (SVM)\n",
    "    # Preprocessing e trasformazione\n",
    "    processed_text = preprocess_text(text)\n",
    "    features = tfidf_vectorizer.transform([processed_text])\n",
    "    # Predizione\n",
    "    svm_prediction = svm_model.predict(features)[0]\n",
    "    results['svm'] = svm_prediction\n",
    "    \n",
    "    # Approccio basato su deep learning (BERT)\n",
    "    bert_result = analyze_sentiment_bert(text)\n",
    "    results['bert'] = bert_result['sentiment']\n",
    "    \n",
    "    # Voto di maggioranza\n",
    "    predictions = list(results.values())\n",
    "    from collections import Counter\n",
    "    counter = Counter(predictions)\n",
    "    majority_vote = counter.most_common(1)[0][0]\n",
    "    \n",
    "    # Dettagli aggiuntivi\n",
    "    details = {\n",
    "        'vader_compound': vader_result['compound'],\n",
    "        'textblob_polarity': textblob_result['polarity'],\n",
    "        'bert_score': bert_result['score'],\n",
    "        'individual_predictions': results\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'sentiment': majority_vote,\n",
    "        'details': details\n",
    "    }\n",
    "\n",
    "# Testiamo la funzione ensemble su alcuni esempi\n",
    "test_texts = [\n",
    "    \"Il vostro servizio clienti è eccellente, ho risolto il problema in pochi minuti!\",\n",
    "    \"Vorrei sapere come posso modificare i miei dati personali nel profilo.\",\n",
    "    \"Sono molto deluso dalla qualità del prodotto, non funziona come dovrebbe.\",\n",
    "    \"Ho provato a contattarvi più volte ma nessuno risponde, pessimo servizio!\",\n",
    "    \"La nuova interfaccia è molto più intuitiva, complimenti per il miglioramento.\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    result = analyze_sentiment_ensemble(text)\n",
    "    print(f\"Testo: {text}\")\n",
    "    print(f\"Sentiment (ensemble): {result['sentiment']}\")\n",
    "    print(f\"Predizioni individuali: {result['details']['individual_predictions']}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizzazione e Interpretazione dei Risultati\n",
    "\n",
    "Creiamo alcune visualizzazioni utili per interpretare i risultati dell'analisi del sentiment nel contesto del customer care."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simuliamo un dataset di comunicazioni dei clienti nel tempo\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Generiamo date per un periodo di 30 giorni\n",
    "start_date = datetime(2023, 1, 1)\n",
    "dates = [start_date + timedelta(days=i) for i in range(30)]\n",
    "\n",
    "# Generiamo sentiment casuali con una distribuzione realistica\n",
    "sentiments = []\n",
    "for _ in range(300):  # 300 comunicazioni in totale\n",
    "    r = random.random()\n",
    "    if r < 0.25:\n",
    "        sentiments.append('negativo')\n",
    "    elif r < 0.65:\n",
    "        sentiments.append('neutro')\n",
    "    else:\n",
    "        sentiments.append('positivo')\n",
    "\n",
    "# Assegniamo date casuali\n",
    "random_dates = [random.choice(dates) for _ in range(300)]\n",
    "\n",
    "# Creiamo il DataFrame\n",
    "time_data = pd.DataFrame({\n",
    "    'data': random_dates,\n",
    "    'sentiment': sentiments\n",
    "})\n",
    "\n",
    "# Ordiniamo per data\n",
    "time_data = time_data.sort_values('data')\n",
    "\n",
    "# Visualizzazione dell'andamento del sentiment nel tempo\n",
    "sentiment_counts = time_data.groupby(['data', 'sentiment']).size().unstack().fillna(0)\n",
    "\n",
    "# Calcoliamo il sentiment netto (positivo - negativo)\n",
    "sentiment_counts['netto'] = sentiment_counts['positivo'] - sentiment_counts['negativo']\n",
    "\n",
    "# Visualizziamo l'andamento\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Subplot 1: Conteggio per categoria\n",
    "plt.subplot(2, 1, 1)\n",
    "sentiment_counts[['positivo', 'neutro', 'negativo']].plot(kind='bar', stacked=True, ax=plt.gca())\n",
    "plt.title('Distribuzione del Sentiment nel Tempo')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Numero di Comunicazioni')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Sentiment')\n",
    "\n",
    "# Subplot 2: Sentiment netto\n",
    "plt.subplot(2, 1, 2)\n",
    "sentiment_counts['netto'].plot(kind='line', marker='o', ax=plt.gca())\n",
    "plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "plt.title('Sentiment Netto nel Tempo (Positivo - Negativo)')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Sentiment Netto')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simuliamo dati per diversi canali di comunicazione\n",
    "channels = ['Email', 'Chat', 'Telefono', 'Social Media', 'App']\n",
    "channel_data = []\n",
    "\n",
    "for channel in channels:\n",
    "    # Generiamo distribuzioni di sentiment diverse per ogni canale\n",
    "    if channel == 'Email':\n",
    "        pos, neu, neg = 0.3, 0.4, 0.3\n",
    "    elif channel == 'Chat':\n",
    "        pos, neu, neg = 0.4, 0.4, 0.2\n",
    "    elif channel == 'Telefono':\n",
    "        pos, neu, neg = 0.25, 0.35, 0.4\n",
    "    elif channel == 'Social Media':\n",
    "        pos, neu, neg = 0.2, 0.3, 0.5\n",
    "    else:  # App\n",
    "        pos, neu, neg = 0.35, 0.45, 0.2\n",
    "    \n",
    "    # Numero di comunicazioni per canale\n",
    "    n = random.randint(80, 120)\n",
    "    \n",
    "    for _ in range(n):\n",
    "        r = random.random()\n",
    "        if r < neg:\n",
    "            sentiment = 'negativo'\n",
    "        elif r < neg + neu:\n",
    "            sentiment = 'neutro'\n",
    "        else:\n",
    "            sentiment = 'positivo'\n",
    "        \n",
    "        channel_data.append({\n",
    "            'canale': channel,\n",
    "            'sentiment': sentiment\n",
    "        })\n",
    "\n",
    "# Creiamo il DataFrame\n",
    "channel_df = pd.DataFrame(channel_data)\n",
    "\n",
    "# Visualizziamo la distribuzione del sentiment per canale\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(x='canale', hue='sentiment', data=channel_df, palette={'positivo': 'green', 'neutro': 'gray', 'negativo': 'red'})\n",
    "plt.title('Distribuzione del Sentiment per Canale di Comunicazione')\n",
    "plt.xlabel('Canale')\n",
    "plt.ylabel('Numero di Comunicazioni')\n",
    "plt.legend(title='Sentiment')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcoliamo le percentuali di sentiment per canale\n",
    "channel_percentages = channel_df.groupby(['canale', 'sentiment']).size().unstack().fillna(0)\n",
    "channel_percentages = channel_percentages.div(channel_percentages.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Visualizziamo le percentuali\n",
    "plt.figure(figsize=(12, 8))\n",
    "channel_percentages.plot(kind='bar', stacked=True, ax=plt.gca(), \n",
    "                         color=['red', 'gray', 'green'])\n",
    "plt.title('Percentuale di Sentiment per Canale di Comunicazione')\n",
    "plt.xlabel('Canale')\n",
    "plt.ylabel('Percentuale')\n",
    "plt.legend(title='Sentiment')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Aggiungiamo le etichette con le percentuali\n",
    "for i, channel in enumerate(channel_percentages.index):\n",
    "    cumulative = 0\n",
    "    for sentiment in channel_percentages.columns:\n",
    "        value = channel_percentages.loc[channel, sentiment]\n",
    "        if value > 5:  # Mostra solo percentuali > 5% per leggibilità\n",
    "            plt.text(i, cumulative + value/2, f'{value:.1f}%', \n",
    "                     ha='center', va='center', color='white', fontweight='bold')\n",
    "        cumulative += value\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Implementazione in un Sistema di Customer Care\n",
    "\n",
    "Vediamo come l'analisi del sentiment potrebbe essere integrata in un sistema di customer care reale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simuliamo un sistema di prioritizzazione delle richieste basato sul sentiment\n",
    "\n",
    "# Classe per rappresentare una richiesta di customer care\n",
    "class CustomerRequest:\n",
    "    def __init__(self, id, text, channel, timestamp):\n",
    "        self.id = id\n",
    "        self.text = text\n",
    "        self.channel = channel\n",
    "        self.timestamp = timestamp\n",
    "        self.sentiment = None\n",
    "        self.sentiment_score = None\n",
    "        self.priority = None\n",
    "    \n",
    "    def analyze_sentiment(self):\n",
    "        # Utilizziamo la nostra funzione ensemble\n",
    "        result = analyze_sentiment_ensemble(self.text)\n",
    "        self.sentiment = result['sentiment']\n",
    "        \n",
    "        # Calcoliamo un punteggio numerico per il sentiment\n",
    "        if self.sentiment == 'positivo':\n",
    "            self.sentiment_score = 1\n",
    "        elif self.sentiment == 'neutro':\n",
    "            self.sentiment_score = 0\n",
    "        else:  # negativo\n",
    "            self.sentiment_score = -1\n",
    "    \n",
    "    def calculate_priority(self):\n",
    "        # Base: più vecchia è la richiesta, più alta è la priorità\n",
    "        age_hours = (datetime.now() - self.timestamp).total_seconds() / 3600\n",
    "        age_factor = min(age_hours / 24, 1)  # Normalizzato a 1 dopo 24 ore\n",
    "        \n",
    "        # Sentiment: richieste negative hanno priorità più alta\n",
    "        sentiment_factor = 0\n",
    "        if self.sentiment == 'negativo':\n",
    "            sentiment_factor = 0.5\n",
    "        \n",
    "        # Canale: alcuni canali potrebbero avere priorità diverse\n",
    "        channel_factor = 0\n",
    "        if self.channel == 'Telefono':\n",
    "            channel_factor = 0.3  # Priorità più alta per telefonate\n",
    "        elif self.channel == 'Social Media':\n",
    "            channel_factor = 0.2  # Priorità media per social (visibilità pubblica)\n",
    "        \n",
    "        # Calcolo della priorità complessiva (0-1, dove 1 è la massima priorità)\n",
    "        self.priority = min(age_factor + sentiment_factor + channel_factor, 1)\n",
    "        \n",
    "        return self.priority\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"ID: {self.id}, Canale: {self.channel}, Sentiment: {self.sentiment}, Priorità: {self.priority:.2f}\\nTesto: {self.text}\"\n",
    "\n",
    "# Simuliamo alcune richieste\n",
    "sample_requests = [\n",
    "    CustomerRequest(1, \"Non riesco ad accedere al mio account da giorni e nessuno risponde alle mie email!\", \"Email\", datetime.now() - timedelta(hours=20)),\n",
    "    CustomerRequest(2, \"Vorrei informazioni sui vostri piani tariffari per le aziende.\", \"Chat\", datetime.now() - timedelta(hours=2)),\n",
    "    CustomerRequest(3, \"Il vostro servizio è eccellente, grazie per la rapida risoluzione del mio problema.\", \"Email\", datetime.now() - timedelta(hours=5)),\n",
    "    CustomerRequest(4, \"Ho riscontrato un problema con l'ultimo aggiornamento dell'app, continua a bloccarsi.\", \"App\", datetime.now() - timedelta(hours=10)),\n",
    "    CustomerRequest(5, \"Sono estremamente deluso dal vostro servizio, è la terza volta che mi mandate un prodotto difettoso!\", \"Telefono\", datetime.now() - timedelta(hours=1))\n",
    "]\n",
    "\n",
    "# Analizziamo il sentiment e calcoliamo la priorità\n",
    "for request in sample_requests:\n",
    "    request.analyze_sentiment()\n",
    "    request.calculate_priority()\n",
    "\n",
    "# Ordiniamo le richieste per priorità\n",
    "prioritized_requests = sorted(sample_requests, key=lambda x: x.priority, reverse=True)\n",
    "\n",
    "# Visualizziamo le richieste prioritizzate\n",
    "print(\"Richieste ordinate per priorità:\\n\")\n",
    "for i, request in enumerate(prioritized_requests):\n",
    "    print(f\"{i+1}. {request}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizziamo la prioritizzazione\n",
    "request_data = [{\n",
    "    'id': r.id,\n",
    "    'sentiment': r.sentiment,\n",
    "    'channel': r.channel,\n",
    "    'age_hours': (datetime.now() - r.timestamp).total_seconds() / 3600,\n",
    "    'priority': r.priority,\n",
    "    'text': r.text[:50] + '...' if len(r.text) > 50 else r.text\n",
    "} for r in sample_requests]\n",
    "\n",
    "request_df = pd.DataFrame(request_data)\n",
    "\n",
    "# Visualizziamo i fattori che influenzano la priorità\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Creiamo un grafico a dispersione\n",
    "scatter = plt.scatter(request_df['age_hours'], request_df['priority'], \n",
    "                      c=request_df['sentiment'].map({'positivo': 'green', 'neutro': 'gray', 'negativo': 'red'}),\n",
    "                      s=100, alpha=0.7)\n",
    "\n",
    "# Aggiungiamo etichette per ogni punto\n",
    "for i, row in request_df.iterrows():\n",
    "    plt.annotate(f\"ID: {row['id']}\\n{row['channel']}\", \n",
    "                 (row['age_hours'], row['priority']),\n",
    "                 xytext=(10, 0), textcoords='offset points')\n",
    "\n",
    "plt.title('Prioritizzazione delle Richieste dei Clienti')\n",
    "plt.xlabel('Età della Richiesta (ore)')\n",
    "plt.ylabel('Priorità')\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "# Aggiungiamo una legenda per il sentiment\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Negativo'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='gray', markersize=10, label='Neutro'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='green', markersize=10, label='Positivo')\n",
    "]\n",
    "plt.legend(handles=legend_elements, title='Sentiment')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusioni e Considerazioni Finali\n",
    "\n",
    "In questo notebook, abbiamo esplorato l'analisi del sentiment nel contesto del customer care. Abbiamo:\n",
    "\n",
    "1. Creato un dataset di esempio di comunicazioni di customer care\n",
    "2. Preprocessato i testi per l'analisi del sentiment\n",
    "3. Implementato e confrontato diversi approcci di analisi del sentiment:\n",
    "   - Approcci basati su lessico (VADER, TextBlob)\n",
    "   - Approcci basati su machine learning tradizionale (Naive Bayes, SVM, ecc.)\n",
    "   - Approcci basati su deep learning (BERT)\n",
    "4. Creato un sistema ensemble che combina più approcci\n",
    "5. Visualizzato e interpretato i risultati dell'analisi del sentiment\n",
    "6. Simulato un sistema di prioritizzazione delle richieste basato sul sentiment\n",
    "\n",
    "### Considerazioni per l'Implementazione Reale\n",
    "\n",
    "In un contesto aziendale reale, ci sono ulteriori considerazioni da tenere in mente:\n",
    "\n",
    "- **Specificità del dominio**: I modelli generici di sentiment analysis potrebbero non catturare sfumature specifiche del dominio. Ad esempio, termini tecnici o gergo aziendale potrebbero essere interpretati erroneamente. È consigliabile fine-tuning su dati specifici del dominio.\n",
    "\n",
    "- **Multilingualità**: Se l'azienda serve clienti in diverse lingue, è importante utilizzare modelli che supportino tutte le lingue rilevanti o implementare soluzioni specifiche per lingua.\n",
    "\n",
    "- **Contesto più ampio**: Il sentiment di un singolo messaggio potrebbe non raccontare l'intera storia. Considerare la storia delle interazioni precedenti e il contesto più ampio può fornire una comprensione più accurata.\n",
    "\n",
    "- **Feedback loop**: Implementare un meccanismo per raccogliere feedback dagli operatori sulle analisi del sentiment errate, utilizzando questi dati per migliorare continuamente il modello.\n",
    "\n",
    "- **Etica e privacy**: Assicurarsi che l'analisi del sentiment sia utilizzata in modo etico e rispettoso della privacy dei clienti. Evitare di fare inferenze invasive o di utilizzare i risultati in modi che potrebbero danneggiare la fiducia dei clienti.\n",
    "\n",
    "- **Integrazione nei workflow**: L'analisi del sentiment dovrebbe essere integrata nei workflow esistenti in modo da supportare, non sostituire, il giudizio umano. Gli operatori dovrebbero essere formati su come interpretare e utilizzare efficacemente i risultati dell'analisi.\n",
    "\n",
    "L'analisi del sentiment nel customer care può fornire insights preziosi e migliorare significativamente l'esperienza del cliente, permettendo alle aziende di identificare rapidamente problemi emergenti, prioritizzare le richieste più urgenti e monitorare la soddisfazione generale nel tempo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
