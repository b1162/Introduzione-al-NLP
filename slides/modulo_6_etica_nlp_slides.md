---
marp: true
theme: default
paginate: true
---

# Modulo 6: Etica e ResponsabilitÃ  nell'NLP ğŸ¤–âš–ï¸

![bg right:40%](https://source.unsplash.com/random/800x600/?ethics,technology)

### Un viaggio tra opportunitÃ  e responsabilitÃ 

<!--
In questa presentazione esploreremo le implicazioni etiche del Natural Language Processing, un campo in rapida evoluzione che sta trasformando il modo in cui interagiamo con la tecnologia. 

L'etica nell'NLP non Ã¨ solo una questione teorica, ma ha implicazioni pratiche significative che influenzano la vita delle persone. Oggi vedremo come i sistemi NLP incorporano valori e prioritÃ , e come questi possono avere conseguenze profonde.

Possibile domanda per la platea: "Chi di voi ha interagito con un sistema di NLP oggi? Forse un assistente vocale, un chatbot, o un traduttore automatico?"
-->

---

## Cosa tratteremo oggi ğŸ“‹

- Introduzione all'etica nell'NLP
- Bias e fairness nei sistemi NLP
- Privacy e sicurezza dei dati
- Trasparenza e spiegabilitÃ 
- Impatto sociale e responsabilitÃ 
- Casi di studio etici nell'NLP
- Framework etici e linee guida
- Sviluppo responsabile di sistemi NLP

<!--
Questa Ã¨ la roadmap della nostra presentazione. Copriremo diversi aspetti dell'etica nell'NLP, partendo dai concetti fondamentali fino ad arrivare a casi di studio concreti e approcci pratici per lo sviluppo responsabile.

Ãˆ importante notare che questi temi sono interconnessi: ad esempio, i bias influenzano l'impatto sociale, mentre la trasparenza Ã¨ fondamentale per garantire l'accountability.

Domanda per stimolare la riflessione: "Quale di questi aspetti pensate sia il piÃ¹ critico per il futuro dell'NLP e perchÃ©?"
-->

---

## Introduzione all'etica nell'NLP ğŸ§­

- L'NLP media sempre piÃ¹ le nostre interazioni quotidiane ğŸŒ
- I sistemi NLP **non sono strumenti neutri** ğŸš©
- Incorporano valori, prioritÃ  e visioni del mondo ğŸ§ 
- Prendono decisioni che un tempo erano esclusivamente umane ğŸ¤”

> "Con grande potere derivano grandi responsabilitÃ "

<!--
L'etica nell'NLP Ã¨ un campo di crescente importanza che affronta le implicazioni morali, sociali e legali delle tecnologie che elaborano e generano linguaggio naturale.

Ãˆ fondamentale sottolineare che i sistemi NLP non sono strumenti neutri: incorporano valori, prioritÃ  e visioni del mondo che possono avere profonde conseguenze. Questi sistemi prendono decisioni che un tempo erano esclusivamente umane, spesso con minore trasparenza e accountability.

La citazione, sebbene famosa da Spider-Man, Ã¨ particolarmente rilevante qui: man mano che i sistemi NLP diventano piÃ¹ potenti, la nostra responsabilitÃ  nel garantire che siano sviluppati e utilizzati eticamente aumenta.

Domanda per la platea: "In quali ambiti della vostra vita quotidiana notate la presenza di sistemi NLP? Avete mai riflettuto sulle implicazioni etiche di queste tecnologie?"
-->
---

## Definizione di Algoretica

L'algoretica Ã¨ un campo emergente dell'etica che si occupa di studiare e valutare i problemi morali legati allo sviluppo, all'uso e all'impatto degli algoritmi, dei dati e delle pratiche correlate, specialmente nell'ambito dell'intelligenza artificiale (IA) e del Natural Language Processing (NLP). 

Questo disciplina si basa su valori condivisi e principi morali che guidano il comportamento nella societÃ , andando oltre le leggi per concentrarsi su ciÃ² che Ã¨ considerato "giusto" o "sbagliato" in contesti tecnologici
L'algoretica applicata al NLP richiede particolare attenzione, poichÃ© le tecnologie linguistiche influenzano molti aspetti della vita quotidiana e possono perpetuare bias o causare danni se non gestite correttamente. 

[The urgency of an algorethics](https://link.springer.com/article/10.1007/s44163-023-00056-6)

---

## Definizione di Algoretica

Di seguito alcuni principi chiave e domande etiche da considerare:
- **Contesto della raccolta dati**: Il contesto in cui i dati sono stati raccolti corrisponde al contesto del loro utilizzo? Ad esempio, utilizzare dati raccolti per scopi accademici in un'applicazione commerciale potrebbe violare aspettative etiche
- **Incentivi e bias nella raccolta dati**: I dati sono stati raccolti da persone o sistemi con quote o strutture di incentivazione che potrebbero introdurre distorsioni? 
- **RappresentativitÃ **: Chi Ã¨ sottorappresentato o assente nei dati utilizzati per addestrare modelli di NLP? Ãˆ possibile trovare dati aggiuntivi o utilizzare metodi statistici per rendere i dataset piÃ¹ inclusivi?
- **Consenso e scelte significative**: I dati sono stati raccolti in un ambiente in cui i soggetti avevano scelte significative e consapevoli riguardo alla loro partecipazione?


---

## PerchÃ© l'etica nell'NLP Ã¨ importante? ğŸ”

- Adozione in contesti **critici e sensibili** ğŸ¥ğŸ‘¨â€âš–ï¸
  - SanitÃ , giustizia, istruzione, finanza
- Impatto su **decisioni significative** che influenzano vite reali ğŸ§¬
- Potenziale di **amplificare disuguaglianze** esistenti ğŸ“ˆ
- NecessitÃ  di bilanciare **innovazione e protezione** ğŸ›¡ï¸

<!--
L'etica nell'NLP Ã¨ particolarmente importante perchÃ© questi sistemi vengono sempre piÃ¹ adottati in contesti critici dove le decisioni hanno un impatto significativo sulla vita delle persone.

Per esempio, nell'ambito sanitario, sistemi NLP possono analizzare cartelle cliniche e supportare diagnosi; nel sistema giudiziario, possono influenzare decisioni sulla libertÃ  condizionale; nel settore finanziario, possono determinare l'accesso al credito.

In tutti questi contesti, Ã¨ essenziale considerare non solo cosa questi sistemi possono fare, ma anche cosa dovrebbero fare e come dovrebbero farlo.

Spunto di riflessione: "Pensate a un sistema NLP che utilizzate regolarmente. Quali potrebbero essere le conseguenze etiche se questo sistema contenesse bias o non fosse trasparente nel suo funzionamento?"
-->

---

# Domanda ğŸ¤”

### Quali sistemi NLP utilizzate quotidianamente?
### Avete mai notato comportamenti problematici?

<!--
Questo Ã¨ un momento interattivo per coinvolgere la platea e raccogliere esperienze personali. Ãˆ importante ascoltare attentamente le risposte, poichÃ© potrebbero emergere esempi interessanti che possono essere ripresi durante la presentazione.

Esempi di sistemi NLP quotidiani includono:
- Assistenti vocali (Siri, Alexa, Google Assistant)
- Traduttori automatici (Google Translate)
- Correttori grammaticali (Grammarly)
- Chatbot di servizio clienti
- Sistemi di raccomandazione di contenuti

Comportamenti problematici potrebbero includere bias di genere nelle traduzioni, difficoltÃ  con accenti o dialetti regionali, o suggerimenti inappropriati.

Dopo alcune risposte, posso fare un breve riepilogo collegando le esperienze condivise ai temi che tratteremo nelle prossime slide.
-->

---

## Bias e fairness nei sistemi NLP âš–ï¸

### Origini dei bias:

- **Dati di addestramento** ğŸ“Š
  - Sottorappresentazione di gruppi
  - Rappresentazioni stereotipate
- **Scelte di progettazione** ğŸ› ï¸
  - Feature, definizione del problema, metriche
- **Contesto di utilizzo** ğŸŒ
  - DisparitÃ  di accesso e performance

<!--
I bias nei sistemi NLP rappresentano una delle sfide etiche piÃ¹ significative. Questi sistemi possono perpetuare o amplificare pregiudizi esistenti nella societÃ , con conseguenze potenzialmente dannose.

I bias possono emergere da diverse fonti:
1. Nei dati di addestramento: se i dati contengono pregiudizi storici o sociali, i modelli tenderanno a replicarli
2. Nelle scelte di progettazione: decisioni su quali caratteristiche includere, come formulare il problema, quali metriche ottimizzare
3. Nel contesto di utilizzo: anche con dati e progettazione impeccabili, i bias possono emergere quando il sistema viene utilizzato in contesti diversi

Un esempio concreto: modelli addestrati su corpora di notizie storiche potrebbero associare piÃ¹ fortemente "dottore" con "uomo" e "infermiere" con "donna", riflettendo e potenzialmente rinforzando stereotipi di genere.

Domanda per stimolare la discussione: "Quali gruppi pensate siano piÃ¹ frequentemente sottorappresentati nei dati di addestramento dei sistemi NLP?"
-->
---

## Manifestazioni di bias nei sistemi NLP ğŸ‘ï¸

- **Word embeddings biased** ğŸ“
  - "uomo : programmatore :: donna : casalinga"
- **Generazione di testo discriminatoria** ğŸ’¬
  - Descrizioni stereotipate di certi gruppi
- **Classificazione iniqua** ğŸ·ï¸
  - Performance degradata per lingue minoritarie

<!--
I bias possono manifestarsi in vari modi nei sistemi NLP:

1. Word embeddings biased: le rappresentazioni vettoriali di parole possono catturare e codificare bias sociali. Un esempio famoso Ã¨ l'analogia "uomo sta a programmatore come donna sta a casalinga", che riflette stereotipi di genere presenti nei dati.

2. Generazione di testo discriminatoria: i modelli generativi possono produrre contenuti che perpetuano stereotipi o linguaggio offensivo, come descrizioni stereotipate di certi gruppi o completamenti di testo che assumono caratteristiche basate su identitÃ .

3. Classificazione iniqua: i classificatori di testo possono performare in modo diseguale tra gruppi diversi, con tassi di errore piÃ¹ alti per certi gruppi o performance degradata per lingue o dialetti minoritari.

Questi esempi mostrano come i bias non siano solo un problema teorico, ma abbiano manifestazioni concrete che possono causare danni reali.

Spunto di riflessione: "Avete mai notato bias in sistemi di traduzione automatica quando traducono professioni da lingue gender-neutral a lingue con distinzioni di genere?"
-->

---

![bg fit](images/cursor-fail.png)

---

## Misurazione e mitigazione dei bias ğŸ“

### Metriche di fairness:
- Demographic parity, Equal opportunity, Equal accuracy

### Tecniche di mitigazione:
- **Interventi sui dati** ğŸ§¹
  - Bilanciamento, data augmentation
- **Interventi algoritmici** ğŸ§®
  - Debiasing di embeddings, adversarial learning
- **Interventi post-processing** ğŸ”„
  - Calibrazione, re-ranking, filtering

<!--
Per affrontare i bias, Ã¨ essenziale poterli misurare e valutare in modo sistematico. Diverse metriche catturano aspetti diversi di equitÃ :
- Demographic parity: output simili attraverso gruppi demografici
- Equal opportunity: tassi di falsi negativi simili tra gruppi
- Equal accuracy: accuratezza simile tra gruppi

Una volta identificati i bias, diverse tecniche possono essere utilizzate per mitigarli:

1. Interventi sui dati: bilanciamento del dataset, data augmentation per gruppi sottorappresentati
2. Interventi algoritmici: tecniche come debiasing di embeddings o adversarial learning
3. Interventi post-processing: aggiustamento delle soglie di decisione, modifica dell'ordine dei risultati

Ãˆ importante notare che non esiste una soluzione universale: la scelta delle metriche e delle tecniche di mitigazione dipende dal contesto specifico e dai valori che si vogliono promuovere.

Domanda per la platea: "Quale approccio alla mitigazione dei bias pensate sia piÃ¹ promettente nel lungo termine: intervenire sui dati, sugli algoritmi o sul post-processing? PerchÃ©?"
-->

---


![bg fit ](images/bias-genere.png)

<!--
Questa slide mostra un esempio concreto di bias di genere nei sistemi di traduzione automatica. L'immagine illustra come, traducendo frasi da lingue gender-neutral (come il turco o l'ungherese) a lingue con distinzioni di genere (come l'inglese), il sistema tende ad assegnare generi basati su stereotipi.

Per esempio, "O bir doktor" in turco (che significa letteralmente "Quella persona Ã¨ un dottore" senza specificare il genere) viene tradotto come "He is a doctor" (Lui Ã¨ un dottore), mentre "O bir hemÅŸire" (Quella persona Ã¨ un infermiere/a) viene tradotto come "She is a nurse" (Lei Ã¨ un'infermiera).

Questo esempio mostra chiaramente come i bias nei dati di addestramento si riflettano nelle traduzioni, perpetuando stereotipi di genere legati alle professioni.

Alcuni sistemi di traduzione hanno iniziato ad affrontare questo problema offrendo traduzioni di genere esplicite, mostrando entrambe le versioni quando il genere Ã¨ ambiguo nella lingua di origine.

Domanda per stimolare la discussione: "Quali altre professioni pensate siano soggette a bias di genere nelle traduzioni automatiche? Come potrebbe questo influenzare la percezione delle professioni nelle diverse culture?"
-->
---

## Privacy e sicurezza dei dati ğŸ”’

### Sfide uniche nell'NLP:

- **Informazioni personali nel testo** ğŸ“
  - PII, informazioni sensibili, comportamentali
- **Memorizzazione nei modelli** ğŸ§ 
  - Riproduzione verbatim, inferenza da memorizzazione
- **Inferenze non autorizzate** ğŸ”
  - Profilazione demografica e psicografica

<!--
La privacy e la sicurezza dei dati rappresentano considerazioni etiche fondamentali nell'NLP, particolarmente rilevanti in un'epoca di crescente raccolta e analisi di dati linguistici personali e sensibili.

I sistemi NLP presentano sfide uniche alla privacy a causa della natura dei dati testuali:

1. I testi spesso contengono informazioni personali identificabili (PII) e sensibili, come nomi, indirizzi, informazioni sulla salute, opinioni politiche, ecc.

2. I modelli NLP, specialmente quelli di grandi dimensioni, possono memorizzare informazioni dai dati di addestramento e potenzialmente riprodurle quando stimolati con prompt specifici.

3. I sistemi NLP possono inferire attributi sensibili non esplicitamente dichiarati, come etÃ , genere, background culturale, tratti di personalitÃ  o condizioni mediche.

Queste sfide richiedono approcci specifici per proteggere la privacy degli individui i cui dati vengono utilizzati per addestrare o interagire con sistemi NLP.

Spunto di riflessione: "Pensate a un messaggio che avete inviato recentemente. Quali informazioni personali conteneva che potrebbero essere problematiche se memorizzate da un modello linguistico?"
-->

---

## Tecniche per la privacy-preserving NLP ğŸ›¡ï¸

- **Anonimizzazione e de-identificazione** ğŸ­
  - NER per PII, redaction, pseudonimizzazione
- **Privacy differenziale** ğŸ“Š
  - Aggiunta di rumore controllato
- **Federated learning** ğŸ“±
  - Addestramento locale sui dispositivi

<!--
Diverse tecniche sono state sviluppate per proteggere la privacy nei sistemi NLP:

1. Anonimizzazione e de-identificazione: tecniche per rimuovere o mascherare informazioni identificabili, come Named Entity Recognition per identificare PII, redaction (rimozione completa), pseudonimizzazione (sostituzione con pseudonimi) o generalizzazione.

2. Privacy differenziale: tecniche matematiche che aggiungono rumore controllato durante l'addestramento o l'analisi, offrendo garanzie matematiche sulla protezione delle informazioni individuali.

3. Federated learning: approccio che mantiene i dati sui dispositivi degli utenti, addestrando i modelli localmente e condividendo solo gli aggiornamenti dei parametri, non i dati stessi.

Queste tecniche rappresentano un campo di ricerca attivo, con continui sviluppi per bilanciare utilitÃ  e privacy.

Domanda per la platea: "Quali di queste tecniche pensate sia piÃ¹ promettente per applicazioni consumer come assistenti vocali o tastiere predittive? E per applicazioni in ambito sanitario?"
-->

---

# Quiz per la platea! ğŸ¯

### Quale di queste NON Ã¨ una tecnica di privacy-preserving NLP?

A) Federated learning
B) Differential privacy
C) Gradient boosting
D) Pseudonimizzazione

<!--
Questo Ã¨ un momento interattivo per verificare l'attenzione e la comprensione della platea. La risposta corretta Ã¨ C) Gradient boosting, che Ã¨ una tecnica di machine learning per migliorare la performance dei modelli, non specificamente legata alla privacy.

Posso spiegare brevemente perchÃ© le altre sono tecniche di privacy-preserving:
- Federated learning: addestra i modelli sui dispositivi degli utenti senza condividere i dati grezzi
- Differential privacy: aggiunge rumore controllato per proteggere le informazioni individuali
- Pseudonimizzazione: sostituisce identificatori reali con pseudonimi per proteggere l'identitÃ 

Questo quiz aiuta a consolidare la comprensione delle tecniche di privacy-preserving NLP discusse nella slide precedente.

Dopo aver raccolto alcune risposte, posso rivelare la risposta corretta e fornire una breve spiegazione prima di passare alla slide successiva.
-->
---

## Sicurezza e attacchi ai sistemi NLP ğŸ›‘

### VulnerabilitÃ  specifiche:

- **Adversarial attacks** ğŸ¯
  - Text perturbations, prompt injection, jailbreaking
- **Data poisoning** â˜ ï¸
  - Inserimento di esempi malevoli nei dati
  - Backdoor attacks
- **Model stealing** ğŸ•µï¸
  - Estrazione di modelli proprietari

<!--
Oltre alle preoccupazioni sulla privacy, i sistemi NLP sono vulnerabili a vari attacchi di sicurezza:

1. Adversarial attacks: attacchi che mirano a ingannare o manipolare i sistemi NLP attraverso modifiche sottili all'input che preservano il significato ma ingannano il modello, manipolazione dell'input per indurre comportamenti non intenzionali (prompt injection), o tecniche per aggirare guardrails di sicurezza (jailbreaking).

2. Data poisoning: attacchi che mirano a compromettere l'addestramento inserendo esempi malevoli nei dati o creando trigger nascosti che causano comportamenti specifici (backdoor attacks).

3. Model stealing: tentativi di estrarre modelli proprietari attraverso query sistematiche, ricostruendo funzionalitÃ  simili senza accesso diretto al modello originale.

Questi attacchi sono particolarmente preoccupanti quando i modelli vengono utilizzati in contesti critici o quando vengono addestrati su dati raccolti da fonti pubbliche.

Spunto di riflessione: "Come possiamo bilanciare l'apertura e la trasparenza nella ricerca NLP con la necessitÃ  di proteggere i sistemi da potenziali abusi?"
-->

---

## Framework normativi e compliance ğŸ“œ

- **Regolamentazioni rilevanti** âš–ï¸
  - GDPR (EU), CCPA/CPRA (California), HIPAA (US)
- **Principi di privacy by design** ğŸ—ï¸
  - Minimizzazione dei dati
  - Limitazione dello scopo
  - Privacy come impostazione predefinita
  - Trasparenza

<!--
La privacy e la sicurezza dei dati nell'NLP sono sempre piÃ¹ regolamentate attraverso vari framework normativi:

1. Regolamentazioni rilevanti:
   - GDPR nell'Unione Europea, che impone requisiti specifici per il trattamento di dati personali
   - CCPA/CPRA in California, che stabilisce diritti dei consumatori sui loro dati personali
   - HIPAA negli Stati Uniti, che protegge le informazioni sanitarie
   - Varie regolamentazioni settoriali specifiche per finanza, istruzione, ecc.

2. Principi di privacy by design, un approccio che incorpora la privacy fin dalle prime fasi di sviluppo:
   - Minimizzazione dei dati: raccogliere solo i dati strettamente necessari
   - Limitazione dello scopo: utilizzare i dati solo per scopi dichiarati
   - Privacy come impostazione predefinita: massima protezione senza intervento dell'utente
   - Trasparenza: comunicazione chiara su raccolta e utilizzo dei dati

Questi framework non sono solo obblighi legali, ma offrono anche linee guida utili per lo sviluppo responsabile.

Domanda per la platea: "Quali sfide specifiche pensate che i sistemi NLP affrontino nel conformarsi a regolamentazioni come il GDPR? Come potrebbero queste sfide essere affrontate?"
-->

---

## Trasparenza e spiegabilitÃ  ğŸ”

### L'importanza della trasparenza:

- **Trasparenza sui dati** ğŸ“Š
  - Provenienza, caratteristiche, annotazione
- **Trasparenza algoritmica** ğŸ§®
  - Architettura, iperparametri, metriche
- **Trasparenza operativa** âš™ï¸
  - Scopo, processo decisionale, supervisione

<!--
La trasparenza e la spiegabilitÃ  sono principi etici fondamentali per i sistemi NLP, particolarmente cruciali quando questi sistemi influenzano decisioni significative.

La trasparenza nei sistemi NLP comprende diversi aspetti interconnessi:

1. Trasparenza sui dati: chiarezza riguardo ai dati utilizzati, inclusa la loro provenienza, caratteristiche, processi di annotazione e rappresentativitÃ .

2. Trasparenza algoritmica: apertura riguardo agli algoritmi e ai modelli utilizzati, inclusa l'architettura, gli iperparametri, le metriche di performance e le limitazioni note.

3. Trasparenza operativa: chiarezza su come il sistema viene utilizzato in pratica, incluso lo scopo previsto, il processo decisionale, il ruolo della supervisione umana e i processi di monitoraggio.

Questa trasparenza Ã¨ essenziale per costruire fiducia e permettere una valutazione critica dei sistemi NLP.

Spunto di riflessione: "Pensate che la trasparenza completa sia sempre desiderabile? Ci sono casi in cui potrebbe essere controproducente o rischiosa?"
-->
---

## Sfide alla spiegabilitÃ  nell'NLP ğŸ¤¯


- **ComplessitÃ  e opacitÃ ** ğŸ§©
  - Miliardi di parametri
  - Rappresentazioni distribuite
  - Comportamenti emergenti
- **Trade-off tra performance e spiegabilitÃ ** âš–ï¸
  - Modelli piÃ¹ potenti tendono ad essere piÃ¹ opachi

<!--
I moderni sistemi NLP, specialmente quelli basati su deep learning, presentano sfide uniche alla spiegabilitÃ :

1. ComplessitÃ  e opacitÃ :
   - Dimensioni enormi con milioni o miliardi di parametri che rendono impossibile l'ispezione manuale
   - Rappresentazioni distribuite dove le informazioni sono codificate in modo non localizzato
   - Relazioni non-lineari complesse difficili da caratterizzare
   - Comportamenti emergenti che non sono stati esplicitamente programmati

2. Trade-off tra performance e spiegabilitÃ :
   - Spesso esiste una tensione tra modelli piÃ¹ semplici e interpretabili (come la regressione logistica) e modelli piÃ¹ complessi con performance superiori (come i Transformer)
   - Questo trade-off Ã¨ particolarmente acuto nell'NLP, dove i modelli piÃ¹ potenti tendono ad essere i piÃ¹ opachi

Queste sfide rendono particolarmente difficile fornire spiegazioni comprensibili per le decisioni dei sistemi NLP avanzati.

Domanda per stimolare la discussione: "Come possiamo bilanciare il desiderio di modelli sempre piÃ¹ potenti con la necessitÃ  di sistemi comprensibili e spiegabili?"
-->

---

## Tecniche per l'interpretabilitÃ  nell'NLP ğŸ”¬

### Approcci principali:

- **InterpretabilitÃ  intrinseca** ğŸ§ 
  - Attention visualization
  - Sparse models
- **InterpretabilitÃ  post-hoc** ğŸ”
  - LIME, SHAP, Feature attribution
- **Spiegazioni in linguaggio naturale** ğŸ’¬
  - Rationale generation
  - Counterfactual explanations

<!--
Diverse tecniche sono state sviluppate per rendere i sistemi NLP piÃ¹ interpretabili:

1. InterpretabilitÃ  intrinseca: approcci che rendono i modelli intrinsecamente piÃ¹ interpretabili
   - Attention visualization: visualizzazione dei pesi di attenzione per comprendere su quali parti dell'input il modello si sta focalizzando
   - Sparse models: modelli che utilizzano solo un sottoinsieme di feature
   - Modelli a strati: architetture che separano chiaramente diverse funzionalitÃ 

2. InterpretabilitÃ  post-hoc: tecniche applicate dopo l'addestramento per spiegare le decisioni
   - LIME: approssima localmente il comportamento del modello con un modello interpretabile
   - SHAP: attribuisce importanza alle feature basandosi sulla teoria dei giochi
   - Feature attribution: identifica quali parole o frasi hanno maggiormente influenzato una predizione

3. Spiegazioni in linguaggio naturale: generazione di spiegazioni comprensibili agli umani
   - Rationale generation: produzione di giustificazioni testuali per le decisioni
   - Counterfactual explanations: spiegazioni che indicano come l'input dovrebbe cambiare per ottenere un risultato diverso

Queste tecniche offrono diverse prospettive sulla spiegabilitÃ , ciascuna con i propri punti di forza e limitazioni.

Spunto di riflessione: "Quale tipo di spiegazione pensate sia piÃ¹ utile per utenti non tecnici? E per sviluppatori o ricercatori?"
-->

---

# Momento di riflessione ğŸ’­

### Se un sistema NLP prende una decisione importante che vi riguarda...

### Quali informazioni vorreste avere sul suo funzionamento?

<!--
Questo Ã¨ un momento interattivo per far riflettere la platea sulle proprie aspettative riguardo alla trasparenza e alla spiegabilitÃ  dei sistemi NLP.

Posso guidare la discussione con alcuni esempi:
- Se un sistema NLP analizza il vostro CV e decide se siete idonei per un colloquio
- Se un assistente vocale interpreta le vostre richieste e prende decisioni su vostro conto
- Se un sistema di moderazione dei contenuti rimuove un vostro post sui social media

Le risposte potrebbero includere:
- Quali dati sono stati utilizzati per addestrare il sistema
- Come il sistema pesa diversi fattori nella decisione
- Quali alternative avrei potuto presentare per ottenere un risultato diverso
- Chi Ã¨ responsabile in ultima istanza della decisione
- Come posso contestare la decisione se ritengo sia errata

Questa riflessione aiuta a collegare i concetti astratti di trasparenza e spiegabilitÃ  alle esperienze concrete delle persone, rendendo il tema piÃ¹ tangibile e rilevante.
-->

---

## Impatto sociale e responsabilitÃ  ğŸŒ

### Impatto multidimensionale:

- **Accesso all'informazione e filter bubbles** ğŸ”
  - Algoritmi che mediano l'accesso all'informazione
- **Disinformazione e manipolazione** ğŸ“°
  - Generazione di fake news, deepfake testuali
- **Impatto sul lavoro e sull'economia** ğŸ’¼
  - Automazione di compiti cognitivi
- **Impatto su lingue e culture** ğŸ—£ï¸
  - DisparitÃ  linguistiche, omogeneizzazione culturale

<!--
I sistemi NLP hanno un impatto sociale profondo e multidimensionale che richiede un'attenta considerazione delle responsabilitÃ  etiche di sviluppatori, organizzazioni e societÃ .

Questo impatto si manifesta in vari modi:

1. Accesso all'informazione: i sistemi NLP mediano sempre piÃ¹ il nostro accesso all'informazione attraverso motori di ricerca, feed di social media e sistemi di raccomandazione, potenzialmente creando "filter bubbles" che limitano l'esposizione a prospettive diverse.

2. Disinformazione: le tecnologie NLP possono essere utilizzate per creare o amplificare disinformazione, generando fake news plausibili o imitando lo stile di specifiche persone.

3. Lavoro ed economia: l'automazione basata su NLP sta trasformando il panorama lavorativo, impattando professioni precedentemente considerate immuni all'automazione e potenzialmente ampliando disuguaglianze esistenti.

4. Lingue e culture: i sistemi NLP possono influenzare la diversitÃ  linguistica e culturale, con performance e disponibilitÃ  migliori per lingue dominanti e potenziale omogeneizzazione culturale.

Questi impatti sollevano questioni fondamentali di responsabilitÃ  e governance.

Domanda per la platea: "Quale di questi impatti vi preoccupa maggiormente? Quali opportunitÃ  positive vedete invece nell'adozione diffusa di sistemi NLP?"
-->

---

## ğŸ’¼ Impatto sul lavoro

- Automazione di mansioni ripetitive
- Nuove opportunitÃ  (traduzione, assistenza)
- Rischio sostituzione lavoro umano ğŸ¤–

ğŸ’¬ **Domanda:**  
Quali lavori potrebbero sparire? Quali nuovi lavori nasceranno?

<!-- 
NOTE PER LO SPEAKER:
Parla dei rischi e delle opportunitÃ . Fai esempi: traduttori automatici vs. revisori umani. Ricorda che lâ€™NLP puÃ² anche creare nuove professioni.
Domanda: â€œSiete piÃ¹ ottimisti o preoccupati per il futuro del lavoro?â€
-->

---

## ResponsabilitÃ  degli sviluppatori e delle organizzazioni ğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’¼

### Approcci proattivi:

- **Valutazione dell'impatto** ğŸ“Š
  - Impact assessment, stakeholder engagement
- **Design responsabile** ğŸ¨
  - Value-sensitive design, inclusive design
- **Governance e accountability** âš–ï¸
  - Chiara attribuzione di responsabilitÃ 
  - Meccanismi di oversight

<!--
Lo sviluppo e l'implementazione responsabile di sistemi NLP richiede un approccio proattivo da parte di sviluppatori e organizzazioni:

1. Valutazione dell'impatto:
   - Impact assessment: valutazione sistematica di potenziali impatti prima dell'implementazione
   - Stakeholder engagement: coinvolgimento di diversi stakeholder, specialmente comunitÃ  potenzialmente impattate
   - Monitoraggio continuo e feedback loops per adattarsi agli effetti reali

2. Design responsabile:
   - Value-sensitive design: incorporazione esplicita di valori etici nel processo di design
   - Inclusive design: considerazione di diversi utenti e contesti d'uso
   - Safeguards by design e graceful failure per minimizzare danni potenziali

3. Governance e accountability:
   - Chiara attribuzione di responsabilitÃ  per decisioni e impatti
   - Meccanismi di oversight interni ed esterni
   - Trasparenza operativa e rimedi accessibili

Questi approcci proattivi sono essenziali per garantire che i sistemi NLP siano sviluppati e utilizzati in modo responsabile.

Spunto di riflessione: "Come possiamo incentivare le organizzazioni ad adottare questi approcci proattivi? Quali meccanismi potrebbero essere piÃ¹ efficaci?"
-->

---

# Una domanda provocatoria ğŸ¤”

### Chi Ã¨ responsabile quando un sistema NLP causa un danno?

- Lo sviluppatore del modello?
- L'organizzazione che lo implementa?
- L'utente che lo utilizza?
- Il regolatore che non ha imposto limiti adeguati?

<!--
Questa Ã¨ una domanda provocatoria per stimolare una discussione sulla responsabilitÃ  condivisa nei sistemi NLP. Non esiste una risposta semplice, poichÃ© la responsabilitÃ  Ã¨ spesso distribuita tra diversi attori.

Posso guidare la discussione esplorando diversi scenari:
- Un sistema di traduzione automatica che produce traduzioni offensive
- Un assistente virtuale che fornisce consigli medici errati
- Un sistema di moderazione dei contenuti che censura ingiustamente certe prospettive

Per ciascuno di questi scenari, possiamo considerare il ruolo e la responsabilitÃ  di diversi attori:
- Gli sviluppatori che hanno creato il modello base
- Le organizzazioni che hanno implementato e personalizzato il sistema
- Gli utenti che utilizzano il sistema in contesti specifici
- I regolatori che stabiliscono (o non stabiliscono) framework normativi

Questa discussione aiuta a comprendere la complessitÃ  della responsabilitÃ  etica nell'NLP e l'importanza di un approccio di governance multi-stakeholder.

Dopo alcune risposte, posso sottolineare che in molti casi la responsabilitÃ  Ã¨ condivisa e che Ã¨ necessario un approccio collaborativo per affrontare le sfide etiche.
-->
---

## Casi di studio etici nell'NLP ğŸ“š

### Esempi emblematici:

- **Bias di genere nei sistemi di traduzione** ğŸŒ
  - Traduzioni stereotipate da lingue gender-neutral
- **Moderazione dei contenuti e libertÃ  di espressione** ğŸ—£ï¸
  - Impatto sproporzionato su comunitÃ  marginalizate
- **Privacy nei modelli linguistici di grandi dimensioni** ğŸ”’
  - Memorizzazione e potenziale rivelazione di dati personali

<!--
L'analisi di casi di studio concreti offre insights preziosi sulle sfide etiche nell'NLP e sugli approcci per affrontarle:

1. Bias di genere nei sistemi di traduzione automatica:
   - Quando traducono da lingue gender-neutral (come il finlandese o il turco) a lingue con distinzioni di genere, i sistemi tendono a perpetuare stereotipi
   - Soluzioni implementate includono traduzioni di genere esplicite, considerazione del contesto piÃ¹ ampio, e debiasing dei dati

2. Moderazione dei contenuti e libertÃ  di espressione:
   - I sistemi di moderazione automatica hanno mostrato tendenze a flaggare erroneamente contenuti in certi dialetti o varianti linguistiche
   - Approcci come moderazione a piÃ¹ livelli, diversificazione dei dati di addestramento, e meccanismi di appello sono stati sviluppati

3. Privacy nei modelli linguistici di grandi dimensioni:
   - I LLM possono memorizzare e potenzialmente rivelare informazioni personali presenti nei dati di addestramento
   - Tecniche come filtraggio pre-addestramento, privacy differenziale, e unlearning sono state proposte

Questi casi illustrano come le sfide etiche nell'NLP siano complesse e richiedano approcci nuanced che bilanciano diversi valori e considerazioni.

Domanda per la platea: "Conoscete altri esempi di dilemmi etici nell'NLP che avete incontrato personalmente o di cui avete sentito parlare?"
-->

---

## Framework etici e linee guida ğŸ“

### Principi etici fondamentali:

- **Beneficenza e non maleficenza** â¤ï¸
  - Massimizzare benefici, minimizzare danni
- **Autonomia e consenso informato** ğŸ¤
  - Rispetto delle scelte individuali
- **Giustizia ed equitÃ ** âš–ï¸
  - Distribuzione equa di benefici e rischi
- **Trasparenza e accountability** ğŸ”
  - Apertura su funzionamento e responsabilitÃ 

<!--
Per affrontare in modo sistematico le sfide etiche nell'NLP, sono stati sviluppati vari framework etici e linee guida che forniscono principi, processi e strumenti pratici.

Diversi principi etici fondamentali sono emersi come particolarmente rilevanti:

1. Beneficenza e non maleficenza: sviluppare sistemi NLP che portino benefici tangibili e evitino danni prevedibili, bilanciando attentamente rischi e benefici.

2. Autonomia e consenso informato: preservare la capacitÃ  degli individui di fare scelte informate, assicurando che comprendano come i loro dati vengono utilizzati.

3. Giustizia ed equitÃ : garantire una distribuzione equa di benefici e rischi, processi decisionali non discriminatori, e rappresentazione equa di diverse prospettive.

4. Trasparenza e accountability: apertura su funzionamento, capacitÃ  e limitazioni dei sistemi, capacitÃ  di fornire spiegazioni comprensibili, e chiara attribuzione di responsabilitÃ .

Questi principi forniscono una base etica per lo sviluppo e l'implementazione di sistemi NLP.

Spunto di riflessione: "Come possiamo bilanciare questi principi quando entrano in conflitto? Ad esempio, quando la massima trasparenza potrebbe compromettere la sicurezza?"
-->
---

## Framework etici esistenti ğŸ“š

- **Framework istituzionali** ğŸ›ï¸
  - [Principi AI dell'OECD](https://legalinstruments.oecd.org/api/download/?uri=/public/0a206222-278b-4958-9698-6aaa23a9591e.pdf)
  - [Ethics Guidelines for Trustworthy AI (EU)](https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai)
- **Framework industriali** ğŸ¢
  - [Microsoft Responsible AI Principles](https://www.microsoft.com/en-us/ai/principles-and-approach)
  - G[oogle AI Principles](https://ai.google/responsibility/principles/)

<!--
Numerose organizzazioni hanno sviluppato framework etici specifici per l'AI e l'NLP:

1. Framework istituzionali:
   - Principi AI dell'OECD: framework adottato da 42 paesi che enfatizza crescita inclusiva, valori centrati sull'umano, trasparenza, robustezza e accountability
   - Ethics Guidelines for Trustworthy AI (EU): framework europeo che identifica sette requisiti chiave per AI affidabile
   - UNESCO Recommendation on the Ethics of AI: primo strumento normativo globale sull'etica dell'AI

2. Framework industriali:
   - Microsoft Responsible AI Principles: framework che enfatizza fairness, reliability & safety, privacy & security, inclusiveness, transparency, accountability
   - Google AI Principles: linee guida che delineano applicazioni che Google non perseguirÃ  e principi per lo sviluppo responsabile
   - Partnership on AI: principi sviluppati da un consorzio di aziende tecnologiche, organizzazioni di ricerca e societÃ  civile

3. Framework accademici e di ricerca:
   - Montreal Declaration for Responsible AI: framework sviluppato attraverso un processo deliberativo che include principi di benessere, autonomia, privacy, solidarietÃ , democrazia, equitÃ  e sostenibilitÃ 
   - IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems: standard tecnici che incorporano considerazioni etiche

Questi framework offrono linee guida preziose, ma la loro implementazione pratica rimane una sfida.

Domanda per la platea: "Quali di questi framework conoscevate giÃ ? Pensate che siano sufficienti per garantire uno sviluppo etico dell'NLP?"
-->

---

## Implementazione pratica dei framework etici ğŸ› ï¸

### Strumenti e processi:

- **Strumenti di valutazione etica** ğŸ“‹
  - Ethical impact assessment, Ethics checklists
- **Processi di governance** ğŸ—ï¸
  - Ethics review boards, Ethics by design
- **Cultura organizzativa** ğŸ‘¥
  - Leadership commitment, Incentivi allineati
  - DiversitÃ  e inclusione

<!--
La traduzione di principi astratti in pratiche concrete richiede strumenti e processi specifici:

1. Strumenti di valutazione etica:
   - Ethical impact assessment: metodologia strutturata per valutare implicazioni etiche
   - Algorithmic impact assessment: framework per valutare impatti potenziali di sistemi algoritmici
   - Ethics checklists: liste di controllo pratiche per diverse fasi di sviluppo
   - Scenario planning: esplorazione di potenziali conseguenze attraverso scenari

2. Processi di governance:
   - Ethics review boards: comitati che valutano progetti dal punto di vista etico
   - Ethics by design: incorporazione di considerazioni etiche fin dalle prime fasi di sviluppo
   - Continuous monitoring: valutazione continua di impatti etici dopo il deployment
   - Stakeholder engagement: coinvolgimento di diversi stakeholder nel processo decisionale

3. Cultura organizzativa:
   - Leadership commitment: impegno visibile della leadership verso l'etica
   - Incentivi allineati: strutture di incentivi che premiano considerazioni etiche
   - DiversitÃ  e inclusione: team diversificati che portano prospettive diverse
   - Psychological safety: ambiente che incoraggia la segnalazione di preoccupazioni etiche

Questi strumenti e processi sono essenziali per tradurre principi etici in pratiche concrete.

Spunto di riflessione: "Quali ostacoli vedete nell'implementazione di questi strumenti e processi nelle organizzazioni? Come potrebbero essere superati?"
-->

---

## Sviluppo responsabile di sistemi NLP ğŸŒ±

### Ethics by design:

- **Fase di concezione e pianificazione** ğŸ§©
  - Valutazione della necessitÃ , definizione di scopo e limiti
- **Fase di raccolta e preparazione dei dati** ğŸ“Š
  - Sourcing etico, valutazione di rappresentativitÃ 
- **Fase di sviluppo del modello** ğŸ› ï¸
  - Scelte di architetture, monitoraggio durante l'addestramento
- **Fase di testing e valutazione** ğŸ”
  - Test multidimensionali, adversarial testing
- **Fase di deployment e monitoraggio** ğŸš€
  - Deployment graduale, monitoraggio continuo

<!--
Lo sviluppo responsabile di sistemi NLP richiede l'integrazione di considerazioni etiche in ogni fase del ciclo di vita:

1. Fase di concezione e pianificazione:
   - Valutazione della necessitÃ : determinare se un sistema NLP Ã¨ la soluzione appropriata
   - Definizione di scopo e limiti: chiarire esplicitamente cosa il sistema dovrebbe e non dovrebbe fare
   - Stakeholder mapping e ethical impact assessment iniziale

2. Fase di raccolta e preparazione dei dati:
   - Sourcing etico: ottenere dati in modo rispettoso di diritti e consenso
   - Valutazione di rappresentativitÃ : analizzare chi Ã¨ rappresentato e chi Ã¨ escluso
   - Documentazione dettagliata e preprocessing consapevole

3. Fase di sviluppo del modello:
   - Scelta di architetture appropriate che bilanciano performance e interpretabilitÃ 
   - Monitoraggio durante l'addestramento di metriche etiche
   - Valutazione disaggregata e documentazione del modello

4. Fase di testing e valutazione:
   - Test multidimensionali che valutano non solo accuratezza ma anche fairness, robustezza, privacy
   - Adversarial testing, red teaming e user testing diversificato

5. Fase di deployment e monitoraggio:
   - Deployment graduale con monitoraggio attento
   - Feedback loops e aggiornamento responsabile

Questo approccio "ethics by design" incorpora considerazioni etiche fin dalle prime fasi di sviluppo.

Spunto di riflessione: "In quale fase del ciclo di vita pensate sia piÃ¹ critico incorporare considerazioni etiche? PerchÃ©?"
-->
---

## Strumenti pratici per lo sviluppo responsabile ğŸ§°

- **Documentazione standardizzata** ğŸ“
  - Datasheets for Datasets
  - Model Cards
- **Toolkit e librerie** ğŸ’»
  - Fairness Indicators
  - What-If Tool
  - AI Fairness 360
- **Processi e framework** ğŸ”„
  - Responsible AI Maturity Model
  - Ethics Canvas

<!--
Diversi strumenti concreti possono supportare lo sviluppo responsabile:

1. Documentazione standardizzata:
   - Datasheets for Datasets: template per documentare caratteristiche, limitazioni e considerazioni etiche dei dataset
   - Model Cards: documentazione standardizzata di capacitÃ , casi d'uso previsti e limitazioni dei modelli
   - Transparency Notes: documentazione accessibile per utenti finali su funzionamento e limitazioni

2. Toolkit e librerie:
   - Fairness Indicators: strumenti per valutare e visualizzare metriche di fairness
   - What-If Tool: strumento interattivo per esplorare comportamento dei modelli
   - AI Fairness 360: libreria open-source per rilevare e mitigare bias
   - Privacy-preserving NLP libraries: strumenti per implementare tecniche come federated learning o differential privacy

3. Processi e framework:
   - Responsible AI Maturity Model: framework per valutare e migliorare pratiche organizzative
   - Ethics Canvas: strumento collaborativo per mappare implicazioni etiche
   - Consequence Scanning: workshop strutturato per identificare conseguenze intenzionali e non
   - Diverse Voices: metodologia per incorporare prospettive diverse nel design

Questi strumenti rendono piÃ¹ concreto e praticabile lo sviluppo responsabile di sistemi NLP.

Domanda per la platea: "Quali di questi strumenti avete giÃ  utilizzato o vorreste esplorare? Quali altri strumenti conoscete che potrebbero essere utili?"
-->

---

## Collaborazione multidisciplinare ğŸ‘¥

![bg right:40%](https://source.unsplash.com/random/800x600/?collaboration,team)

- **Team multidisciplinari** ğŸ§ 
  - Esperti di etica, scienze sociali, legge, domain experts
- **Coinvolgimento degli stakeholder** ğŸ¤
  - Participatory design
  - Community engagement
- **Formazione e sensibilizzazione** ğŸ“š
  - Curriculum integration
  - Leadership awareness

<!--
Lo sviluppo responsabile richiede collaborazione tra diverse discipline:

1. Team multidisciplinari:
   - Composizione diversificata: inclusione di esperti di etica, scienze sociali, legge, domain experts
   - Collaborazione strutturata: processi che facilitano dialogo tra discipline diverse
   - Linguaggio comune e rispetto reciproco per diverse forme di expertise

2. Coinvolgimento degli stakeholder:
   - Participatory design: coinvolgimento attivo degli utenti finali nel processo di design
   - Community engagement: dialogo con comunitÃ  potenzialmente impattate
   - Expert consultation e feedback iterativo

3. Formazione e sensibilizzazione:
   - Curriculum integration: incorporazione di considerazioni etiche nella formazione tecnica
   - Hands-on training e continuing education
   - Leadership awareness e cross-functional training
   - Ethics champions interni

Questa collaborazione multidisciplinare Ã¨ essenziale per identificare e affrontare le complesse sfide etiche nell'NLP.

Spunto di riflessione: "Come possiamo superare le barriere linguistiche e concettuali tra diverse discipline per facilitare una collaborazione efficace?"
-->

---

# Riflessione finale ğŸ’­

### L'etica nell'NLP non Ã¨ un ostacolo all'innovazione, ma una componente essenziale di un'innovazione veramente benefica e sostenibile.

<!--
Questa slide offre una riflessione conclusiva sul tema dell'etica nell'NLP. Ãˆ importante sottolineare che l'etica non Ã¨ un freno all'innovazione, ma piuttosto un elemento che la rende piÃ¹ robusta, sostenibile e benefica per la societÃ .

Posso elaborare su questo punto evidenziando che:
- L'innovazione tecnologica ha senso solo se migliora effettivamente la vita delle persone
- Considerare le implicazioni etiche fin dall'inizio puÃ² prevenire costosi fallimenti e perdita di fiducia
- Un approccio etico puÃ² stimolare innovazioni piÃ¹ creative che rispondono a esigenze reali
- La fiducia del pubblico Ã¨ essenziale per l'adozione diffusa delle tecnologie NLP

Questo messaggio finale invita la platea a vedere l'etica non come una checklist di conformitÃ  o un insieme di restrizioni, ma come una bussola che guida verso un'innovazione piÃ¹ significativa e di impatto positivo.

Posso concludere chiedendo alla platea di riflettere su come possono incorporare considerazioni etiche nel loro lavoro quotidiano, sia che siano sviluppatori, ricercatori, manager o utenti di sistemi NLP.
-->
---

## Conclusione ğŸ¯

- I sistemi NLP incorporano valori e prioritÃ  con profonde conseguenze sociali ğŸŒ
- I bias possono perpetuare o amplificare disuguaglianze esistenti âš–ï¸
- La privacy Ã¨ particolarmente critica per dati linguistici personali ğŸ”’
- La trasparenza e la spiegabilitÃ  sono essenziali per costruire fiducia ğŸ”
- Lo sviluppo responsabile richiede un approccio multidisciplinare ğŸ‘¥
- L'etica nell'NLP Ã¨ un processo continuo, non una destinazione finale ğŸ”„

<!--
In questa conclusione, riassumiamo i punti chiave discussi durante la presentazione:

I sistemi NLP non sono strumenti neutri, ma incorporano valori e prioritÃ  che possono avere profonde conseguenze sociali. Questo richiede un'attenta considerazione delle implicazioni etiche in ogni fase del loro sviluppo e utilizzo.

I bias nei sistemi NLP possono perpetuare o amplificare disuguaglianze esistenti, richiedendo tecniche specifiche di misurazione e mitigazione.

La privacy Ã¨ particolarmente critica quando si tratta di dati linguistici, che spesso contengono informazioni personali e sensibili.

La trasparenza e la spiegabilitÃ  sono essenziali per costruire fiducia e permettere oversight, nonostante le sfide poste dalla complessitÃ  dei moderni sistemi NLP.

Lo sviluppo responsabile richiede un approccio multidisciplinare che integri diverse prospettive e competenze.

Infine, Ã¨ importante sottolineare che l'etica nell'NLP non Ã¨ una checklist da completare una volta per tutte, ma un processo continuo di riflessione, valutazione e miglioramento.

Guardando al futuro, possiamo anticipare che le questioni etiche nell'NLP diventeranno sempre piÃ¹ complesse con l'evoluzione della tecnologia, rendendo ancora piÃ¹ importante un approccio proattivo e riflessivo.

Domanda finale per la platea: "Quale aspetto dell'etica nell'NLP pensate sarÃ  piÃ¹ importante affrontare nei prossimi anni? Come possiamo prepararci per queste sfide future?"
-->>


---

## ğŸš€ Sfide future

- Maggiore explainability
- Modelli piÃ¹ inclusivi
- Regolamentazione internazionale ğŸŒ

ğŸ’¬ **Domanda:**  
Chi dovrebbe decidere le regole? Governi, aziende, utenti?

<!-- 
NOTE PER LO SPEAKER:
Spiega che le sfide etiche richiederanno collaborazione tra governi, aziende, ricercatori e societÃ  civile.
Domanda: â€œChi dovrebbe avere lâ€™ultima parola sulle regole etiche?â€
-->

---

## âœ¨ Come ci ricorda Spider-Man

> â€œDa grandi poteri derivano grandi responsabilitÃ â€ ğŸ•·ï¸

ğŸ’¬ **Domanda finale:**  
Come usereste il vostro â€˜potere NLPâ€™ per fare del bene?

<!-- 
NOTE PER LO SPEAKER:
Chiudi con leggerezza ma lascia un messaggio potente. Cita Spider-Man per essere simpatico, ma ricollegati al concetto di responsabilitÃ .
Domanda: â€œSe poteste costruire un modello NLP per aiutare il mondo, cosa fareste?â€
-->

---

## Riferimenti e Approfondimenti ğŸ“š

- Bender, E. M., et al. (2021). **On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?**
- Blodgett, S. L., et al. (2020). **Language (Technology) is Power: A Critical Survey of "Bias" in NLP**
- Floridi, L., & Cowls, J. (2019). **A Unified Framework of Five Principles for AI in Society**
- Weidinger, L., et al. (2021). **Ethical and social risks of harm from Language Models**

<!--
Questa slide fornisce riferimenti bibliografici chiave per chi volesse approfondire i temi trattati nella presentazione.

I riferimenti selezionati rappresentano lavori fondamentali nel campo dell'etica nell'NLP:

- Il paper di Bender et al. (noto come "Stochastic Parrots") Ã¨ un lavoro influente che discute i rischi dei modelli linguistici di grandi dimensioni
- Il survey di Blodgett et al. offre una panoramica critica della ricerca sui bias nell'NLP
- Il framework di Floridi e Cowls propone cinque principi etici fondamentali per l'AI in societÃ 
- Il paper di Weidinger et al. esplora i rischi etici e sociali dei modelli linguistici

Posso menzionare che questi sono solo alcuni dei lavori piÃ¹ rilevanti, e che il campo Ã¨ in rapida evoluzione con nuove pubblicazioni che emergono continuamente.

Potrei anche suggerire risorse online come il AI Ethics Guidelines Global Inventory, il Partnership on AI, o il Montreal AI Ethics Institute per chi volesse rimanere aggiornato sugli sviluppi in questo campo.
-->

---

## ğŸ“£ Grazie per lâ€™attenzione!

ğŸ™ Domande? Commenti?  
Pronti a cambiare il mondoâ€¦ in modo etico!

<!-- 
NOTE PER LO SPEAKER:
Ringrazia la classe, invita a fare domande e a continuare la discussione.
-->