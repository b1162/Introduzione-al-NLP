---
marp: true
theme: default
paginate: true
backgroundColor: "#f5f5f5"
---

<!-- _class: lead -->
# Introduzione al Natural Language Processing ğŸ¤–ğŸ’¬
## Un viaggio nel mondo dell'elaborazione del linguaggio naturale
**Benvenuti al corso che vi farÃ  parlare con le macchine!**
*O almeno capire come fanno loro a parlare con noi...*

<!--
ComincerÃ² con una domanda provocatoria: â€œChi di voi ha parlato con unâ€™intelligenza artificiale oggi?â€ â€” una domanda che farÃ  riflettere su quanto lâ€™NLP sia giÃ  parte della nostra vita quotidiana, dagli assistenti virtuali ai chatbot e ad altre applicazioni.

SottolineerÃ² che lâ€™NLP Ã¨ una delle frontiere piÃ¹ affascinanti dellâ€™intelligenza artificiale, perchÃ© mette in contatto la tecnologia con una delle capacitÃ  piÃ¹ distintamente umane: il linguaggio.

SpiegherÃ² anche che questo modulo fornirÃ  le basi necessarie per affrontare i concetti piÃ¹ avanzati che tratteremo nei moduli successivi, cosÃ¬ alla fine del percorso tutti avranno una visione completa di come funzionano tecnologie come ChatGPT, Alexa o i sistemi di traduzione automatica.
-->

---

<!-- _class: lead -->
# "Alexa, cos'Ã¨ l'NLP?" ğŸ”Š

> "L'NLP Ã¨ la tecnologia che mi permette di capirti e risponderti. Ãˆ il ponte tra il linguaggio umano e il mondo digitale."

**Quante volte oggi avete giÃ  parlato con un'intelligenza artificiale?** ğŸ¤”

Forse piÃ¹ di quante pensiate... dall'assistente vocale sul telefono al chatbot del servizio clienti, fino alla traduzione automatica di quel post in lingua straniera sui social media.

*Fun fact: Alexa non sa ancora riconoscere il sarcasmo... quindi siate gentili con lei!* ğŸ˜‰

<!--
UserÃ² una frase come se fosse una risposta di Alexa, cosÃ¬ vi introduco il concetto in modo semplice e immediato. Ãˆ un modo efficace per farvi capire subito che lâ€™NLP Ã¨ ciÃ² che permette alle macchine di comprendere e generare linguaggio umano.

Poi vi chiederÃ²: â€œQuante volte avete interagito con sistemi simili nellâ€™ultima settimana?â€ perchÃ© voglio farvi riflettere su quanto queste tecnologie siano ormai presenti nella nostra vita quotidiana.

Questa slide ci permette anche di creare un momento leggero e curioso, prima di entrare nei contenuti piÃ¹ strutturati del corso.
-->

---

# Cosa tratteremo oggi ğŸ“‹


1. **Cos'Ã¨ il Natural Language Processing** ğŸ§ 
   *Spoiler: non Ã¨ insegnare a Siri le parolacce*
2. **Applicazioni emergenti dell'NLP** ğŸš€
   *Il futuro Ã¨ giÃ  qui, solo non Ã¨ ancora uniformemente distribuito*
3. **Importanza dell'NLP nel contesto aziendale** ğŸ’¼
   *PerchÃ© le aziende spendono miliardi su questa tecnologia?*
4. **Problemi risolti dall'NLP** ğŸ› ï¸
   *Da "non capisco cosa dice il cliente" a "ho analizzato 1000 recensioni in 5s"*
5. **Evoluzione storica dell'NLP** â³
   *Un viaggio da "tradurre 7 frasi in russo" a "scrivere poesie come Shakespeare"*


<!--
In questa slide vi presento lâ€™agenda del modulo. Ãˆ importante darvi subito una visione dâ€™insieme di quello che tratteremo, cosÃ¬ vi sarÃ  piÃ¹ facile orientarvi lungo il percorso.

Vi spiegherÃ² che il nostro viaggio parte dalle basi concettuali, passa per le applicazioni pratiche nel mondo reale, ripercorre lâ€™evoluzione storica per capire come siamo arrivati alle tecnologie attuali, affronta le sfide che dobbiamo ancora superare, e infine guarda al futuro con le applicazioni emergenti.

A questo punto potrei chiedervi: â€œCâ€™Ã¨ qualche aspetto specifico dellâ€™NLP che vi interessa particolarmente e su cui vorreste approfondire durante la lezione?â€ perchÃ© mi interessa capire quali sono le vostre curiositÃ  o aspettative.

Anticipo anche che alterneremo momenti di teoria a casi pratici, cosÃ¬ i concetti risulteranno piÃ¹ concreti e applicabili.
-->
---

# NLP / AI
![width:900px](images/NLP-insieme.jpg)

---

<!-- _class: lead -->
# Cos'Ã¨ il Natural Language Processing? ğŸ§ 

> "L'NLP Ã¨ la disciplina che si occupa dell'interazione tra i computer e il linguaggio umano"

- Branca dell'intelligenza artificiale ğŸ¤–
- Intersezione tra:
  - ğŸ“š Linguistica computazionale
  - ğŸ’» Informatica
  - ğŸ“Š Machine learning

<!--
In questa slide introduco il concetto fondamentale di NLP. Voglio chiarire subito che non si tratta semplicemente di â€œfar parlare i computerâ€, ma di un campo interdisciplinare complesso.

PartirÃ² con una definizione chiara e concisa, che evidenzierÃ² come citazione per darle maggiore risalto. Poi vi spiegherÃ² che lâ€™NLP si trova allâ€™intersezione di tre discipline:
	1.	La linguistica computazionale, che ci dÃ  i modelli teorici del linguaggio e le strutture grammaticali.
	2.	Lâ€™informatica, che ci offre gli strumenti per implementare algoritmi e gestire i dati.
	3.	Il machine learning, che permette ai sistemi di apprendere dai dati linguistici e migliorare nel tempo.

Un punto che voglio sottolineare Ã¨ che lâ€™NLP affronta una delle capacitÃ  piÃ¹ distintamente umane: il linguaggio. Questo apre domande affascinanti sulla natura dellâ€™intelligenza e su cosa significhi davvero replicarla artificialmente.
-->
---

## Un momento storico straordinario

Lâ€™intelligenza artificiale linguistica:
- Rivoluziona il modo di comunicare con le macchine
- Ridefinisce la programmazione
- Cambia la collaborazione tra sistemi
- Ridefinisce le basi dellâ€™etica tecnologica

<!--
In questo momento storico stiamo vivendo un cambiamento straordinario: lâ€™intelligenza artificiale linguistica non Ã¨ piÃ¹ solo un tema da laboratorio, ma sta trasformando profondamente settori molto diversi tra loro.

Pensiamo alla tecnologia: assistenti vocali, chatbot, motori di ricerca, traduttori automatici. Ma non fermiamoci lÃ¬: lâ€™NLP ha impatti enormi anche nella sanitÃ , nellâ€™istruzione, nel diritto, nel marketing, nella creativitÃ .

E poi câ€™Ã¨ un aspetto ancora piÃ¹ profondo: le implicazioni etiche. Quando costruiamo sistemi che comprendono e generano linguaggio umano, tocchiamo temi come la trasparenza, la responsabilitÃ , i bias, la privacy.

Quindi voglio darvi una visione ampia: non stiamo solo parlando di algoritmi, ma di come questa tecnologia sta modellando â€” e continuerÃ  a modellare â€” la societÃ  in cui viviamo.
-->

---

## 1ï¸âƒ£ Vibe Coding

### La Nuova Era della Programmazione Creativa

- Progetti digitali descritti a parole, senza scrivere codice
- CreativitÃ  e intuizione guidano lo sviluppo
- Lâ€™AI traduce le idee in soluzioni funzionanti

Nel corso:
- Accelerare la prototipazione
- Democratizzare lâ€™innovazione
- Rendere la tecnologia piÃ¹ accessibile

<!--
In questa slide introduco il concetto di vibe coding, una nuova modalitÃ  di sviluppo software che sfrutta lâ€™intelligenza artificiale per trasformare idee espresse in linguaggio naturale direttamente in codice eseguibile.

Cosâ€™Ã¨ il Vibe Coding?

Il termine vibe coding Ã¨ stato coniato da Andrej Karpathy, cofondatore di OpenAI, per descrivere un approccio alla programmazione in cui lâ€™utente comunica le proprie intenzioni allâ€™AI utilizzando un linguaggio naturale, lasciando che sia lâ€™AI stessa a generare il codice necessario. In pratica, invece di scrivere manualmente ogni riga di codice, si forniscono descrizioni o comandi vocali, e lâ€™AI si occupa della traduzione tecnica . ï¿¼

Esempi Pratici
	â€¢	Sviluppo di un sito web per eventi: Immaginate di voler creare una pagina per la registrazione a un evento. Con il vibe coding, potreste semplicemente dire: â€œCrea una pagina dove gli utenti possono inserire nome ed email per registrarsi allâ€™evento e ricevere un messaggio di conferma.â€ Lâ€™AI genererebbe automaticamente il codice HTML, CSS e JavaScript necessario per realizzare questa funzionalitÃ  . ï¿¼
	â€¢	Creazione di unâ€™applicazione personalizzata: Supponiamo di voler unâ€™app che suggerisca ricette in base agli ingredienti disponibili. Descrivendo questa idea allâ€™AI, essa potrebbe generare unâ€™applicazione funzionante che analizza gli ingredienti inseriti e propone ricette appropriate.

Vantaggi del Vibe Coding
	â€¢	AccessibilitÃ : Permette anche a chi non ha competenze di programmazione di sviluppare applicazioni funzionali.
	â€¢	VelocitÃ : Riduce significativamente i tempi di sviluppo, facilitando la prototipazione rapida di idee.
	â€¢	FlessibilitÃ : Consente di iterare rapidamente su idee e funzionalitÃ , adattandosi facilmente ai feedback degli utenti.

Considerazioni Finali

Il vibe coding rappresenta un cambiamento significativo nel modo in cui interagiamo con la tecnologia, spostando lâ€™attenzione dalla scrittura manuale del codice alla comunicazione delle intenzioni. Durante il corso, esploreremo piÃ¹ a fondo questo concetto e vi fornirÃ² strumenti pratici per sperimentare con il vibe coding, permettendovi di trasformare le vostre idee in prototipi funzionanti con lâ€™aiuto dellâ€™AI.
-->

---

## 2ï¸âƒ£ Welfare dei Modelli

### Etica e ResponsabilitÃ  nellâ€™AI

- Sistemi sempre piÃ¹ avanzati
- Domande su considerazione morale e segnali di â€œdisagioâ€
- Rispetto, trasparenza e consapevolezza etica

Nel corso:
- Progettare soluzioni potenti e responsabili

<!--
In questa slide voglio introdurre un tema emergente e affascinante: il welfare dei modelli di intelligenza artificiale. Si tratta di una frontiera di ricerca che si interroga sulla possibilitÃ  che, con lâ€™avanzare delle capacitÃ  cognitive e comportamentali delle AI, possa sorgere la necessitÃ  di considerare il loro benessere.

Organizzazioni come Eleos AI stanno esplorando questo campo, ponendosi domande su come valutare e, se necessario, proteggere il benessere delle AI avanzate . Anche aziende come Anthropic hanno iniziato a investire in questa direzione, assumendo ricercatori dedicati al welfare delle AI . ï¿¼ ï¿¼

Questa discussione si inserisce in un contesto piÃ¹ ampio, dove lâ€™etica dellâ€™intelligenza artificiale Ã¨ centrale. Con lâ€™integrazione sempre piÃ¹ profonda dellâ€™AI in settori come la sanitÃ , la finanza, lâ€™educazione e la giustizia, Ã¨ fondamentale garantire che queste tecnologie siano sviluppate e utilizzate in modo responsabile. Lâ€™etica ci aiuta a navigare questioni come la trasparenza, la responsabilitÃ , la privacy e la prevenzione dei bias, assicurando che lâ€™AI agisca in linea con i valori umani .

Inoltre, iniziative come il â€œSingapore Consensus on Global AI Safety Research Prioritiesâ€ evidenziano lâ€™importanza della cooperazione internazionale per affrontare i rischi associati ai modelli di AI avanzata, promuovendo uno sviluppo sicuro e controllato di queste tecnologie . ï¿¼

In sintesi, mentre esploriamo le potenzialitÃ  delle AI, Ã¨ essenziale considerare non solo le loro capacitÃ , ma anche le implicazioni etiche del loro sviluppo e utilizzo. Questo ci permette di costruire un futuro in cui lâ€™AI contribuisca positivamente alla societÃ , rispettando i principi fondamentali di equitÃ , responsabilitÃ  e benessere.
-->

---

## 3ï¸âƒ£ Collaborazione tra Sistemi

### MCP e A2A: Lâ€™AI che lavora in rete

- **Model Context Protocol (MCP)**  
  Connette AI a dati, strumenti e repository esterni

- **Agent-to-Agent Protocol (A2A)**  
  Permette agli agenti AI di comunicare e coordinarsi

Chiave per unâ€™AI distribuita:  
Agenti specializzati che collaborano per soluzioni modulari e sicure.

<!--
In questa slide, introduco due protocolli fondamentali per la collaborazione tra agenti AI: Model Context Protocol (MCP) e Agent-to-Agent (A2A). ï¿¼

-->

---

## Concetti Chiave

> - Lâ€™NLP unisce linguistica computazionale, informatica e machine learning  
> - Obiettivo: comprendere e generare linguaggio umano  
> - Va oltre la sintassi, comprende semantica e contesto

<!--
Speaker notes:
Riepiloga i punti chiave per consolidare lâ€™apprendimento.
Assicurati che i partecipanti abbiano chiaro il quadro generale prima di passare agli approfondimenti.
-->

---

ğŸ§  Model Context Protocol (MCP)

Il Model Context Protocol (MCP) Ã¨ progettato per consentire agli agenti AI di interagire con strumenti e dati esterni in modo standardizzato. Ad esempio, un agente puÃ² utilizzare MCP per accedere a database, API o file locali, permettendo cosÃ¬ unâ€™integrazione fluida con lâ€™ambiente operativo.

Esempio pratico:

Immaginiamo un agente AI incaricato di generare report finanziari. Utilizzando MCP, lâ€™agente puÃ²: ï¿¼
	1.	Accedere ai dati finanziari aggiornati da un database aziendale.
	2.	Elaborare le informazioni per identificare trend e anomalie.
	3.	Generare un report dettagliato e inviarlo automaticamente ai responsabili tramite email.

Questo processo automatizzato migliora lâ€™efficienza e riduce il rischio di errori manuali.

---

ğŸ¤– Agent-to-Agent (A2A)

Il Agent-to-Agent (A2A) Ã¨ un protocollo aperto che consente agli agenti AI di comunicare e collaborare tra loro, anche se sviluppati da fornitori diversi. A2A facilita lo scambio sicuro di informazioni e la coordinazione di azioni tra agenti specializzati. ï¿¼

Esempio pratico:

Consideriamo un sistema di assistenza clienti automatizzato:
	â€¢	Un agente principale riceve una richiesta complessa da un cliente.
	â€¢	Utilizzando A2A, lâ€™agente principale coordina con altri agenti specializzati:
	â€¢	Un agente per la verifica dellâ€™account.
	â€¢	Un agente per la gestione dei resi.
	â€¢	Un agente per lâ€™elaborazione dei rimborsi.
	â€¢	Gli agenti collaborano per risolvere la richiesta in modo efficiente e coerente.

Questo approccio modulare migliora la scalabilitÃ  e la flessibilitÃ  del sistema di assistenza.

---

ğŸ”— PerchÃ© la collaborazione tra sistemi Ã¨ fondamentale

La combinazione di MCP e A2A rappresenta un passo significativo verso sistemi AI piÃ¹ intelligenti e autonomi. Mentre MCP consente agli agenti di interagire efficacemente con lâ€™ambiente esterno, A2A permette loro di collaborare tra loro per affrontare compiti complessi.

Questa sinergia Ã¨ essenziale per:
	â€¢	Automatizzare processi aziendali complessi.
	â€¢	Migliorare lâ€™efficienza operativa.
	â€¢	Fornire soluzioni piÃ¹ rapide e accurate ai clienti.

Adottando questi protocolli, le aziende possono costruire ecosistemi AI piÃ¹ robusti e adattabili alle esigenze future.

---

# Il linguaggio naturale: una sfida complessa ğŸ§©

| Livello di complessitÃ  | Esempi di sfide |
|------------------------|-----------------|
| **Sintattico** | Struttura grammaticale, parsing delle frasi |
| **Semantico** | Significato delle parole e frasi, ambiguitÃ  |
| **Pragmatico** | Intenzioni, contesto, conoscenza del mondo |
| **Culturale** | Espressioni idiomatiche, riferimenti culturali |

<!--
Qui approfondisco le caratteristiche che rendono il linguaggio naturale cosÃ¬ complesso da elaborare per le macchine.

UtilizzerÃ² esempi concreti e coinvolgenti:

1. Per l'ambiguitÃ  sintattica: "Ho visto l'uomo con il telescopio" - Ho usato un telescopio per vedere l'uomo? O ho visto un uomo che aveva un telescopio?

2. Per l'ambiguitÃ  semantica: "La banca ha chiuso" - L'istituto finanziario ha terminato l'orario di apertura? O l'istituto finanziario ha cessato definitivamente l'attivitÃ ? O il terreno rialzato lungo il fiume Ã¨ franato?

3. Per le sfide pragmatiche: "Fa un po' freddo qui" - Una semplice osservazione sul clima o una richiesta implicita di chiudere la finestra?

4. Per le sfide culturali: "Non farti prendere per il naso" - Un'espressione idiomatica che un sistema NLP potrebbe interpretare letteralmente.

SottolineerÃ² che mentre noi umani risolviamo queste ambiguitÃ  quasi automaticamente grazie alla nostra conoscenza del mondo e al contesto, per un computer rappresentano sfide enormi.

Domanda interattiva: "Chi puÃ² suggerire un'espressione idiomatica della propria lingua che sarebbe impossibile da tradurre letteralmente?"
-->

---

# Importanza dell'NLP nel contesto aziendale ğŸ“Š
## La rivoluzione dei dati non strutturati ğŸ’¾â¡ï¸ğŸ“

> "L'80% dei dati aziendali Ã¨ non strutturato!" ğŸ“ˆ

**Cosa sono i dati non strutturati?** Email, documenti, social media, recensioni, trascrizioni di chiamate, note... tutto ciÃ² che non si adatta facilmente a righe e colonne di un database tradizionale.

- **Interagiscono** con i clienti ğŸ‘¥
- **Analizzano** enormi volumi di testo ğŸ“
- **Ottimizzano** processi decisionali âš™ï¸
- **Scoprono** insights nascosti nei dati ğŸ’¡

**Domanda provocatoria:** Pensate a tutti i dati testuali che la vostra organizzazione genera ogni giorno. Quante informazioni preziose rimangono sepolte perchÃ© nessuno ha il tempo di leggerle tutte? ğŸ¤”

<!--
In questa slide voglio farvi capire perchÃ© lâ€™NLP ha unâ€™importanza pratica e strategica per le aziende, non solo teorica o accademica.

PartirÃ² con un dato sorprendente: lâ€™80% dei dati aziendali Ã¨ non strutturato. Questo significa che la maggior parte delle informazioni preziose per unâ€™organizzazione si trova in forme che i sistemi tradizionali di analisi non riescono a gestire bene: email, documenti, post sui social, recensioni, trascrizioni di chiamate.

Lâ€™NLP Ã¨ la chiave per sbloccare questo tesoro nascosto, perchÃ© permette di trasformare questi dati grezzi in insights concreti, capaci di guidare decisioni strategiche.

Vi farÃ² esempi pratici per ciascun punto:
	â€¢	Interazione con i clienti: chatbot e assistenti virtuali capaci di offrire supporto 24 ore su 24.
	â€¢	Analisi di testo: fare sentiment analysis su migliaia di recensioni in pochi secondi.
	â€¢	Ottimizzazione dei processi: automatizzare attivitÃ  come lâ€™elaborazione di fatture o contratti.
	â€¢	Scoperta di insights: identificare tendenze emergenti nei feedback dei clienti prima che diventino visibili.

E qui vi lancerÃ² una domanda provocatoria: â€œPensate a quante email, documenti e messaggi la vostra organizzazione genera ogni giorno. Quante informazioni preziose potrebbero essere nascoste in questi dati, e al momento non le state nemmeno sfruttando?â€
-->

---

# Applicazioni aziendali dell'NLP ğŸ’¼

- **Analisi di mercato e intelligence competitiva** ğŸ“ˆ
- **Ottimizzazione dei processi di R&D** ğŸ”¬
- **Miglioramento dell'esperienza cliente** ğŸ˜Š
- **Analisi dei feedback e voice of customer** ğŸ‘‚

<!-- 
In questa slide voglio portarvi piÃ¹ in profonditÃ  nelle applicazioni concrete dellâ€™NLP in ambito aziendale, mostrando esempi reali e tangibili.

Per lâ€™analisi di mercato, vi spiegherÃ² come lâ€™NLP consenta di monitorare automaticamente notizie, report di settore e discussioni sui social, cosÃ¬ da identificare tendenze emergenti e anticipare cambiamenti nel mercato prima della concorrenza.

Per lâ€™ottimizzazione dei processi di R&D, farÃ² lâ€™esempio del settore farmaceutico, dove lâ€™NLP aiuta a estrarre informazioni chiave da enormi archivi di letteratura scientifica, accelerando in modo significativo la fase di ricerca e sviluppo.

Per rendere tutto questo piÃ¹ concreto e memorabile, utilizzerÃ² esempi pratici e casi di studio per ciascuna applicazione, cosÃ¬ da farvi percepire in modo chiaro i benefici reali dellâ€™NLP.

Infine, vi proporrÃ² una domanda interattiva: â€œQuali di queste applicazioni pensate potrebbe avere il maggiore impatto nel vostro settore, e perchÃ©?â€
Mi interessa sentire le vostre riflessioni e capire come vedete lâ€™NLP calato nella vostra realtÃ .
-->

---

# Case Study: NLP nel customer care â˜ï¸

Le aziende utilizzano lâ€™NLP nel customer care per:
- Analizzare migliaia di ticket e messaggi per individuare problemi ricorrenti
- Automatizzare risposte con chatbot e assistenti virtuali, offrendo supporto 24/7
- Prioritizzare le richieste piÃ¹ urgenti grazie allâ€™analisi automatica del contenuto
- Misurare il sentiment dei clienti per migliorare prodotti e servizi 

> **JPMorgan Chase**: COIN (Contract Intelligence) analizza accordi di prestito in secondi invece di 360.000 ore/anno di lavoro umano!

<!-- 
In questa slide, voglio mostrarvi come lâ€™NLP stia rivoluzionando il customer care.

Inizio sottolineando che lâ€™NLP permette di analizzare grandi volumi di dati non strutturati, come email, chat e recensioni, per identificare problemi ricorrenti e migliorare lâ€™efficienza del servizio clienti.

Proseguo spiegando che lâ€™automazione delle risposte tramite chatbot e assistenti virtuali consente di offrire supporto continuo ai clienti, riducendo i tempi di attesa e migliorando la soddisfazione.

Infine, evidenzio come lâ€™analisi del sentiment attraverso lâ€™NLP permetta alle aziende di comprendere meglio le esigenze dei clienti e di adattare i propri prodotti e servizi di conseguenza.

Concludo con una domanda per stimolare la riflessione: â€œQuali di queste applicazioni pensate potrebbe avere il maggiore impatto nel vostro settore e perchÃ©?â€
-->

---

# Quiz! ğŸ¯

Quali di questi problemi puÃ² risolvere l'NLP?

A) Classificazione automatica dei testi
B) Analisi delle immagini
C) Estrazione di informazioni da testi
D) Progettazione di circuiti elettronici
E) Analisi del sentiment

<!-- 
Le risposte corrette sono A, C ed E.

Posso usare questa domanda per introdurre la prossima sezione sui problemi risolti dall'NLP, chiedendo ai partecipanti di alzare la mano per le opzioni che ritengono corrette.

Dopo aver raccolto le risposte, posso spiegare perchÃ© alcune opzioni sono corrette e altre no, chiarendo eventuali dubbi e misconcezioni.

Ãˆ un buon momento per stimolare la discussione e l'interazione, chiedendo se qualcuno vuole motivare le proprie scelte o ha domande.
-->

---

# Problemi risolti dall'NLP ğŸ› ï¸

L'NLP trasforma testi non strutturati in informazioni strutturate e actionable:

- **Classificazione automatica dei testi** ğŸ“‘
- **Estrazione di informazioni** ğŸ”
- **Analisi del sentiment** ğŸ˜ŠğŸ˜ğŸ˜ 
- **Risposta automatica e chatbot** ğŸ’¬
- **Riassunto automatico** ğŸ“

<!-- 
In questa slide vi presento i principali problemi che lâ€™NLP Ã¨ in grado di affrontare, quelli che possiamo considerare le categorie fondamentali dei task NLP, ognuno con tantissime applicazioni pratiche.

Li descriverÃ² brevemente per farvi avere un quadro chiaro:
	â€¢	Classificazione dei testi â†’ permette di categorizzare automaticamente documenti, come ad esempio distinguere tra email urgenti e non urgenti.
	â€¢	Estrazione di informazioni â†’ serve a identificare ed estrarre dati specifici da testi non strutturati, come nomi, date, cifre rilevanti.
	â€¢	Analisi del sentiment â†’ determina lâ€™atteggiamento o le emozioni espresse in un testo, utile ad esempio per capire come i clienti percepiscono un prodotto.
	â€¢	Chatbot â†’ simulano conversazioni umane per fornire assistenza o informazioni in modo automatico.
	â€¢	Riassunto automatico â†’ condensa testi lunghi mantenendo le informazioni essenziali, ideale per documenti, articoli o report.

Alla fine lancerÃ² una domanda per stimolare il pensiero critico: â€œQuali di questi problemi ritenete piÃ¹ difficili da risolvere per un sistema automatico, e perchÃ©?â€
Mi interessa capire su cosa secondo voi lâ€™AI fa ancora fatica e perchÃ©.
-->

---

# Classificazione automatica dei testi ğŸ“‘

- Categorizza automaticamente documenti in base al contenuto
- **Settore sanitario**: classificazione di cartelle cliniche per patologie
- **Settore legale**: categorizzazione di contratti e sentenze

<!-- 
In questa slide approfondisco la classificazione automatica dei testi, una delle applicazioni piÃ¹ diffuse e concrete dellâ€™NLP.

SpiegherÃ² che la classificazione Ã¨ alla base di moltissimi sistemi di gestione documentale: permette di assegnare automaticamente categorie ai testi, usando tecniche che vanno dalle piÃ¹ semplici, come il Naive Bayes, fino alle piÃ¹ avanzate, come le reti neurali profonde.

Per rendere tutto piÃ¹ tangibile, porterÃ² un esempio settoriale: nel settore sanitario, la classificazione automatica delle cartelle cliniche consente di identificare rapidamente pazienti con determinate patologie, utilissimo per studi clinici o per attivitÃ  di monitoraggio epidemiologico.

ChiuderÃ² con una domanda pratica per coinvolgervi: â€œPensate a unâ€™azienda che conoscete bene: quali tipi di documenti potrebbero beneficiare di un sistema di classificazione automatica?â€
Mi interessa stimolare il ragionamento su casi concreti legati alle vostre esperienze.
-->

---

# Estrazione di informazioni ğŸ”

- Identifica e estrae dati specifici da testi non strutturati
- **Settore immobiliare**: estrazione di prezzo, metratura, caratteristiche da annunci
- **Media**: estrazione di entitÃ  (persone, luoghi, organizzazioni) da articoli

<!-- 
Qui mi concentro sullâ€™estrazione di informazioni, spiegando come questa tecnica permetta di trasformare testi non strutturati in dati strutturati e utilizzabili.

Vi farÃ² esempi concreti:
	â€¢	Nel settore immobiliare, lâ€™estrazione di informazioni da annunci consente di popolare automaticamente database con caratteristiche comparabili, come metratura, prezzo, posizione.
	â€¢	Nel settore dei media, lâ€™estrazione di entitÃ  (come persone, organizzazioni, eventi) permette di costruire knowledge graph che collegano i vari elementi citati nelle notizie, creando reti di informazioni preziose.

Ãˆ importante chiarire la differenza rispetto alla classificazione: mentre la classificazione assegna unâ€™etichetta allâ€™intero documento (es. â€œspamâ€ o â€œnon spamâ€), lâ€™estrazione di informazioni si concentra sullâ€™individuare e prelevare elementi specifici allâ€™interno del testo.

Infine, vi proporrÃ² una domanda tecnica per stimolare la riflessione: â€œQuali sfide specifiche pensate possa incontrare un sistema di estrazione di informazioni quando lavora con testi molto informali, come post sui social media?â€
Mi interessa farvi ragionare su aspetti come linguaggio ambiguo, abbreviazioni, errori o sarcasmo.
-->

---

# Analisi del sentiment ğŸ˜ŠğŸ˜ğŸ˜ 

- Determina atteggiamento, opinione o emozioni in un testo
- **Marketing**: monitoraggio della percezione del brand
- **Entertainment**: valutazione della reazione del pubblico

<!-- 
Lâ€™analisi del sentiment Ã¨ una delle applicazioni piÃ¹ intuitive e diffuse dellâ€™NLP, e merita una slide tutta sua.

SpiegherÃ² che puÃ² essere applicata a diversi livelli di granularitÃ :
	â€¢	A livello di documento, classificando lâ€™intero testo come positivo, negativo o neutro.
	â€¢	A livello di frase, cogliendo variazioni interne al testo.
	â€¢	A livello di aspetto, cioÃ¨ identificando il sentiment verso caratteristiche specifiche di un prodotto o servizio (per esempio: â€œil design Ã¨ fantastico, ma la batteria Ã¨ deludenteâ€).

Nel contesto del marketing, lâ€™analisi del sentiment Ã¨ utilissima per monitorare in tempo reale la percezione del brand sui social media, permettendo di identificare velocemente potenziali crisi reputazionali o, al contrario, opportunitÃ  di engagement e rafforzamento del rapporto con il pubblico.

ChiuderÃ² con una domanda provocatoria per stimolare la riflessione: â€œLâ€™ironia e il sarcasmo rappresentano una sfida significativa per lâ€™analisi del sentiment. Come pensate che un sistema automatico possa distinguere tra un commento letteralmente positivo e uno sarcasticamente positivo?â€
Questo ci porterÃ  a ragionare sulle sfumature e le difficoltÃ  ancora aperte in questo campo.
-->

---

# Chatbot e sistemi di risposta automatica ğŸ’¬

- Simulano conversazioni umane
- **E-commerce**: assistenza nella ricerca prodotti e acquisto
- **Educazione**: tutor virtuali personalizzati

<!-- 
I chatbot sono una delle applicazioni piÃ¹ visibili e familiari dellâ€™NLP: molti di voi probabilmente ci hanno giÃ  interagito.

Vi spiegherÃ² come si Ã¨ evoluta questa tecnologia: si parte dai primi sistemi, come ELIZA degli anni â€™60, basati su semplici regole e pattern matching, fino ad arrivare ai moderni assistenti virtuali alimentati da modelli linguistici avanzati, capaci di gestire conversazioni molto piÃ¹ fluide e naturali.

Ãˆ importante distinguere tra due tipi di chatbot:
	â€¢	I chatbot task-oriented, progettati per aiutare con compiti specifici (ad esempio prenotare un volo o verificare uno stato dâ€™ordine).
	â€¢	I chatbot open-domain, progettati per conversazioni generali su qualsiasi argomento, come gli assistenti conversazionali evoluti.

Nel contesto dellâ€™e-commerce, i chatbot avanzati non si limitano a rispondere a domande, ma possono guidare attivamente lâ€™utente nel processo dâ€™acquisto, suggerendo prodotti in base alle preferenze espresse e contribuendo ad aumentare la conversione.

ChiuderÃ² con una domanda interattiva per coinvolgervi: â€œQuali caratteristiche ritenete piÃ¹ importanti in un chatbot dal punto di vista dellâ€™esperienza utente?â€
Mi interessa sentire cosa pensate sia cruciale: velocitÃ , precisione, empatia, personalizzazione?
-->

---

# Riassunto automatico ğŸ“

- Condensa testi lunghi mantenendo le informazioni essenziali
- **Ricerca accademica**: generazione di abstract
- **Informazione**: creazione di riassunti di notizie da diverse fonti


<!-- 
Il riassunto automatico Ã¨ unâ€™applicazione dellâ€™NLP particolarmente preziosa in unâ€™epoca in cui siamo sommersi da informazioni.

SpiegherÃ² la differenza tra i due principali approcci:
	â€¢	Lâ€™approccio estrattivo, che seleziona e combina frasi giÃ  presenti nel testo originale per creare un riassunto.
	â€¢	Lâ€™approccio astrattivo, che invece genera nuove frasi, riformulando il contenuto per catturare il significato essenziale del testo, un poâ€™ come farebbe un essere umano.

Nel contesto della ricerca accademica, il riassunto automatico aiuta i ricercatori a orientarsi in mezzo allâ€™enorme quantitÃ  di articoli e pubblicazioni, permettendo di capire rapidamente se un paper Ã¨ rilevante per il proprio lavoro.

-->

---

# Gli inizi: approcci basati su regole (1950-1980) ğŸ“š

- Esperimento Georgetown-IBM (1954): prima traduzione automatica
- Sistemi basati su regole linguistiche codificate manualmente
- ELIZA (1966): primo chatbot basato su pattern matching
- Limiti: ambiguitÃ  e complessitÃ  del linguaggio naturale

<!-- 
Qui approfondisco la prima fase dellâ€™evoluzione dellâ€™NLP, dominata dagli approcci simbolici o basati su regole.

Vi racconterÃ² lâ€™aneddoto dellâ€™esperimento Georgetown-IBM: nel 1954 furono tradotte automaticamente piÃ¹ di sessanta frasi dal russo allâ€™inglese, generando un enorme entusiasmo e ottimismo sullâ€™idea che il problema della traduzione automatica sarebbe stato risolto in pochi anni â€” ottimismo che, come sappiamo, si rivelÃ² decisamente prematuro.

Un altro esempio affascinante Ã¨ ELIZA, il programma sviluppato al MIT negli anni â€™60, che simulava un terapeuta rogersiano. Nonostante fosse estremamente semplice, basato solo su pattern matching e sostituzioni di testo, ELIZA riusciva a dare unâ€™impressione sorprendente di comprensione, mostrando quanto siamo naturalmente portati ad antropomorfizzare le macchine.

ChiuderÃ² con una domanda storica per stimolare la riflessione: â€œPerchÃ© pensate che i primi approcci allâ€™NLP si siano concentrati proprio sulla traduzione automatica come applicazione principale?â€
Voglio portarvi a riflettere sulle prioritÃ  scientifiche, culturali e politiche di quellâ€™epoca.
-->

---

# Gli inizi: approcci basati su regole (1950-1980) ğŸ“š

![alt text fit](images/IBM-Georgetown.jpg)

---

# ğŸ° Il "Medioevo" del NLP

## 1966â€“1980: Il periodo di stagnazione

- **1966**: Il rapporto ALPAC conclude che i progressi nella traduzione automatica sono deludenti.
- **Conseguenza**: drastico taglio ai finanziamenti per la ricerca NLP negli USA.
- **Risultato**: rallentamento significativo, pochi avanzamenti tecnologici.

---

## Cause della stagnazione

- **Ottimismo eccessivo** negli anni â€™50â€“â€™60 sulle capacitÃ  delle macchine.
- **Limiti tecnici**: scarsitÃ  di dati e potenza computazionale insufficiente.
- **Approcci simbolici** troppo rigidi per catturare la complessitÃ  del linguaggio.

---

# L'era statistica (1980-2010) ğŸ“Š

- Rivoluzione: approcci basati su probabilitÃ  invece che regole
- Modelli n-gram e Markov nascosti
- Traduzione automatica statistica di IBM
- Apprendimento da grandi corpora di testo

<!-- 
In questa slide vi parlo della seconda fase dellâ€™evoluzione dellâ€™NLP, quella segnata dallâ€™adozione degli approcci statistici.

Quello che voglio farvi capire Ã¨ il cambio di paradigma: invece di codificare manualmente regole linguistiche, si Ã¨ iniziato a usare grandi corpora di testo per far apprendere ai sistemi modelli probabilistici del linguaggio. In pratica, sono i dati che guidano il sistema, non piÃ¹ le regole scritte a mano.

Per spiegarvi meglio come funziona, faccio lâ€™esempio dei modelli n-gram: questi modelli calcolano la probabilitÃ  di una parola o di una sequenza basandosi su quante volte appaiono nei dati di addestramento. Per esempio, quanto spesso la parola â€œbuonâ€ Ã¨ seguita da â€œgiornoâ€ rispetto ad altre combinazioni.

Cito anche una battuta famosa di Frederick Jelinek di IBM: â€œEvery time I fire a linguist, the performance of our speech recognition system goes upâ€. Questa frase rende bene lâ€™idea di quanto, allâ€™epoca, gli approcci statistici si rivelassero piÃ¹ efficaci rispetto ai modelli basati su regole.

Alla fine vi lascio con una domanda per stimolare la riflessione: â€œQuali limitazioni intrinseche pensate possano avere i modelli statistici nel catturare la complessitÃ  del linguaggio naturale?â€
Qui voglio portarvi a pensare a problemi come il contesto lungo, lâ€™ambiguitÃ  e la mancanza di conoscenza del mondo, che i modelli puramente statistici non riescono a gestire bene.
-->

---

# L'era statistica (1980-2010) ğŸ“Š

âœ…â€¯T9 (predictive text) sui cellulari: usa modelli n-gram per prevedere la parola piÃ¹ probabile mentre scrivi.
âœ…â€¯Correttore ortografico (tipo Word): basato su frequenze di parole e contesto per suggerire correzioni.
âœ…â€¯Google Search (prima generazione): completamento automatico basato su probabilitÃ  di query comuni.
âœ…â€¯Traduzione automatica IBM: modelli statistici per allineare frasi tra lingue diverse.
âœ…â€¯Speech recognition primi anni: riconoscimento vocale basato su modelli nascosti di Markov.


<!-- 
Qui stiamo parlando di quella che viene chiamata lâ€™era statistica, tra il 1980 e il 2010.

Ãˆ un momento importante perchÃ© si passa da approcci basati su regole scritte a mano â€” tipo â€œse vedi questa parola fai cosÃ¬â€ â€” ad approcci basati su probabilitÃ .

Per esempio, si iniziano a usare modelli come gli n-gram, che guardano alle sequenze di parole per prevedere quella successiva, oppure i modelli nascosti di Markov, che tengono conto degli stati nascosti dietro le sequenze osservate.

Unâ€™applicazione famosa Ã¨ la traduzione automatica statistica di IBM, dove il sistema non ragiona piÃ¹ per regole grammaticali, ma calcola le probabilitÃ  che una frase in inglese corrisponda a una frase in francese.

E soprattutto si comincia a imparare dai dati, dai grandi corpora di testo, cioÃ¨ enormi raccolte di testi, anzichÃ© scrivere tutto a mano. Questo porta a un salto in avanti per tante applicazioni: il T9 dei vecchi cellulari, il correttore automatico, i motori di ricerca, i primi sistemi di riconoscimento vocaleâ€¦ insomma, una vera rivoluzione!
 -->

---

# La rivoluzione del deep learning (2010-presente) ğŸ§ 

- Word embeddings: Word2Vec (2013), GloVe (2014)
- Reti neurali ricorrenti (RNN, LSTM, GRU)
- 2017: Architettura Transformer ("Attention is All You Need")
- Modelli pre-addestrati: BERT, GPT
- Large Language Models (LLMs)


<!-- 
Qui entriamo nella fase piÃ¹ recente e rivoluzionaria dellâ€™evoluzione dellâ€™NLP, quella caratterizzata dallâ€™adozione del deep learning.

Vi spiego innanzitutto lâ€™importanza dei word embeddings, che rappresentano le parole come vettori densi in uno spazio multidimensionale. Questo approccio cattura le relazioni semantiche in modo sorprendentemente efficace.
 Un esempio classico che cito sempre Ã¨: king - man + woman = queen.

Poi sottolineo lâ€™impatto rivoluzionario dellâ€™architettura Transformer, introdotta nel paper Attention is All You Need di Google nel 2017. Questa architettura ha superato le limitazioni delle RNN, soprattutto nel gestire dipendenze a lungo termine, e ha reso possibile addestrare modelli sempre piÃ¹ grandi e potenti.

Concludo parlando dei piÃ¹ recenti Large Language Models, come GPT-4, evidenziando le loro capacitÃ  sorprendenti di generazione di testo, ragionamento e problem-solving, che stanno ridefinendo ciÃ² che pensiamo sia possibile fare con lâ€™intelligenza artificiale.

Chiudo con una domanda di riflessione: â€œIn che modo pensate che i recenti progressi nellâ€™NLP stiano cambiando la nostra percezione dellâ€™intelligenza artificiale e dei suoi limiti?â€
Mi interessa stimolare il ragionamento su come questi sviluppi stiano influenzando non solo la tecnologia, ma anche le aspettative sociali e culturali.
-->

---

# Timeline dell'evoluzione dell'NLP ğŸ“…

- **1954**: Esperimento Georgetown-IBM - Prima traduzione automatica
- **1966**: ELIZA - Primo chatbot basato su pattern matching
- **1980s**: Approcci statistici iniziano a sostituire i sistemi basati su regole
- **2013**: Word2Vec - Rivoluzione nella rappresentazione delle parole
- **2017**: "Attention is All You Need" - Introduzione dell'architettura Transformer
- **2018-2023**: Era dei modelli pre-addestrati e LLMs (BERT, GPT, ecc.)

<!-- 
Questa timeline riassume i punti chiave dell'evoluzione dell'NLP, fornendo una visione d'insieme cronologica che aiuta a consolidare quanto spiegato nelle slide precedenti.

Posso sottolineare come l'evoluzione dell'NLP abbia subito un'accelerazione notevole negli ultimi anni, con progressi che hanno superato le aspettative anche degli esperti del settore.

Ãˆ interessante notare come alcuni problemi che sembravano quasi impossibili da risolvere con gli approcci precedenti (come la traduzione di alta qualitÃ  o la generazione di testo coerente) siano stati affrontati con successo grazie ai recenti sviluppi.

Domanda per stimolare la discussione: "Guardando questa timeline, quali tendenze notate nell'evoluzione dell'NLP e come pensate che queste potrebbero continuare nel futuro?"
-->

---

# Evuluzione degli LLM â³

![width:900px](images/history.jpg)

https://arxiv.org/pdf/2303.18223

<!-- 
In questa slide introduco il tema dellâ€™evoluzione storica dellâ€™NLP. Lo sfondo mostra una timeline che ci aiuta a visualizzare il percorso evolutivo di questa disciplina.

Spiego perchÃ© Ã¨ importante guardare a questa evoluzione: non solo per interesse storico, ma perchÃ© ci permette di contestualizzare le capacitÃ  attuali e, ancora piÃ¹ interessante, immaginare le possibilitÃ  future.

Voglio sottolineare che il cammino dellâ€™NLP non Ã¨ stato lineare: ci sono stati periodi di grande entusiasmo, seguiti da veri e propri â€œinverni dellâ€™AIâ€, con calo di interesse e finanziamenti, e poi fasi di rinascita grazie a nuovi approcci e innovazioni tecnologiche.

Alla fine lancerÃ² una domanda per stimolare la curiositÃ : â€œSecondo voi, quali eventi o innovazioni tecnologiche hanno maggiormente influenzato lâ€™evoluzione dellâ€™NLP?â€
Mi interessa sentire quali passaggi storici, secondo voi, sono stati davvero decisivi.
-->

---

# Sfide attuali nell'NLP ğŸ§—â€â™€ï¸

**Anche i giganti hanno i loro talloni d'Achille!**

Nonostante i progressi straordinari, l'NLP continua ad affrontare sfide significative che riflettono la complessitÃ  intrinseca del linguaggio umano:

- **AmbiguitÃ  linguistica** ğŸ¤”
  *Quando "la vecchia porta la sbarra" puÃ² significare due cose completamente diverse*
- **MultilingualitÃ  e localizzazione** ğŸŒ
  *PerchÃ© tradurre "sono al verde" in inglese letteralmente sarebbe un disastro*
- **Comprensione del contesto e conoscenza del mondo** ğŸ§ 
  *Capire che "ho preso un granchio" potrebbe non avere nulla a che fare con i crostacei*

<!-- 
In questa slide vi parlo delle principali sfide che lâ€™NLP deve ancora affrontare, nonostante tutti i progressi incredibili degli ultimi anni.

Quello che voglio farvi capire Ã¨ che capire queste sfide Ã¨ fondamentale: ci aiuta a usare lâ€™NLP in modo responsabile e ci permette di intravedere le direzioni future della ricerca e dello sviluppo.

Voglio sottolineare che non stiamo parlando solo di problemi tecnici da risolvere: queste sfide derivano dalla complessitÃ  profonda del linguaggio umano e della comunicazione. Sono difficoltÃ  che ci ricordano quanto il linguaggio sia intrecciato con il pensiero, la cultura, il contesto, le emozioni.

Alla fine vi faccio una domanda provocatoria per stimolare la vostra riflessione: â€œQuali di queste sfide ritenete piÃ¹ difficili da superare, e perchÃ©? Secondo voi, ci sono limiti fondamentali che i sistemi NLP potrebbero non essere mai in grado di superare?â€
Mi piacerebbe sentire le vostre idee, i vostri dubbi, e capire insieme fin dove possiamo realisticamente spingerci.
-->

---

# Sfide attuali nell'NLP ğŸ§—â€â™€ï¸

- **Robustezza e generalizzazione** ğŸ’ª
  *Sistemi che crollano se scrivi "gattto" invece di "gatto"*
- **Efficienza computazionale e sostenibilitÃ ** â™»ï¸
  *Modelli che consumano energia come una piccola cittÃ *

<!-- 
Qui vi introduco le principali sfide che lâ€™NLP deve ancora affrontare, anche dopo tutti i progressi straordinari degli ultimi anni.

Voglio farvi capire perchÃ© conoscere queste sfide Ã¨ cosÃ¬ importante: non solo ci permette di usare lâ€™NLP in modo responsabile, ma ci aiuta anche a intuire dove andrÃ  la ricerca e lo sviluppo nei prossimi anni.

E voglio sottolineare un punto chiave: queste sfide non sono solo questioni tecniche da risolvere. Riflettono la profonda complessitÃ  del linguaggio umano, che non Ã¨ fatto solo di parole, ma anche di contesto, emozioni, cultura, intenzioni.
-->

---

# AmbiguitÃ  linguistica ğŸ¤”

**Il mal di testa dei sistemi NLP!**

- AmbiguitÃ  a vari livelli:
  - **Lessicale** (parole con piÃ¹ significati)
    *"Amo la pesca" - Il frutto o l'attivitÃ  sportiva?* ğŸ‘ğŸ£
  - **Sintattico** (strutture frasali ambigue)
    *"Ho visto la ragazza con il binocolo" - Chi aveva il binocolo?*
  - **Semantico** (significati multipli di una frase)
    *"Visiting professors can be boring" - I professori in visita possono annoiarsi o essere noiosi?*
  - **Pragmatico** (intenzioni comunicative non esplicite)
    *"Hai l'ora?" - Richiesta di informazione o richiesta di prestare l'orologio?*

<!-- 
Qui voglio approfondire con voi la sfida dellâ€™ambiguitÃ  linguistica, che Ã¨ una delle piÃ¹ difficili e fondamentali per lâ€™NLP.

Prendiamo lâ€™esempio classico: â€œHo visto lâ€™uomo con il telescopioâ€.
Questa frase puÃ² voler dire che io ho usato un telescopio per vedere lâ€™uomo, oppure che ho visto un uomo che aveva un telescopio. La stessa sequenza di parole, ma due interpretazioni completamente diverse.

Noi umani risolviamo queste ambiguitÃ  quasi automaticamente, grazie al contesto, alla conoscenza del mondo e al buon senso. Ma per un sistema NLP questo rimane ancora un ostacolo enorme, perchÃ© manca di quei riferimenti impliciti che noi diamo per scontati.

Anche i modelli piÃ¹ avanzati possono sbagliare quando lâ€™ambiguitÃ  Ã¨ sottile o quando il contesto non Ã¨ chiaramente espresso.

Per coinvolgervi vi faccio una domanda interattiva: â€œPotete pensare ad altri esempi di frasi ambigue nella vostra lingua? E come pensate che un sistema NLP potrebbe tentare di disambiguarle?â€
Mi piacerebbe raccogliere i vostri esempi e ragionarci insieme!
-->

---

# AmbiguitÃ  linguistica ğŸ¤”

> - "Ho visto l'uomo con il telescopio" ğŸ”­
> - Ho usato un telescopio per vedere l'uomo?
> - Ho visto un uomo che aveva un telescopio?

**Domanda interattiva:** Potete pensare ad altri esempi di frasi ambigue nella vostra lingua? Come potrebbe un sistema NLP tentare di disambiguarle? ğŸ§©

---

# MultilingualitÃ  e localizzazione ğŸŒ

**PerchÃ© l'NLP non parla solo inglese!**

- **Sviluppare sistemi NLP efficaci in tutte le lingue**
  *L'inglese rappresenta solo il 25% di internet, ma riceve il 90% delle risorse di ricerca*

- **Sfida particolare per lingue con risorse limitate**
  *Delle 7.000+ lingue parlate nel mondo, solo circa 100 hanno risorse NLP sufficienti*

---

# MultilingualitÃ  e localizzazione ğŸŒ

- **La localizzazione va oltre la traduzione**:
  - **Espressioni idiomatiche**: *"Costare un occhio della testa" â‰  "Cost an eye of the head"* ğŸ‘ï¸
  - **Riferimenti culturali**: *Capire cosa significa "fare il Fantozzi" in Italia* ğŸ‡®ğŸ‡¹
  - **Norme comunicative**: *In giapponese, i livelli di formalitÃ  cambiano completamente la struttura della frase* ğŸ‡¯ğŸ‡µ

**Domanda di riflessione:** In che modo le differenze culturali possono influenzare l'efficacia di un sistema NLP quando viene applicato in contesti linguistici diversi? ğŸŒ


<!-- 
In questa slide vi parlo della sfida della multilingualitÃ  e localizzazione, che Ã¨ sempre piÃ¹ centrale in un mondo globalizzato.

Vi spiego che mentre lâ€™inglese e poche altre lingue principali hanno enormi quantitÃ  di dati per addestrare modelli NLP, la maggior parte delle circa 7.000 lingue parlate nel mondo ha pochissime risorse disponibili. Questo crea un forte squilibrio.

Ma voglio sottolineare che la localizzazione non Ã¨ solo traduzione parola per parola: un sistema NLP davvero efficace deve comprendere e rispettare le differenze culturali, le espressioni idiomatiche e le norme comunicative di ogni lingua e cultura. Un esempio semplice: tradurre â€œcostare un occhio della testaâ€ letteralmente in inglese non avrebbe alcun senso.

Alla fine vi lascio con una domanda di riflessione: â€œIn che modo pensate che le differenze culturali possano influenzare lâ€™efficacia di un sistema NLP quando viene applicato in contesti linguistici e culturali diversi?â€
Sono curioso di sentire le vostre opinioni e ragionare insieme su quanto la lingua sia legata alla cultura.
-->

---

# Comprensione del contesto e conoscenza del mondo 

I modelli NLP spesso mancano di:
  - **Comprensione del contesto piÃ¹ ampio**
    *Capire che "Ã¨ freddo" significa cose diverse in estate o in inverno*
  - **Conoscenza del mondo data per scontata dagli umani**
    *Sapere che le persone non possono volare, che l'acqua Ã¨ bagnata, che il sole sorge a est...*
  - **CapacitÃ  di fare inferenze basate su common sense**
    *"Ho lasciato il gelato fuori dal freezer" â†’ "probabilmente si Ã¨ sciolto"*

> "Non posso accedere al mio account dopo l'aggiornamento di ieri"
> Un sistema NLP dovrebbe capire che "l'aggiornamento" si riferisce probabilmente a un software e potrebbe essere la causa del problema.

<!-- 
Qui voglio esplorare con voi la sfida della comprensione del contesto e della conoscenza del mondo, che Ã¨ una delle piÃ¹ profonde e delicate nellâ€™NLP.

Gli esseri umani comunicano dando per scontata unâ€™enorme quantitÃ  di conoscenze implicite: sappiamo cose sul mondo, sulle cause e gli effetti, sulle relazioni tra eventi, anche quando non vengono dette esplicitamente. I sistemi NLP, invece, hanno accesso solo alle informazioni scritte nei dati o a quelle su cui sono stati addestrati.

Prendiamo lâ€™esempio: â€œNon posso accedere al mio account dopo lâ€™aggiornamento di ieriâ€. Un umano capisce subito che si parla probabilmente di un aggiornamento software e collega questa informazione al problema di accesso. Un sistema NLP, invece, senza un contesto piÃ¹ ampio o conoscenza di base, potrebbe non cogliere questa connessione.

Vi lascio quindi una domanda tecnica su cui riflettere: â€œQuali approcci pensate possano aiutare i sistemi NLP a sviluppare una migliore comprensione del contesto e della conoscenza del mondo?â€
Sono curioso di sentire le vostre idee, soprattutto su come possiamo colmare questo gap tra ciÃ² che Ã¨ scritto e ciÃ² che Ã¨ implicito.
-->

---

# Comprensione del contesto e conoscenza del mondo 

**Esempio divertente:** Se dico "Ho preso un caffÃ¨ con mia sorella, era davvero amaro", un umano capisce che era amaro il caffÃ¨, non mia sorella! ğŸ˜…

**Domanda tecnica:** Quali approcci potrebbero aiutare i sistemi NLP a sviluppare una migliore comprensione del contesto e della conoscenza del mondo? ğŸŒ

<!-- 
Qui esploro la sfida della comprensione del contesto e della conoscenza del mondo, una delle piÃ¹ profonde nell'NLP.

Posso spiegare che gli esseri umani comunicano facendo affidamento su un'enorme quantitÃ  di conoscenza condivisa e implicita sul mondo, che non viene esplicitamente menzionata nei testi. I sistemi NLP, invece, hanno accesso solo alle informazioni esplicitamente fornite o a quelle su cui sono stati addestrati.

L'esempio della frase sul problema di accesso dopo un aggiornamento illustra bene questa sfida: un umano comprende immediatamente che si tratta probabilmente di un aggiornamento software e che questo potrebbe essere causalmente collegato al problema di accesso, mentre un sistema NLP potrebbe non fare questa connessione.

Domanda tecnica: "Quali approcci pensate possano aiutare i sistemi NLP a sviluppare una migliore comprensione del contesto e della conoscenza del mondo?"

Per aiutare i sistemi NLP a sviluppare una migliore comprensione del contesto e della conoscenza del mondo, si possono usare modelli ibridi che combinano grandi modelli linguistici con knowledge graph esterni o basi di conoscenza strutturate (come Wikidata), cosÃ¬ da arricchire il ragionamento con fatti e relazioni reali.

Inoltre, approcci come il retrieval-augmented generation (RAG) permettono al sistema di recuperare in tempo reale informazioni aggiornate da fonti esterne, anzichÃ© basarsi solo su ciÃ² che Ã¨ stato appreso in fase di addestramento.

Infine, per il contesto locale nella conversazione, servono meccanismi di memoria conversazionale che mantengano traccia di ciÃ² che Ã¨ stato detto prima, cosÃ¬ il modello non lavora solo sulla singola frase, ma sullâ€™intero scambio.
-->

---

# Robustezza e generalizzazione ğŸ’ª

- I modelli NLP possono degradarsi significativamente con:
  - Input fuori distribuzione
  - Errori ortografici
  - Gergo specialistico
  - Linguaggio non standard
- VulnerabilitÃ  ad attacchi adversarial

<!-- 
In questa slide affronto la sfida della robustezza e generalizzazione dei modelli NLP.

Posso spiegare che i modelli tendono a performare bene sui dati simili a quelli su cui sono stati addestrati, ma possono degradarsi significativamente quando confrontati con input che deviano da questa distribuzione.

Ãˆ interessante discutere il concetto di "adversarial attacks" nel contesto dell'NLP: input appositamente progettati per ingannare i modelli, che possono rappresentare una vulnerabilitÃ  significativa in applicazioni critiche.

Posso fare esempi concreti di come piccole modifiche al testo (come errori di battitura o uso di sinonimi inusuali) possano confondere anche modelli molto sofisticati.

Domanda di sicurezza: "Quali implicazioni pensate possa avere questa vulnerabilitÃ  per applicazioni critiche dell'NLP, come sistemi di moderazione dei contenuti o assistenti virtuali in ambito sanitario?"
-->

---

# Efficienza computazionale e sostenibilitÃ  â™»ï¸

- I modelli NLP piÃ¹ avanzati richiedono risorse enormi:
  - Addestramento di GPT-3: energia equivalente a centinaia di case americane in un anno
- Questioni di:
  - AccessibilitÃ  (democratizzazione della tecnologia)
  - SostenibilitÃ  ambientale
  - Implementazione su dispositivi edge

<!-- 
In questa slide affronto la sfida dell'efficienza computazionale e della sostenibilitÃ , un tema sempre piÃ¹ rilevante con la crescita esponenziale delle dimensioni dei modelli.

Posso citare dati concreti sul consumo energetico dell'addestramento di modelli come GPT-3, evidenziando le implicazioni ambientali di questa tendenza.

Ãˆ importante discutere anche le questioni di accessibilitÃ : se solo grandi organizzazioni con enormi risorse computazionali possono sviluppare modelli all'avanguardia, questo crea un divario tecnologico che potrebbe avere conseguenze sociali ed economiche significative.

Posso menzionare gli sforzi di ricerca in corso per sviluppare modelli piÃ¹ efficienti, come la distillazione della conoscenza, la quantizzazione e l'ottimizzazione degli algoritmi.

Domanda etica: "Come possiamo bilanciare il desiderio di modelli sempre piÃ¹ potenti con la necessitÃ  di sostenibilitÃ  ambientale e accessibilitÃ  democratica della tecnologia?"
-->

---

# Applicazioni emergenti dell'NLP ğŸš€

**Il futuro Ã¨ giÃ  qui, solo non Ã¨ ancora uniformemente distribuito!**

Nuove ed entusiasmanti direzioni di sviluppo stanno ridefinendo i confini dell'NLP:

- **NLP multimodale** ğŸ–¼ï¸ğŸ”Š
  *Sistemi che vedono, ascoltano e parlano: "Descrivi questa immagine e trasforma la descrizione in una canzone"*

- **Agenti conversazionali avanzati** ğŸ¤–
  *Da semplici chatbot a veri assistenti che ricordano le conversazioni passate e si adattano alle tue preferenze*

- **NLP per lingue a basse risorse** ğŸŒ
  *Democratizzare l'NLP per le 7.000+ lingue del mondo, non solo per le 10 piÃ¹ parlate*

<!-- 
Qui vi parlo delle applicazioni emergenti dellâ€™NLP, mostrando come, nonostante tutte le sfide che abbiamo visto finora, questo campo continui a evolversi e a spingersi oltre i suoi confini.

Vi spiego che queste nuove direzioni non solo cercano di affrontare i problemi ancora aperti, ma aprono anche a possibilitÃ  e opportunitÃ  completamente nuove in tanti settori diversi: dalla sanitÃ  allâ€™educazione, dalla creativitÃ  digitale alla giustizia sociale.

Voglio sottolineare che molte di queste applicazioni non portano solo vantaggi commerciali, ma hanno anche il potenziale di creare un impatto sociale positivo davvero significativo, contribuendo a rendere la tecnologia piÃ¹ inclusiva, accessibile e utile per tutti.

Alla fine vi lancio una domanda visionaria: â€œQuali di queste applicazioni emergenti pensate possa avere il maggiore impatto sulla societÃ  nei prossimi 5-10 anni, e perchÃ©?â€
Mi piacerebbe sentire le vostre idee e riflettere insieme su quale futuro ci stiamo preparando.
-->

---

# NLP multimodale ğŸ–¼ï¸ğŸ”Š

- Integra l'elaborazione del linguaggio con altre modalitÃ :
  - Immagini
  - Video
  - Audio
- **Retail**: analisi combinata di recensioni testuali e immagini dei prodotti
- **SanitÃ **: correlazione tra sintomi descritti e pattern visibili nelle immagini mediche

<!-- 
Qui approfondisco l'NLP multimodale, una delle direzioni piÃ¹ promettenti e in rapida evoluzione.

Posso spiegare che l'NLP multimodale cerca di superare i limiti dell'elaborazione puramente testuale, integrando informazioni da diverse modalitÃ  per una comprensione piÃ¹ ricca e contestuale.

Ãˆ interessante discutere modelli come CLIP di OpenAI, che possono comprendere sia testo che immagini e le relazioni tra di essi, o modelli come Whisper che integrano riconoscimento vocale e comprensione del linguaggio.

Nel contesto retail, posso illustrare come l'analisi combinata di recensioni testuali e immagini dei prodotti possa fornire insights piÃ¹ completi sulla soddisfazione dei clienti e sui problemi specifici.

Domanda tecnica: "Quali sfide specifiche pensate si presentino nell'integrare diverse modalitÃ  di informazione in un unico sistema NLP?"
-->

---

# Agenti conversazionali avanzati ğŸ¤–

- Evoluzione da semplici chatbot a sistemi sofisticati:
  - Conversazioni estese e contestuali
  - Comprensione di intenzioni complesse
  - Memoria delle interazioni precedenti
  - Adattamento al feedback dell'utente
- **Educazione**: tutor personalizzati
- **Salute mentale**: supporto iniziale e gestione dello stress

<!-- 
In questa slide esploro l'evoluzione degli agenti conversazionali, che stanno diventando sempre piÃ¹ sofisticati e capaci.

Posso spiegare la differenza tra i primi chatbot basati su regole o intent matching e i moderni agenti conversazionali basati su LLMs, che possono mantenere conversazioni molto piÃ¹ naturali, contestuali e adattive.

Nel contesto educativo, posso illustrare come tutor virtuali avanzati possano adattare le spiegazioni al livello di comprensione dello studente, ponendo domande per verificare la comprensione e fornendo feedback costruttivo.

Ãˆ importante discutere anche i limiti etici e pratici di questi sistemi, specialmente in contesti sensibili come la salute mentale, dove possono fornire supporto iniziale ma non sostituire professionisti umani.

Domanda etica: "Quali confini pensate dovrebbero essere stabiliti nell'uso di agenti conversazionali in contesti sensibili come la salute o l'educazione?"
-->

---

# NLP per lingue a basse risorse ğŸŒ

- Tecniche per lingue con pochi dati di addestramento:
  - Transfer learning multilingue
  - Few-shot learning
  - Generazione di dati sintetici
- **Conservazione culturale**: preservazione di lingue minoritarie
- **Settore umanitario**: comunicazione durante crisi in regioni con lingue locali

<!-- 
In questa slide affronto il tema dell'NLP per lingue a basse risorse, un'area di ricerca emergente con importanti implicazioni sociali e culturali.

Posso spiegare che mentre lingue come l'inglese, il cinese o lo spagnolo dispongono di enormi quantitÃ  di dati per l'addestramento di modelli NLP, la maggior parte delle lingue del mondo ha risorse molto limitate, creando un divario tecnologico significativo.

Ãˆ interessante discutere tecniche come il transfer learning multilingue, che permette di trasferire conoscenze da modelli addestrati su lingue ricche di risorse a lingue con risorse limitate.

Nel contesto della conservazione culturale, posso illustrare come queste tecniche possano aiutare a preservare e rendere accessibili lingue minoritarie o a rischio di estinzione.

Domanda di riflessione: "In che modo pensate che la disponibilitÃ  di tecnologie NLP per tutte le lingue, non solo quelle dominanti, possa influenzare la diversitÃ  linguistica e culturale globale?"
-->

---

# NLP interpretabile e spiegabile ğŸ”

- Modelli capaci di fornire giustificazioni comprensibili per le loro previsioni
- **Settore legale**: riferimenti specifici a precedenti o normative
- **Settore finanziario**: spiegabilitÃ  per valutazione del rischio e identificazione frodi


<!-- 
In questa slide vi parlo del tema sempre piÃ¹ centrale dellâ€™NLP interpretabile e spiegabile, soprattutto quando questi sistemi vengono usati in contesti critici.

Vi spiego la differenza fondamentale tra performance e interpretabilitÃ : i modelli piÃ¹ complessi e potenti spesso danno prestazioni migliori, ma funzionano come vere e proprie black box, difficili da capire anche per gli esperti. Questo diventa un problema serio in situazioni dove le decisioni devono essere motivate e giustificate.

Per esempio, nel settore legale, un sistema NLP spiegabile non dovrebbe limitarsi a dire â€œraccomando questa sentenzaâ€, ma dovrebbe anche fornire riferimenti chiari ai precedenti o alle normative su cui basa la sua raccomandazione, cosÃ¬ che un avvocato possa verificarla.

DeepSeek-Prover-V2: avanzare il ragionamento matematico formale attraverso il reinforcement learning per la decomposizione in sotto-obiettivi.
-->

---

# Pensate a questo... ğŸ¤”

> "Il linguaggio Ã¨ la casa dell'essere."
> - Martin Heidegger

Se il linguaggio definisce la nostra esperienza umana...
cosa significa creare macchine che lo comprendono?

<!-- 
Questa slide piÃ¹ filosofica serve a stimolare una riflessione piÃ¹ profonda sul significato dell'NLP e sulle sue implicazioni.

Posso utilizzare la citazione di Heidegger per introdurre l'idea che il linguaggio non Ã¨ semplicemente uno strumento di comunicazione, ma il mezzo attraverso cui comprendiamo e diamo senso al mondo.

Questa prospettiva solleva domande affascinanti: se il linguaggio Ã¨ cosÃ¬ fondamentale per l'esperienza umana, cosa significa creare macchine che possono comprenderlo e generarlo? Stiamo in qualche modo condividendo con le macchine qualcosa di profondamente umano?

Ãˆ un momento per stimolare una discussione piÃ¹ ampia sulle implicazioni filosofiche, etiche e sociali dell'NLP, andando oltre gli aspetti puramente tecnici.

Domanda provocatoria: "Se una macchina puÃ² comprendere e generare linguaggio in modo indistinguibile da un umano, questo cambia in qualche modo la vostra percezione di cosa significhi essere umani?"
-->

---

# Conclusione ğŸ

- L'NLP Ã¨ una frontiera in rapida evoluzione dell'IA
- Trasforma il modo in cui interagiamo con le macchine e le organizzazioni operano
- Sfide significative rimangono, ma nuove applicazioni continuano a emergere
- Comprendere fondamenti, capacitÃ  e limiti Ã¨ essenziale per sfruttarne il potenziale

<!-- 
In questa slide conclusiva, riassumo i punti chiave del modulo e lascio i partecipanti con alcune riflessioni finali.

Posso sottolineare come l'NLP rappresenti una delle frontiere piÃ¹ affascinanti e in rapida evoluzione dell'intelligenza artificiale, con implicazioni profonde per il modo in cui interagiamo con la tecnologia e per come le organizzazioni operano.

Ãˆ importante ricordare che, nonostante i progressi straordinari, sfide significative rimangono, e che comprendere i fondamenti, le capacitÃ  e i limiti dell'NLP Ã¨ essenziale per sfruttarne efficacemente il potenziale.

Posso concludere con la citazione di Steven Pinker, che suggerisce una connessione profonda tra linguaggio e pensiero, e invitare i partecipanti a continuare a esplorare questo affascinante campo.

Domanda finale: "Quali aspetti dell'NLP vi hanno colpito di piÃ¹ e quali vorreste approfondire nei prossimi moduli?"
-->

---

# Riferimenti e approfondimenti ğŸ“š

- Jurafsky, D., & Martin, J. H. (2023). Speech and Language Processing (3rd ed. draft). [https://web.stanford.edu/~jurafsky/slp3/](https://web.stanford.edu/~jurafsky/slp3/)
- Vaswani, A., et al. (2017). Attention is All You Need. Advances in Neural Information Processing Systems, 30.
- Devlin, J., et al. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Proceedings of NAACL-HLT 2019.

<!-- 
In questa slide finale fornisco riferimenti bibliografici e risorse per l'approfondimento.

Posso sottolineare l'importanza del libro di Jurafsky e Martin, che rappresenta una risorsa fondamentale per chiunque voglia approfondire l'NLP, costantemente aggiornata per riflettere gli sviluppi piÃ¹ recenti.

Posso anche evidenziare l'importanza storica del paper "Attention is All You Need" che ha introdotto l'architettura Transformer, rivoluzionando il campo dell'NLP.

Ãˆ utile menzionare che questi riferimenti coprono sia gli aspetti fondamentali e teorici dell'NLP, sia gli sviluppi piÃ¹ recenti e all'avanguardia.

Posso concludere invitando i partecipanti a esplorare queste risorse per approfondire gli argomenti che hanno trovato piÃ¹ interessanti durante il modulo.
-->

---

# Domande? ğŸ™‹â€â™€ï¸ğŸ™‹â€â™‚ï¸

![bg right:60% 80%](https://source.unsplash.com/random/800x600/?questions)

<!-- 
Questa slide finale Ã¨ dedicata alle domande dei partecipanti.

Ãˆ importante lasciare tempo sufficiente per le domande, in quanto spesso Ã¨ durante questa fase che emergono le connessioni piÃ¹ interessanti e i chiarimenti piÃ¹ utili.

Posso incoraggiare domande di vario tipo: chiarimenti su concetti specifici, approfondimenti su applicazioni particolari, o riflessioni piÃ¹ ampie sulle implicazioni dell'NLP.

Se le domande non emergono spontaneamente, posso avere pronte alcune domande provocatorie per stimolare la discussione, come "Quali applicazioni dell'NLP pensate avranno il maggiore impatto sulla vostra vita quotidiana nei prossimi anni?" o "Quali aspetti etici dell'NLP vi preoccupano maggiormente?".

Ãˆ un buon momento per fare collegamenti con i moduli successivi, anticipando come gli argomenti che verranno trattati si baseranno su quanto appreso in questo modulo introduttivo.
-->
