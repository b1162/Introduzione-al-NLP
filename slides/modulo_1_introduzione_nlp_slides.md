---
marp: true
theme: default
paginate: true
backgroundColor: "#f5f5f5"
---

<!-- _class: lead -->
# Introduzione al Natural Language Processing 🤖💬
## Un viaggio nel mondo dell'elaborazione del linguaggio naturale
**Benvenuti al corso che vi farà parlare con le macchine!**
*O almeno capire come fanno loro a parlare con noi...*

<!--
Comincerò con una domanda provocatoria: “Chi di voi ha parlato con un’intelligenza artificiale oggi?” — una domanda che farà riflettere su quanto l’NLP sia già parte della nostra vita quotidiana, dagli assistenti virtuali ai chatbot e ad altre applicazioni.

Sottolineerò che l’NLP è una delle frontiere più affascinanti dell’intelligenza artificiale, perché mette in contatto la tecnologia con una delle capacità più distintamente umane: il linguaggio.

Spiegherò anche che questo modulo fornirà le basi necessarie per affrontare i concetti più avanzati che tratteremo nei moduli successivi, così alla fine del percorso tutti avranno una visione completa di come funzionano tecnologie come ChatGPT, Alexa o i sistemi di traduzione automatica.
-->

---

<!-- _class: lead -->
# "Alexa, cos'è l'NLP?" 🔊

> "L'NLP è la tecnologia che mi permette di capirti e risponderti. È il ponte tra il linguaggio umano e il mondo digitale."

**Quante volte oggi avete già parlato con un'intelligenza artificiale?** 🤔

Forse più di quante pensiate... dall'assistente vocale sul telefono al chatbot del servizio clienti, fino alla traduzione automatica di quel post in lingua straniera sui social media.

*Fun fact: Alexa non sa ancora riconoscere il sarcasmo... quindi siate gentili con lei!* 😉

<!--
Userò una frase come se fosse una risposta di Alexa, così vi introduco il concetto in modo semplice e immediato. È un modo efficace per farvi capire subito che l’NLP è ciò che permette alle macchine di comprendere e generare linguaggio umano.

Poi vi chiederò: “Quante volte avete interagito con sistemi simili nell’ultima settimana?” perché voglio farvi riflettere su quanto queste tecnologie siano ormai presenti nella nostra vita quotidiana.

Questa slide ci permette anche di creare un momento leggero e curioso, prima di entrare nei contenuti più strutturati del corso.
-->

---

# Cosa tratteremo oggi 📋


1. **Cos'è il Natural Language Processing** 🧠
   *Spoiler: non è insegnare a Siri le parolacce*
2. **Applicazioni emergenti dell'NLP** 🚀
   *Il futuro è già qui, solo non è ancora uniformemente distribuito*
3. **Importanza dell'NLP nel contesto aziendale** 💼
   *Perché le aziende spendono miliardi su questa tecnologia?*
4. **Problemi risolti dall'NLP** 🛠️
   *Da "non capisco cosa dice il cliente" a "ho analizzato 1000 recensioni in 5s"*
5. **Evoluzione storica dell'NLP** ⏳
   *Un viaggio da "tradurre 7 frasi in russo" a "scrivere poesie come Shakespeare"*


<!--
In questa slide vi presento l’agenda del modulo. È importante darvi subito una visione d’insieme di quello che tratteremo, così vi sarà più facile orientarvi lungo il percorso.

Vi spiegherò che il nostro viaggio parte dalle basi concettuali, passa per le applicazioni pratiche nel mondo reale, ripercorre l’evoluzione storica per capire come siamo arrivati alle tecnologie attuali, affronta le sfide che dobbiamo ancora superare, e infine guarda al futuro con le applicazioni emergenti.

A questo punto potrei chiedervi: “C’è qualche aspetto specifico dell’NLP che vi interessa particolarmente e su cui vorreste approfondire durante la lezione?” perché mi interessa capire quali sono le vostre curiosità o aspettative.

Anticipo anche che alterneremo momenti di teoria a casi pratici, così i concetti risulteranno più concreti e applicabili.
-->
---

# NLP / AI
![width:900px](images/NLP-insieme.jpg)

---

<!-- _class: lead -->
# Cos'è il Natural Language Processing? 🧠

> "L'NLP è la disciplina che si occupa dell'interazione tra i computer e il linguaggio umano"

- Branca dell'intelligenza artificiale 🤖
- Intersezione tra:
  - 📚 Linguistica computazionale
  - 💻 Informatica
  - 📊 Machine learning

<!--
In questa slide introduco il concetto fondamentale di NLP. Voglio chiarire subito che non si tratta semplicemente di “far parlare i computer”, ma di un campo interdisciplinare complesso.

Partirò con una definizione chiara e concisa, che evidenzierò come citazione per darle maggiore risalto. Poi vi spiegherò che l’NLP si trova all’intersezione di tre discipline:
	1.	La linguistica computazionale, che ci dà i modelli teorici del linguaggio e le strutture grammaticali.
	2.	L’informatica, che ci offre gli strumenti per implementare algoritmi e gestire i dati.
	3.	Il machine learning, che permette ai sistemi di apprendere dai dati linguistici e migliorare nel tempo.

Un punto che voglio sottolineare è che l’NLP affronta una delle capacità più distintamente umane: il linguaggio. Questo apre domande affascinanti sulla natura dell’intelligenza e su cosa significhi davvero replicarla artificialmente.
-->
---

## Un momento storico straordinario

L’intelligenza artificiale linguistica:
- Rivoluziona il modo di comunicare con le macchine
- Ridefinisce la programmazione
- Cambia la collaborazione tra sistemi
- Ridefinisce le basi dell’etica tecnologica

<!--
In questo momento storico stiamo vivendo un cambiamento straordinario: l’intelligenza artificiale linguistica non è più solo un tema da laboratorio, ma sta trasformando profondamente settori molto diversi tra loro.

Pensiamo alla tecnologia: assistenti vocali, chatbot, motori di ricerca, traduttori automatici. Ma non fermiamoci lì: l’NLP ha impatti enormi anche nella sanità, nell’istruzione, nel diritto, nel marketing, nella creatività.

E poi c’è un aspetto ancora più profondo: le implicazioni etiche. Quando costruiamo sistemi che comprendono e generano linguaggio umano, tocchiamo temi come la trasparenza, la responsabilità, i bias, la privacy.

Quindi voglio darvi una visione ampia: non stiamo solo parlando di algoritmi, ma di come questa tecnologia sta modellando — e continuerà a modellare — la società in cui viviamo.
-->

---

## 1️⃣ Vibe Coding

### La Nuova Era della Programmazione Creativa

- Progetti digitali descritti a parole, senza scrivere codice
- Creatività e intuizione guidano lo sviluppo
- L’AI traduce le idee in soluzioni funzionanti

Nel corso:
- Accelerare la prototipazione
- Democratizzare l’innovazione
- Rendere la tecnologia più accessibile

<!--
In questa slide introduco il concetto di vibe coding, una nuova modalità di sviluppo software che sfrutta l’intelligenza artificiale per trasformare idee espresse in linguaggio naturale direttamente in codice eseguibile.

Cos’è il Vibe Coding?

Il termine vibe coding è stato coniato da Andrej Karpathy, cofondatore di OpenAI, per descrivere un approccio alla programmazione in cui l’utente comunica le proprie intenzioni all’AI utilizzando un linguaggio naturale, lasciando che sia l’AI stessa a generare il codice necessario. In pratica, invece di scrivere manualmente ogni riga di codice, si forniscono descrizioni o comandi vocali, e l’AI si occupa della traduzione tecnica . ￼

Esempi Pratici
	•	Sviluppo di un sito web per eventi: Immaginate di voler creare una pagina per la registrazione a un evento. Con il vibe coding, potreste semplicemente dire: “Crea una pagina dove gli utenti possono inserire nome ed email per registrarsi all’evento e ricevere un messaggio di conferma.” L’AI genererebbe automaticamente il codice HTML, CSS e JavaScript necessario per realizzare questa funzionalità . ￼
	•	Creazione di un’applicazione personalizzata: Supponiamo di voler un’app che suggerisca ricette in base agli ingredienti disponibili. Descrivendo questa idea all’AI, essa potrebbe generare un’applicazione funzionante che analizza gli ingredienti inseriti e propone ricette appropriate.

Vantaggi del Vibe Coding
	•	Accessibilità: Permette anche a chi non ha competenze di programmazione di sviluppare applicazioni funzionali.
	•	Velocità: Riduce significativamente i tempi di sviluppo, facilitando la prototipazione rapida di idee.
	•	Flessibilità: Consente di iterare rapidamente su idee e funzionalità, adattandosi facilmente ai feedback degli utenti.

Considerazioni Finali

Il vibe coding rappresenta un cambiamento significativo nel modo in cui interagiamo con la tecnologia, spostando l’attenzione dalla scrittura manuale del codice alla comunicazione delle intenzioni. Durante il corso, esploreremo più a fondo questo concetto e vi fornirò strumenti pratici per sperimentare con il vibe coding, permettendovi di trasformare le vostre idee in prototipi funzionanti con l’aiuto dell’AI.
-->

---

## 2️⃣ Welfare dei Modelli

### Etica e Responsabilità nell’AI

- Sistemi sempre più avanzati
- Domande su considerazione morale e segnali di “disagio”
- Rispetto, trasparenza e consapevolezza etica

Nel corso:
- Progettare soluzioni potenti e responsabili

<!--
In questa slide voglio introdurre un tema emergente e affascinante: il welfare dei modelli di intelligenza artificiale. Si tratta di una frontiera di ricerca che si interroga sulla possibilità che, con l’avanzare delle capacità cognitive e comportamentali delle AI, possa sorgere la necessità di considerare il loro benessere.

Organizzazioni come Eleos AI stanno esplorando questo campo, ponendosi domande su come valutare e, se necessario, proteggere il benessere delle AI avanzate . Anche aziende come Anthropic hanno iniziato a investire in questa direzione, assumendo ricercatori dedicati al welfare delle AI . ￼ ￼

Questa discussione si inserisce in un contesto più ampio, dove l’etica dell’intelligenza artificiale è centrale. Con l’integrazione sempre più profonda dell’AI in settori come la sanità, la finanza, l’educazione e la giustizia, è fondamentale garantire che queste tecnologie siano sviluppate e utilizzate in modo responsabile. L’etica ci aiuta a navigare questioni come la trasparenza, la responsabilità, la privacy e la prevenzione dei bias, assicurando che l’AI agisca in linea con i valori umani .

Inoltre, iniziative come il “Singapore Consensus on Global AI Safety Research Priorities” evidenziano l’importanza della cooperazione internazionale per affrontare i rischi associati ai modelli di AI avanzata, promuovendo uno sviluppo sicuro e controllato di queste tecnologie . ￼

In sintesi, mentre esploriamo le potenzialità delle AI, è essenziale considerare non solo le loro capacità, ma anche le implicazioni etiche del loro sviluppo e utilizzo. Questo ci permette di costruire un futuro in cui l’AI contribuisca positivamente alla società, rispettando i principi fondamentali di equità, responsabilità e benessere.
-->

---

## 3️⃣ Collaborazione tra Sistemi

### MCP e A2A: L’AI che lavora in rete

- **Model Context Protocol (MCP)**  
  Connette AI a dati, strumenti e repository esterni

- **Agent-to-Agent Protocol (A2A)**  
  Permette agli agenti AI di comunicare e coordinarsi

Chiave per un’AI distribuita:  
Agenti specializzati che collaborano per soluzioni modulari e sicure.

<!--
In questa slide, introduco due protocolli fondamentali per la collaborazione tra agenti AI: Model Context Protocol (MCP) e Agent-to-Agent (A2A). ￼

-->

---

## Concetti Chiave

> - L’NLP unisce linguistica computazionale, informatica e machine learning  
> - Obiettivo: comprendere e generare linguaggio umano  
> - Va oltre la sintassi, comprende semantica e contesto

<!--
Speaker notes:
Riepiloga i punti chiave per consolidare l’apprendimento.
Assicurati che i partecipanti abbiano chiaro il quadro generale prima di passare agli approfondimenti.
-->

---

🧠 Model Context Protocol (MCP)

Il Model Context Protocol (MCP) è progettato per consentire agli agenti AI di interagire con strumenti e dati esterni in modo standardizzato. Ad esempio, un agente può utilizzare MCP per accedere a database, API o file locali, permettendo così un’integrazione fluida con l’ambiente operativo.

Esempio pratico:

Immaginiamo un agente AI incaricato di generare report finanziari. Utilizzando MCP, l’agente può: ￼
	1.	Accedere ai dati finanziari aggiornati da un database aziendale.
	2.	Elaborare le informazioni per identificare trend e anomalie.
	3.	Generare un report dettagliato e inviarlo automaticamente ai responsabili tramite email.

Questo processo automatizzato migliora l’efficienza e riduce il rischio di errori manuali.

---

🤖 Agent-to-Agent (A2A)

Il Agent-to-Agent (A2A) è un protocollo aperto che consente agli agenti AI di comunicare e collaborare tra loro, anche se sviluppati da fornitori diversi. A2A facilita lo scambio sicuro di informazioni e la coordinazione di azioni tra agenti specializzati. ￼

Esempio pratico:

Consideriamo un sistema di assistenza clienti automatizzato:
	•	Un agente principale riceve una richiesta complessa da un cliente.
	•	Utilizzando A2A, l’agente principale coordina con altri agenti specializzati:
	•	Un agente per la verifica dell’account.
	•	Un agente per la gestione dei resi.
	•	Un agente per l’elaborazione dei rimborsi.
	•	Gli agenti collaborano per risolvere la richiesta in modo efficiente e coerente.

Questo approccio modulare migliora la scalabilità e la flessibilità del sistema di assistenza.

---

🔗 Perché la collaborazione tra sistemi è fondamentale

La combinazione di MCP e A2A rappresenta un passo significativo verso sistemi AI più intelligenti e autonomi. Mentre MCP consente agli agenti di interagire efficacemente con l’ambiente esterno, A2A permette loro di collaborare tra loro per affrontare compiti complessi.

Questa sinergia è essenziale per:
	•	Automatizzare processi aziendali complessi.
	•	Migliorare l’efficienza operativa.
	•	Fornire soluzioni più rapide e accurate ai clienti.

Adottando questi protocolli, le aziende possono costruire ecosistemi AI più robusti e adattabili alle esigenze future.

---

# Il linguaggio naturale: una sfida complessa 🧩

| Livello di complessità | Esempi di sfide |
|------------------------|-----------------|
| **Sintattico** | Struttura grammaticale, parsing delle frasi |
| **Semantico** | Significato delle parole e frasi, ambiguità |
| **Pragmatico** | Intenzioni, contesto, conoscenza del mondo |
| **Culturale** | Espressioni idiomatiche, riferimenti culturali |

<!--
Qui approfondisco le caratteristiche che rendono il linguaggio naturale così complesso da elaborare per le macchine.

Utilizzerò esempi concreti e coinvolgenti:

1. Per l'ambiguità sintattica: "Ho visto l'uomo con il telescopio" - Ho usato un telescopio per vedere l'uomo? O ho visto un uomo che aveva un telescopio?

2. Per l'ambiguità semantica: "La banca ha chiuso" - L'istituto finanziario ha terminato l'orario di apertura? O l'istituto finanziario ha cessato definitivamente l'attività? O il terreno rialzato lungo il fiume è franato?

3. Per le sfide pragmatiche: "Fa un po' freddo qui" - Una semplice osservazione sul clima o una richiesta implicita di chiudere la finestra?

4. Per le sfide culturali: "Non farti prendere per il naso" - Un'espressione idiomatica che un sistema NLP potrebbe interpretare letteralmente.

Sottolineerò che mentre noi umani risolviamo queste ambiguità quasi automaticamente grazie alla nostra conoscenza del mondo e al contesto, per un computer rappresentano sfide enormi.

Domanda interattiva: "Chi può suggerire un'espressione idiomatica della propria lingua che sarebbe impossibile da tradurre letteralmente?"
-->

---

# Importanza dell'NLP nel contesto aziendale 📊
## La rivoluzione dei dati non strutturati 💾➡️📝

> "L'80% dei dati aziendali è non strutturato!" 📈

**Cosa sono i dati non strutturati?** Email, documenti, social media, recensioni, trascrizioni di chiamate, note... tutto ciò che non si adatta facilmente a righe e colonne di un database tradizionale.

- **Interagiscono** con i clienti 👥
- **Analizzano** enormi volumi di testo 📝
- **Ottimizzano** processi decisionali ⚙️
- **Scoprono** insights nascosti nei dati 💡

**Domanda provocatoria:** Pensate a tutti i dati testuali che la vostra organizzazione genera ogni giorno. Quante informazioni preziose rimangono sepolte perché nessuno ha il tempo di leggerle tutte? 🤔

<!--
In questa slide voglio farvi capire perché l’NLP ha un’importanza pratica e strategica per le aziende, non solo teorica o accademica.

Partirò con un dato sorprendente: l’80% dei dati aziendali è non strutturato. Questo significa che la maggior parte delle informazioni preziose per un’organizzazione si trova in forme che i sistemi tradizionali di analisi non riescono a gestire bene: email, documenti, post sui social, recensioni, trascrizioni di chiamate.

L’NLP è la chiave per sbloccare questo tesoro nascosto, perché permette di trasformare questi dati grezzi in insights concreti, capaci di guidare decisioni strategiche.

Vi farò esempi pratici per ciascun punto:
	•	Interazione con i clienti: chatbot e assistenti virtuali capaci di offrire supporto 24 ore su 24.
	•	Analisi di testo: fare sentiment analysis su migliaia di recensioni in pochi secondi.
	•	Ottimizzazione dei processi: automatizzare attività come l’elaborazione di fatture o contratti.
	•	Scoperta di insights: identificare tendenze emergenti nei feedback dei clienti prima che diventino visibili.

E qui vi lancerò una domanda provocatoria: “Pensate a quante email, documenti e messaggi la vostra organizzazione genera ogni giorno. Quante informazioni preziose potrebbero essere nascoste in questi dati, e al momento non le state nemmeno sfruttando?”
-->

---

# Applicazioni aziendali dell'NLP 💼

- **Analisi di mercato e intelligence competitiva** 📈
- **Ottimizzazione dei processi di R&D** 🔬
- **Miglioramento dell'esperienza cliente** 😊
- **Analisi dei feedback e voice of customer** 👂

<!-- 
In questa slide voglio portarvi più in profondità nelle applicazioni concrete dell’NLP in ambito aziendale, mostrando esempi reali e tangibili.

Per l’analisi di mercato, vi spiegherò come l’NLP consenta di monitorare automaticamente notizie, report di settore e discussioni sui social, così da identificare tendenze emergenti e anticipare cambiamenti nel mercato prima della concorrenza.

Per l’ottimizzazione dei processi di R&D, farò l’esempio del settore farmaceutico, dove l’NLP aiuta a estrarre informazioni chiave da enormi archivi di letteratura scientifica, accelerando in modo significativo la fase di ricerca e sviluppo.

Per rendere tutto questo più concreto e memorabile, utilizzerò esempi pratici e casi di studio per ciascuna applicazione, così da farvi percepire in modo chiaro i benefici reali dell’NLP.

Infine, vi proporrò una domanda interattiva: “Quali di queste applicazioni pensate potrebbe avere il maggiore impatto nel vostro settore, e perché?”
Mi interessa sentire le vostre riflessioni e capire come vedete l’NLP calato nella vostra realtà.
-->

---

# Case Study: NLP nel customer care ☎️

Le aziende utilizzano l’NLP nel customer care per:
- Analizzare migliaia di ticket e messaggi per individuare problemi ricorrenti
- Automatizzare risposte con chatbot e assistenti virtuali, offrendo supporto 24/7
- Prioritizzare le richieste più urgenti grazie all’analisi automatica del contenuto
- Misurare il sentiment dei clienti per migliorare prodotti e servizi 

> **JPMorgan Chase**: COIN (Contract Intelligence) analizza accordi di prestito in secondi invece di 360.000 ore/anno di lavoro umano!

<!-- 
In questa slide, voglio mostrarvi come l’NLP stia rivoluzionando il customer care.

Inizio sottolineando che l’NLP permette di analizzare grandi volumi di dati non strutturati, come email, chat e recensioni, per identificare problemi ricorrenti e migliorare l’efficienza del servizio clienti.

Proseguo spiegando che l’automazione delle risposte tramite chatbot e assistenti virtuali consente di offrire supporto continuo ai clienti, riducendo i tempi di attesa e migliorando la soddisfazione.

Infine, evidenzio come l’analisi del sentiment attraverso l’NLP permetta alle aziende di comprendere meglio le esigenze dei clienti e di adattare i propri prodotti e servizi di conseguenza.

Concludo con una domanda per stimolare la riflessione: “Quali di queste applicazioni pensate potrebbe avere il maggiore impatto nel vostro settore e perché?”
-->

---

# Quiz! 🎯

Quali di questi problemi può risolvere l'NLP?

A) Classificazione automatica dei testi
B) Analisi delle immagini
C) Estrazione di informazioni da testi
D) Progettazione di circuiti elettronici
E) Analisi del sentiment

<!-- 
Le risposte corrette sono A, C ed E.

Posso usare questa domanda per introdurre la prossima sezione sui problemi risolti dall'NLP, chiedendo ai partecipanti di alzare la mano per le opzioni che ritengono corrette.

Dopo aver raccolto le risposte, posso spiegare perché alcune opzioni sono corrette e altre no, chiarendo eventuali dubbi e misconcezioni.

È un buon momento per stimolare la discussione e l'interazione, chiedendo se qualcuno vuole motivare le proprie scelte o ha domande.
-->

---

# Problemi risolti dall'NLP 🛠️

L'NLP trasforma testi non strutturati in informazioni strutturate e actionable:

- **Classificazione automatica dei testi** 📑
- **Estrazione di informazioni** 🔍
- **Analisi del sentiment** 😊😐😠
- **Risposta automatica e chatbot** 💬
- **Riassunto automatico** 📝

<!-- 
In questa slide vi presento i principali problemi che l’NLP è in grado di affrontare, quelli che possiamo considerare le categorie fondamentali dei task NLP, ognuno con tantissime applicazioni pratiche.

Li descriverò brevemente per farvi avere un quadro chiaro:
	•	Classificazione dei testi → permette di categorizzare automaticamente documenti, come ad esempio distinguere tra email urgenti e non urgenti.
	•	Estrazione di informazioni → serve a identificare ed estrarre dati specifici da testi non strutturati, come nomi, date, cifre rilevanti.
	•	Analisi del sentiment → determina l’atteggiamento o le emozioni espresse in un testo, utile ad esempio per capire come i clienti percepiscono un prodotto.
	•	Chatbot → simulano conversazioni umane per fornire assistenza o informazioni in modo automatico.
	•	Riassunto automatico → condensa testi lunghi mantenendo le informazioni essenziali, ideale per documenti, articoli o report.

Alla fine lancerò una domanda per stimolare il pensiero critico: “Quali di questi problemi ritenete più difficili da risolvere per un sistema automatico, e perché?”
Mi interessa capire su cosa secondo voi l’AI fa ancora fatica e perché.
-->

---

# Classificazione automatica dei testi 📑

- Categorizza automaticamente documenti in base al contenuto
- **Settore sanitario**: classificazione di cartelle cliniche per patologie
- **Settore legale**: categorizzazione di contratti e sentenze

<!-- 
In questa slide approfondisco la classificazione automatica dei testi, una delle applicazioni più diffuse e concrete dell’NLP.

Spiegherò che la classificazione è alla base di moltissimi sistemi di gestione documentale: permette di assegnare automaticamente categorie ai testi, usando tecniche che vanno dalle più semplici, come il Naive Bayes, fino alle più avanzate, come le reti neurali profonde.

Per rendere tutto più tangibile, porterò un esempio settoriale: nel settore sanitario, la classificazione automatica delle cartelle cliniche consente di identificare rapidamente pazienti con determinate patologie, utilissimo per studi clinici o per attività di monitoraggio epidemiologico.

Chiuderò con una domanda pratica per coinvolgervi: “Pensate a un’azienda che conoscete bene: quali tipi di documenti potrebbero beneficiare di un sistema di classificazione automatica?”
Mi interessa stimolare il ragionamento su casi concreti legati alle vostre esperienze.
-->

---

# Estrazione di informazioni 🔍

- Identifica e estrae dati specifici da testi non strutturati
- **Settore immobiliare**: estrazione di prezzo, metratura, caratteristiche da annunci
- **Media**: estrazione di entità (persone, luoghi, organizzazioni) da articoli

<!-- 
Qui mi concentro sull’estrazione di informazioni, spiegando come questa tecnica permetta di trasformare testi non strutturati in dati strutturati e utilizzabili.

Vi farò esempi concreti:
	•	Nel settore immobiliare, l’estrazione di informazioni da annunci consente di popolare automaticamente database con caratteristiche comparabili, come metratura, prezzo, posizione.
	•	Nel settore dei media, l’estrazione di entità (come persone, organizzazioni, eventi) permette di costruire knowledge graph che collegano i vari elementi citati nelle notizie, creando reti di informazioni preziose.

È importante chiarire la differenza rispetto alla classificazione: mentre la classificazione assegna un’etichetta all’intero documento (es. “spam” o “non spam”), l’estrazione di informazioni si concentra sull’individuare e prelevare elementi specifici all’interno del testo.

Infine, vi proporrò una domanda tecnica per stimolare la riflessione: “Quali sfide specifiche pensate possa incontrare un sistema di estrazione di informazioni quando lavora con testi molto informali, come post sui social media?”
Mi interessa farvi ragionare su aspetti come linguaggio ambiguo, abbreviazioni, errori o sarcasmo.
-->

---

# Analisi del sentiment 😊😐😠

- Determina atteggiamento, opinione o emozioni in un testo
- **Marketing**: monitoraggio della percezione del brand
- **Entertainment**: valutazione della reazione del pubblico

<!-- 
L’analisi del sentiment è una delle applicazioni più intuitive e diffuse dell’NLP, e merita una slide tutta sua.

Spiegherò che può essere applicata a diversi livelli di granularità:
	•	A livello di documento, classificando l’intero testo come positivo, negativo o neutro.
	•	A livello di frase, cogliendo variazioni interne al testo.
	•	A livello di aspetto, cioè identificando il sentiment verso caratteristiche specifiche di un prodotto o servizio (per esempio: “il design è fantastico, ma la batteria è deludente”).

Nel contesto del marketing, l’analisi del sentiment è utilissima per monitorare in tempo reale la percezione del brand sui social media, permettendo di identificare velocemente potenziali crisi reputazionali o, al contrario, opportunità di engagement e rafforzamento del rapporto con il pubblico.

Chiuderò con una domanda provocatoria per stimolare la riflessione: “L’ironia e il sarcasmo rappresentano una sfida significativa per l’analisi del sentiment. Come pensate che un sistema automatico possa distinguere tra un commento letteralmente positivo e uno sarcasticamente positivo?”
Questo ci porterà a ragionare sulle sfumature e le difficoltà ancora aperte in questo campo.
-->

---

# Chatbot e sistemi di risposta automatica 💬

- Simulano conversazioni umane
- **E-commerce**: assistenza nella ricerca prodotti e acquisto
- **Educazione**: tutor virtuali personalizzati

<!-- 
I chatbot sono una delle applicazioni più visibili e familiari dell’NLP: molti di voi probabilmente ci hanno già interagito.

Vi spiegherò come si è evoluta questa tecnologia: si parte dai primi sistemi, come ELIZA degli anni ’60, basati su semplici regole e pattern matching, fino ad arrivare ai moderni assistenti virtuali alimentati da modelli linguistici avanzati, capaci di gestire conversazioni molto più fluide e naturali.

È importante distinguere tra due tipi di chatbot:
	•	I chatbot task-oriented, progettati per aiutare con compiti specifici (ad esempio prenotare un volo o verificare uno stato d’ordine).
	•	I chatbot open-domain, progettati per conversazioni generali su qualsiasi argomento, come gli assistenti conversazionali evoluti.

Nel contesto dell’e-commerce, i chatbot avanzati non si limitano a rispondere a domande, ma possono guidare attivamente l’utente nel processo d’acquisto, suggerendo prodotti in base alle preferenze espresse e contribuendo ad aumentare la conversione.

Chiuderò con una domanda interattiva per coinvolgervi: “Quali caratteristiche ritenete più importanti in un chatbot dal punto di vista dell’esperienza utente?”
Mi interessa sentire cosa pensate sia cruciale: velocità, precisione, empatia, personalizzazione?
-->

---

# Riassunto automatico 📝

- Condensa testi lunghi mantenendo le informazioni essenziali
- **Ricerca accademica**: generazione di abstract
- **Informazione**: creazione di riassunti di notizie da diverse fonti


<!-- 
Il riassunto automatico è un’applicazione dell’NLP particolarmente preziosa in un’epoca in cui siamo sommersi da informazioni.

Spiegherò la differenza tra i due principali approcci:
	•	L’approccio estrattivo, che seleziona e combina frasi già presenti nel testo originale per creare un riassunto.
	•	L’approccio astrattivo, che invece genera nuove frasi, riformulando il contenuto per catturare il significato essenziale del testo, un po’ come farebbe un essere umano.

Nel contesto della ricerca accademica, il riassunto automatico aiuta i ricercatori a orientarsi in mezzo all’enorme quantità di articoli e pubblicazioni, permettendo di capire rapidamente se un paper è rilevante per il proprio lavoro.

-->

---

# Gli inizi: approcci basati su regole (1950-1980) 📚

- Esperimento Georgetown-IBM (1954): prima traduzione automatica
- Sistemi basati su regole linguistiche codificate manualmente
- ELIZA (1966): primo chatbot basato su pattern matching
- Limiti: ambiguità e complessità del linguaggio naturale

<!-- 
Qui approfondisco la prima fase dell’evoluzione dell’NLP, dominata dagli approcci simbolici o basati su regole.

Vi racconterò l’aneddoto dell’esperimento Georgetown-IBM: nel 1954 furono tradotte automaticamente più di sessanta frasi dal russo all’inglese, generando un enorme entusiasmo e ottimismo sull’idea che il problema della traduzione automatica sarebbe stato risolto in pochi anni — ottimismo che, come sappiamo, si rivelò decisamente prematuro.

Un altro esempio affascinante è ELIZA, il programma sviluppato al MIT negli anni ’60, che simulava un terapeuta rogersiano. Nonostante fosse estremamente semplice, basato solo su pattern matching e sostituzioni di testo, ELIZA riusciva a dare un’impressione sorprendente di comprensione, mostrando quanto siamo naturalmente portati ad antropomorfizzare le macchine.

Chiuderò con una domanda storica per stimolare la riflessione: “Perché pensate che i primi approcci all’NLP si siano concentrati proprio sulla traduzione automatica come applicazione principale?”
Voglio portarvi a riflettere sulle priorità scientifiche, culturali e politiche di quell’epoca.
-->

---

# Gli inizi: approcci basati su regole (1950-1980) 📚

![alt text fit](images/IBM-Georgetown.jpg)

---

# 🏰 Il "Medioevo" del NLP

## 1966–1980: Il periodo di stagnazione

- **1966**: Il rapporto ALPAC conclude che i progressi nella traduzione automatica sono deludenti.
- **Conseguenza**: drastico taglio ai finanziamenti per la ricerca NLP negli USA.
- **Risultato**: rallentamento significativo, pochi avanzamenti tecnologici.

---

## Cause della stagnazione

- **Ottimismo eccessivo** negli anni ’50–’60 sulle capacità delle macchine.
- **Limiti tecnici**: scarsità di dati e potenza computazionale insufficiente.
- **Approcci simbolici** troppo rigidi per catturare la complessità del linguaggio.

---

# L'era statistica (1980-2010) 📊

- Rivoluzione: approcci basati su probabilità invece che regole
- Modelli n-gram e Markov nascosti
- Traduzione automatica statistica di IBM
- Apprendimento da grandi corpora di testo

<!-- 
In questa slide vi parlo della seconda fase dell’evoluzione dell’NLP, quella segnata dall’adozione degli approcci statistici.

Quello che voglio farvi capire è il cambio di paradigma: invece di codificare manualmente regole linguistiche, si è iniziato a usare grandi corpora di testo per far apprendere ai sistemi modelli probabilistici del linguaggio. In pratica, sono i dati che guidano il sistema, non più le regole scritte a mano.

Per spiegarvi meglio come funziona, faccio l’esempio dei modelli n-gram: questi modelli calcolano la probabilità di una parola o di una sequenza basandosi su quante volte appaiono nei dati di addestramento. Per esempio, quanto spesso la parola “buon” è seguita da “giorno” rispetto ad altre combinazioni.

Cito anche una battuta famosa di Frederick Jelinek di IBM: “Every time I fire a linguist, the performance of our speech recognition system goes up”. Questa frase rende bene l’idea di quanto, all’epoca, gli approcci statistici si rivelassero più efficaci rispetto ai modelli basati su regole.

Alla fine vi lascio con una domanda per stimolare la riflessione: “Quali limitazioni intrinseche pensate possano avere i modelli statistici nel catturare la complessità del linguaggio naturale?”
Qui voglio portarvi a pensare a problemi come il contesto lungo, l’ambiguità e la mancanza di conoscenza del mondo, che i modelli puramente statistici non riescono a gestire bene.
-->

---

# L'era statistica (1980-2010) 📊

✅ T9 (predictive text) sui cellulari: usa modelli n-gram per prevedere la parola più probabile mentre scrivi.
✅ Correttore ortografico (tipo Word): basato su frequenze di parole e contesto per suggerire correzioni.
✅ Google Search (prima generazione): completamento automatico basato su probabilità di query comuni.
✅ Traduzione automatica IBM: modelli statistici per allineare frasi tra lingue diverse.
✅ Speech recognition primi anni: riconoscimento vocale basato su modelli nascosti di Markov.


<!-- 
Qui stiamo parlando di quella che viene chiamata l’era statistica, tra il 1980 e il 2010.

È un momento importante perché si passa da approcci basati su regole scritte a mano — tipo “se vedi questa parola fai così” — ad approcci basati su probabilità.

Per esempio, si iniziano a usare modelli come gli n-gram, che guardano alle sequenze di parole per prevedere quella successiva, oppure i modelli nascosti di Markov, che tengono conto degli stati nascosti dietro le sequenze osservate.

Un’applicazione famosa è la traduzione automatica statistica di IBM, dove il sistema non ragiona più per regole grammaticali, ma calcola le probabilità che una frase in inglese corrisponda a una frase in francese.

E soprattutto si comincia a imparare dai dati, dai grandi corpora di testo, cioè enormi raccolte di testi, anziché scrivere tutto a mano. Questo porta a un salto in avanti per tante applicazioni: il T9 dei vecchi cellulari, il correttore automatico, i motori di ricerca, i primi sistemi di riconoscimento vocale… insomma, una vera rivoluzione!
 -->

---

# La rivoluzione del deep learning (2010-presente) 🧠

- Word embeddings: Word2Vec (2013), GloVe (2014)
- Reti neurali ricorrenti (RNN, LSTM, GRU)
- 2017: Architettura Transformer ("Attention is All You Need")
- Modelli pre-addestrati: BERT, GPT
- Large Language Models (LLMs)


<!-- 
Qui entriamo nella fase più recente e rivoluzionaria dell’evoluzione dell’NLP, quella caratterizzata dall’adozione del deep learning.

Vi spiego innanzitutto l’importanza dei word embeddings, che rappresentano le parole come vettori densi in uno spazio multidimensionale. Questo approccio cattura le relazioni semantiche in modo sorprendentemente efficace.
 Un esempio classico che cito sempre è: king - man + woman = queen.

Poi sottolineo l’impatto rivoluzionario dell’architettura Transformer, introdotta nel paper Attention is All You Need di Google nel 2017. Questa architettura ha superato le limitazioni delle RNN, soprattutto nel gestire dipendenze a lungo termine, e ha reso possibile addestrare modelli sempre più grandi e potenti.

Concludo parlando dei più recenti Large Language Models, come GPT-4, evidenziando le loro capacità sorprendenti di generazione di testo, ragionamento e problem-solving, che stanno ridefinendo ciò che pensiamo sia possibile fare con l’intelligenza artificiale.

Chiudo con una domanda di riflessione: “In che modo pensate che i recenti progressi nell’NLP stiano cambiando la nostra percezione dell’intelligenza artificiale e dei suoi limiti?”
Mi interessa stimolare il ragionamento su come questi sviluppi stiano influenzando non solo la tecnologia, ma anche le aspettative sociali e culturali.
-->

---

# Timeline dell'evoluzione dell'NLP 📅

- **1954**: Esperimento Georgetown-IBM - Prima traduzione automatica
- **1966**: ELIZA - Primo chatbot basato su pattern matching
- **1980s**: Approcci statistici iniziano a sostituire i sistemi basati su regole
- **2013**: Word2Vec - Rivoluzione nella rappresentazione delle parole
- **2017**: "Attention is All You Need" - Introduzione dell'architettura Transformer
- **2018-2023**: Era dei modelli pre-addestrati e LLMs (BERT, GPT, ecc.)

<!-- 
Questa timeline riassume i punti chiave dell'evoluzione dell'NLP, fornendo una visione d'insieme cronologica che aiuta a consolidare quanto spiegato nelle slide precedenti.

Posso sottolineare come l'evoluzione dell'NLP abbia subito un'accelerazione notevole negli ultimi anni, con progressi che hanno superato le aspettative anche degli esperti del settore.

È interessante notare come alcuni problemi che sembravano quasi impossibili da risolvere con gli approcci precedenti (come la traduzione di alta qualità o la generazione di testo coerente) siano stati affrontati con successo grazie ai recenti sviluppi.

Domanda per stimolare la discussione: "Guardando questa timeline, quali tendenze notate nell'evoluzione dell'NLP e come pensate che queste potrebbero continuare nel futuro?"
-->

---

# Evuluzione degli LLM ⏳

![width:900px](images/history.jpg)

https://arxiv.org/pdf/2303.18223

<!-- 
In questa slide introduco il tema dell’evoluzione storica dell’NLP. Lo sfondo mostra una timeline che ci aiuta a visualizzare il percorso evolutivo di questa disciplina.

Spiego perché è importante guardare a questa evoluzione: non solo per interesse storico, ma perché ci permette di contestualizzare le capacità attuali e, ancora più interessante, immaginare le possibilità future.

Voglio sottolineare che il cammino dell’NLP non è stato lineare: ci sono stati periodi di grande entusiasmo, seguiti da veri e propri “inverni dell’AI”, con calo di interesse e finanziamenti, e poi fasi di rinascita grazie a nuovi approcci e innovazioni tecnologiche.

Alla fine lancerò una domanda per stimolare la curiosità: “Secondo voi, quali eventi o innovazioni tecnologiche hanno maggiormente influenzato l’evoluzione dell’NLP?”
Mi interessa sentire quali passaggi storici, secondo voi, sono stati davvero decisivi.
-->

---

# Sfide attuali nell'NLP 🧗‍♀️

**Anche i giganti hanno i loro talloni d'Achille!**

Nonostante i progressi straordinari, l'NLP continua ad affrontare sfide significative che riflettono la complessità intrinseca del linguaggio umano:

- **Ambiguità linguistica** 🤔
  *Quando "la vecchia porta la sbarra" può significare due cose completamente diverse*
- **Multilingualità e localizzazione** 🌍
  *Perché tradurre "sono al verde" in inglese letteralmente sarebbe un disastro*
- **Comprensione del contesto e conoscenza del mondo** 🧠
  *Capire che "ho preso un granchio" potrebbe non avere nulla a che fare con i crostacei*

<!-- 
In questa slide vi parlo delle principali sfide che l’NLP deve ancora affrontare, nonostante tutti i progressi incredibili degli ultimi anni.

Quello che voglio farvi capire è che capire queste sfide è fondamentale: ci aiuta a usare l’NLP in modo responsabile e ci permette di intravedere le direzioni future della ricerca e dello sviluppo.

Voglio sottolineare che non stiamo parlando solo di problemi tecnici da risolvere: queste sfide derivano dalla complessità profonda del linguaggio umano e della comunicazione. Sono difficoltà che ci ricordano quanto il linguaggio sia intrecciato con il pensiero, la cultura, il contesto, le emozioni.

Alla fine vi faccio una domanda provocatoria per stimolare la vostra riflessione: “Quali di queste sfide ritenete più difficili da superare, e perché? Secondo voi, ci sono limiti fondamentali che i sistemi NLP potrebbero non essere mai in grado di superare?”
Mi piacerebbe sentire le vostre idee, i vostri dubbi, e capire insieme fin dove possiamo realisticamente spingerci.
-->

---

# Sfide attuali nell'NLP 🧗‍♀️

- **Robustezza e generalizzazione** 💪
  *Sistemi che crollano se scrivi "gattto" invece di "gatto"*
- **Efficienza computazionale e sostenibilità** ♻️
  *Modelli che consumano energia come una piccola città*

<!-- 
Qui vi introduco le principali sfide che l’NLP deve ancora affrontare, anche dopo tutti i progressi straordinari degli ultimi anni.

Voglio farvi capire perché conoscere queste sfide è così importante: non solo ci permette di usare l’NLP in modo responsabile, ma ci aiuta anche a intuire dove andrà la ricerca e lo sviluppo nei prossimi anni.

E voglio sottolineare un punto chiave: queste sfide non sono solo questioni tecniche da risolvere. Riflettono la profonda complessità del linguaggio umano, che non è fatto solo di parole, ma anche di contesto, emozioni, cultura, intenzioni.
-->

---

# Ambiguità linguistica 🤔

**Il mal di testa dei sistemi NLP!**

- Ambiguità a vari livelli:
  - **Lessicale** (parole con più significati)
    *"Amo la pesca" - Il frutto o l'attività sportiva?* 🍑🎣
  - **Sintattico** (strutture frasali ambigue)
    *"Ho visto la ragazza con il binocolo" - Chi aveva il binocolo?*
  - **Semantico** (significati multipli di una frase)
    *"Visiting professors can be boring" - I professori in visita possono annoiarsi o essere noiosi?*
  - **Pragmatico** (intenzioni comunicative non esplicite)
    *"Hai l'ora?" - Richiesta di informazione o richiesta di prestare l'orologio?*

<!-- 
Qui voglio approfondire con voi la sfida dell’ambiguità linguistica, che è una delle più difficili e fondamentali per l’NLP.

Prendiamo l’esempio classico: “Ho visto l’uomo con il telescopio”.
Questa frase può voler dire che io ho usato un telescopio per vedere l’uomo, oppure che ho visto un uomo che aveva un telescopio. La stessa sequenza di parole, ma due interpretazioni completamente diverse.

Noi umani risolviamo queste ambiguità quasi automaticamente, grazie al contesto, alla conoscenza del mondo e al buon senso. Ma per un sistema NLP questo rimane ancora un ostacolo enorme, perché manca di quei riferimenti impliciti che noi diamo per scontati.

Anche i modelli più avanzati possono sbagliare quando l’ambiguità è sottile o quando il contesto non è chiaramente espresso.

Per coinvolgervi vi faccio una domanda interattiva: “Potete pensare ad altri esempi di frasi ambigue nella vostra lingua? E come pensate che un sistema NLP potrebbe tentare di disambiguarle?”
Mi piacerebbe raccogliere i vostri esempi e ragionarci insieme!
-->

---

# Ambiguità linguistica 🤔

> - "Ho visto l'uomo con il telescopio" 🔭
> - Ho usato un telescopio per vedere l'uomo?
> - Ho visto un uomo che aveva un telescopio?

**Domanda interattiva:** Potete pensare ad altri esempi di frasi ambigue nella vostra lingua? Come potrebbe un sistema NLP tentare di disambiguarle? 🧩

---

# Multilingualità e localizzazione 🌍

**Perché l'NLP non parla solo inglese!**

- **Sviluppare sistemi NLP efficaci in tutte le lingue**
  *L'inglese rappresenta solo il 25% di internet, ma riceve il 90% delle risorse di ricerca*

- **Sfida particolare per lingue con risorse limitate**
  *Delle 7.000+ lingue parlate nel mondo, solo circa 100 hanno risorse NLP sufficienti*

---

# Multilingualità e localizzazione 🌍

- **La localizzazione va oltre la traduzione**:
  - **Espressioni idiomatiche**: *"Costare un occhio della testa" ≠ "Cost an eye of the head"* 👁️
  - **Riferimenti culturali**: *Capire cosa significa "fare il Fantozzi" in Italia* 🇮🇹
  - **Norme comunicative**: *In giapponese, i livelli di formalità cambiano completamente la struttura della frase* 🇯🇵

**Domanda di riflessione:** In che modo le differenze culturali possono influenzare l'efficacia di un sistema NLP quando viene applicato in contesti linguistici diversi? 🌐


<!-- 
In questa slide vi parlo della sfida della multilingualità e localizzazione, che è sempre più centrale in un mondo globalizzato.

Vi spiego che mentre l’inglese e poche altre lingue principali hanno enormi quantità di dati per addestrare modelli NLP, la maggior parte delle circa 7.000 lingue parlate nel mondo ha pochissime risorse disponibili. Questo crea un forte squilibrio.

Ma voglio sottolineare che la localizzazione non è solo traduzione parola per parola: un sistema NLP davvero efficace deve comprendere e rispettare le differenze culturali, le espressioni idiomatiche e le norme comunicative di ogni lingua e cultura. Un esempio semplice: tradurre “costare un occhio della testa” letteralmente in inglese non avrebbe alcun senso.

Alla fine vi lascio con una domanda di riflessione: “In che modo pensate che le differenze culturali possano influenzare l’efficacia di un sistema NLP quando viene applicato in contesti linguistici e culturali diversi?”
Sono curioso di sentire le vostre opinioni e ragionare insieme su quanto la lingua sia legata alla cultura.
-->

---

# Comprensione del contesto e conoscenza del mondo 

I modelli NLP spesso mancano di:
  - **Comprensione del contesto più ampio**
    *Capire che "è freddo" significa cose diverse in estate o in inverno*
  - **Conoscenza del mondo data per scontata dagli umani**
    *Sapere che le persone non possono volare, che l'acqua è bagnata, che il sole sorge a est...*
  - **Capacità di fare inferenze basate su common sense**
    *"Ho lasciato il gelato fuori dal freezer" → "probabilmente si è sciolto"*

> "Non posso accedere al mio account dopo l'aggiornamento di ieri"
> Un sistema NLP dovrebbe capire che "l'aggiornamento" si riferisce probabilmente a un software e potrebbe essere la causa del problema.

<!-- 
Qui voglio esplorare con voi la sfida della comprensione del contesto e della conoscenza del mondo, che è una delle più profonde e delicate nell’NLP.

Gli esseri umani comunicano dando per scontata un’enorme quantità di conoscenze implicite: sappiamo cose sul mondo, sulle cause e gli effetti, sulle relazioni tra eventi, anche quando non vengono dette esplicitamente. I sistemi NLP, invece, hanno accesso solo alle informazioni scritte nei dati o a quelle su cui sono stati addestrati.

Prendiamo l’esempio: “Non posso accedere al mio account dopo l’aggiornamento di ieri”. Un umano capisce subito che si parla probabilmente di un aggiornamento software e collega questa informazione al problema di accesso. Un sistema NLP, invece, senza un contesto più ampio o conoscenza di base, potrebbe non cogliere questa connessione.

Vi lascio quindi una domanda tecnica su cui riflettere: “Quali approcci pensate possano aiutare i sistemi NLP a sviluppare una migliore comprensione del contesto e della conoscenza del mondo?”
Sono curioso di sentire le vostre idee, soprattutto su come possiamo colmare questo gap tra ciò che è scritto e ciò che è implicito.
-->

---

# Comprensione del contesto e conoscenza del mondo 

**Esempio divertente:** Se dico "Ho preso un caffè con mia sorella, era davvero amaro", un umano capisce che era amaro il caffè, non mia sorella! 😅

**Domanda tecnica:** Quali approcci potrebbero aiutare i sistemi NLP a sviluppare una migliore comprensione del contesto e della conoscenza del mondo? 🌐

<!-- 
Qui esploro la sfida della comprensione del contesto e della conoscenza del mondo, una delle più profonde nell'NLP.

Posso spiegare che gli esseri umani comunicano facendo affidamento su un'enorme quantità di conoscenza condivisa e implicita sul mondo, che non viene esplicitamente menzionata nei testi. I sistemi NLP, invece, hanno accesso solo alle informazioni esplicitamente fornite o a quelle su cui sono stati addestrati.

L'esempio della frase sul problema di accesso dopo un aggiornamento illustra bene questa sfida: un umano comprende immediatamente che si tratta probabilmente di un aggiornamento software e che questo potrebbe essere causalmente collegato al problema di accesso, mentre un sistema NLP potrebbe non fare questa connessione.

Domanda tecnica: "Quali approcci pensate possano aiutare i sistemi NLP a sviluppare una migliore comprensione del contesto e della conoscenza del mondo?"

Per aiutare i sistemi NLP a sviluppare una migliore comprensione del contesto e della conoscenza del mondo, si possono usare modelli ibridi che combinano grandi modelli linguistici con knowledge graph esterni o basi di conoscenza strutturate (come Wikidata), così da arricchire il ragionamento con fatti e relazioni reali.

Inoltre, approcci come il retrieval-augmented generation (RAG) permettono al sistema di recuperare in tempo reale informazioni aggiornate da fonti esterne, anziché basarsi solo su ciò che è stato appreso in fase di addestramento.

Infine, per il contesto locale nella conversazione, servono meccanismi di memoria conversazionale che mantengano traccia di ciò che è stato detto prima, così il modello non lavora solo sulla singola frase, ma sull’intero scambio.
-->

---

# Robustezza e generalizzazione 💪

- I modelli NLP possono degradarsi significativamente con:
  - Input fuori distribuzione
  - Errori ortografici
  - Gergo specialistico
  - Linguaggio non standard
- Vulnerabilità ad attacchi adversarial

<!-- 
In questa slide affronto la sfida della robustezza e generalizzazione dei modelli NLP.

Posso spiegare che i modelli tendono a performare bene sui dati simili a quelli su cui sono stati addestrati, ma possono degradarsi significativamente quando confrontati con input che deviano da questa distribuzione.

È interessante discutere il concetto di "adversarial attacks" nel contesto dell'NLP: input appositamente progettati per ingannare i modelli, che possono rappresentare una vulnerabilità significativa in applicazioni critiche.

Posso fare esempi concreti di come piccole modifiche al testo (come errori di battitura o uso di sinonimi inusuali) possano confondere anche modelli molto sofisticati.

Domanda di sicurezza: "Quali implicazioni pensate possa avere questa vulnerabilità per applicazioni critiche dell'NLP, come sistemi di moderazione dei contenuti o assistenti virtuali in ambito sanitario?"
-->

---

# Efficienza computazionale e sostenibilità ♻️

- I modelli NLP più avanzati richiedono risorse enormi:
  - Addestramento di GPT-3: energia equivalente a centinaia di case americane in un anno
- Questioni di:
  - Accessibilità (democratizzazione della tecnologia)
  - Sostenibilità ambientale
  - Implementazione su dispositivi edge

<!-- 
In questa slide affronto la sfida dell'efficienza computazionale e della sostenibilità, un tema sempre più rilevante con la crescita esponenziale delle dimensioni dei modelli.

Posso citare dati concreti sul consumo energetico dell'addestramento di modelli come GPT-3, evidenziando le implicazioni ambientali di questa tendenza.

È importante discutere anche le questioni di accessibilità: se solo grandi organizzazioni con enormi risorse computazionali possono sviluppare modelli all'avanguardia, questo crea un divario tecnologico che potrebbe avere conseguenze sociali ed economiche significative.

Posso menzionare gli sforzi di ricerca in corso per sviluppare modelli più efficienti, come la distillazione della conoscenza, la quantizzazione e l'ottimizzazione degli algoritmi.

Domanda etica: "Come possiamo bilanciare il desiderio di modelli sempre più potenti con la necessità di sostenibilità ambientale e accessibilità democratica della tecnologia?"
-->

---

# Applicazioni emergenti dell'NLP 🚀

**Il futuro è già qui, solo non è ancora uniformemente distribuito!**

Nuove ed entusiasmanti direzioni di sviluppo stanno ridefinendo i confini dell'NLP:

- **NLP multimodale** 🖼️🔊
  *Sistemi che vedono, ascoltano e parlano: "Descrivi questa immagine e trasforma la descrizione in una canzone"*

- **Agenti conversazionali avanzati** 🤖
  *Da semplici chatbot a veri assistenti che ricordano le conversazioni passate e si adattano alle tue preferenze*

- **NLP per lingue a basse risorse** 🌏
  *Democratizzare l'NLP per le 7.000+ lingue del mondo, non solo per le 10 più parlate*

<!-- 
Qui vi parlo delle applicazioni emergenti dell’NLP, mostrando come, nonostante tutte le sfide che abbiamo visto finora, questo campo continui a evolversi e a spingersi oltre i suoi confini.

Vi spiego che queste nuove direzioni non solo cercano di affrontare i problemi ancora aperti, ma aprono anche a possibilità e opportunità completamente nuove in tanti settori diversi: dalla sanità all’educazione, dalla creatività digitale alla giustizia sociale.

Voglio sottolineare che molte di queste applicazioni non portano solo vantaggi commerciali, ma hanno anche il potenziale di creare un impatto sociale positivo davvero significativo, contribuendo a rendere la tecnologia più inclusiva, accessibile e utile per tutti.

Alla fine vi lancio una domanda visionaria: “Quali di queste applicazioni emergenti pensate possa avere il maggiore impatto sulla società nei prossimi 5-10 anni, e perché?”
Mi piacerebbe sentire le vostre idee e riflettere insieme su quale futuro ci stiamo preparando.
-->

---

# NLP multimodale 🖼️🔊

- Integra l'elaborazione del linguaggio con altre modalità:
  - Immagini
  - Video
  - Audio
- **Retail**: analisi combinata di recensioni testuali e immagini dei prodotti
- **Sanità**: correlazione tra sintomi descritti e pattern visibili nelle immagini mediche

<!-- 
Qui approfondisco l'NLP multimodale, una delle direzioni più promettenti e in rapida evoluzione.

Posso spiegare che l'NLP multimodale cerca di superare i limiti dell'elaborazione puramente testuale, integrando informazioni da diverse modalità per una comprensione più ricca e contestuale.

È interessante discutere modelli come CLIP di OpenAI, che possono comprendere sia testo che immagini e le relazioni tra di essi, o modelli come Whisper che integrano riconoscimento vocale e comprensione del linguaggio.

Nel contesto retail, posso illustrare come l'analisi combinata di recensioni testuali e immagini dei prodotti possa fornire insights più completi sulla soddisfazione dei clienti e sui problemi specifici.

Domanda tecnica: "Quali sfide specifiche pensate si presentino nell'integrare diverse modalità di informazione in un unico sistema NLP?"
-->

---

# Agenti conversazionali avanzati 🤖

- Evoluzione da semplici chatbot a sistemi sofisticati:
  - Conversazioni estese e contestuali
  - Comprensione di intenzioni complesse
  - Memoria delle interazioni precedenti
  - Adattamento al feedback dell'utente
- **Educazione**: tutor personalizzati
- **Salute mentale**: supporto iniziale e gestione dello stress

<!-- 
In questa slide esploro l'evoluzione degli agenti conversazionali, che stanno diventando sempre più sofisticati e capaci.

Posso spiegare la differenza tra i primi chatbot basati su regole o intent matching e i moderni agenti conversazionali basati su LLMs, che possono mantenere conversazioni molto più naturali, contestuali e adattive.

Nel contesto educativo, posso illustrare come tutor virtuali avanzati possano adattare le spiegazioni al livello di comprensione dello studente, ponendo domande per verificare la comprensione e fornendo feedback costruttivo.

È importante discutere anche i limiti etici e pratici di questi sistemi, specialmente in contesti sensibili come la salute mentale, dove possono fornire supporto iniziale ma non sostituire professionisti umani.

Domanda etica: "Quali confini pensate dovrebbero essere stabiliti nell'uso di agenti conversazionali in contesti sensibili come la salute o l'educazione?"
-->

---

# NLP per lingue a basse risorse 🌏

- Tecniche per lingue con pochi dati di addestramento:
  - Transfer learning multilingue
  - Few-shot learning
  - Generazione di dati sintetici
- **Conservazione culturale**: preservazione di lingue minoritarie
- **Settore umanitario**: comunicazione durante crisi in regioni con lingue locali

<!-- 
In questa slide affronto il tema dell'NLP per lingue a basse risorse, un'area di ricerca emergente con importanti implicazioni sociali e culturali.

Posso spiegare che mentre lingue come l'inglese, il cinese o lo spagnolo dispongono di enormi quantità di dati per l'addestramento di modelli NLP, la maggior parte delle lingue del mondo ha risorse molto limitate, creando un divario tecnologico significativo.

È interessante discutere tecniche come il transfer learning multilingue, che permette di trasferire conoscenze da modelli addestrati su lingue ricche di risorse a lingue con risorse limitate.

Nel contesto della conservazione culturale, posso illustrare come queste tecniche possano aiutare a preservare e rendere accessibili lingue minoritarie o a rischio di estinzione.

Domanda di riflessione: "In che modo pensate che la disponibilità di tecnologie NLP per tutte le lingue, non solo quelle dominanti, possa influenzare la diversità linguistica e culturale globale?"
-->

---

# NLP interpretabile e spiegabile 🔍

- Modelli capaci di fornire giustificazioni comprensibili per le loro previsioni
- **Settore legale**: riferimenti specifici a precedenti o normative
- **Settore finanziario**: spiegabilità per valutazione del rischio e identificazione frodi


<!-- 
In questa slide vi parlo del tema sempre più centrale dell’NLP interpretabile e spiegabile, soprattutto quando questi sistemi vengono usati in contesti critici.

Vi spiego la differenza fondamentale tra performance e interpretabilità: i modelli più complessi e potenti spesso danno prestazioni migliori, ma funzionano come vere e proprie black box, difficili da capire anche per gli esperti. Questo diventa un problema serio in situazioni dove le decisioni devono essere motivate e giustificate.

Per esempio, nel settore legale, un sistema NLP spiegabile non dovrebbe limitarsi a dire “raccomando questa sentenza”, ma dovrebbe anche fornire riferimenti chiari ai precedenti o alle normative su cui basa la sua raccomandazione, così che un avvocato possa verificarla.

DeepSeek-Prover-V2: avanzare il ragionamento matematico formale attraverso il reinforcement learning per la decomposizione in sotto-obiettivi.
-->

---

# Pensate a questo... 🤔

> "Il linguaggio è la casa dell'essere."
> - Martin Heidegger

Se il linguaggio definisce la nostra esperienza umana...
cosa significa creare macchine che lo comprendono?

<!-- 
Questa slide più filosofica serve a stimolare una riflessione più profonda sul significato dell'NLP e sulle sue implicazioni.

Posso utilizzare la citazione di Heidegger per introdurre l'idea che il linguaggio non è semplicemente uno strumento di comunicazione, ma il mezzo attraverso cui comprendiamo e diamo senso al mondo.

Questa prospettiva solleva domande affascinanti: se il linguaggio è così fondamentale per l'esperienza umana, cosa significa creare macchine che possono comprenderlo e generarlo? Stiamo in qualche modo condividendo con le macchine qualcosa di profondamente umano?

È un momento per stimolare una discussione più ampia sulle implicazioni filosofiche, etiche e sociali dell'NLP, andando oltre gli aspetti puramente tecnici.

Domanda provocatoria: "Se una macchina può comprendere e generare linguaggio in modo indistinguibile da un umano, questo cambia in qualche modo la vostra percezione di cosa significhi essere umani?"
-->

---

# Conclusione 🏁

- L'NLP è una frontiera in rapida evoluzione dell'IA
- Trasforma il modo in cui interagiamo con le macchine e le organizzazioni operano
- Sfide significative rimangono, ma nuove applicazioni continuano a emergere
- Comprendere fondamenti, capacità e limiti è essenziale per sfruttarne il potenziale

<!-- 
In questa slide conclusiva, riassumo i punti chiave del modulo e lascio i partecipanti con alcune riflessioni finali.

Posso sottolineare come l'NLP rappresenti una delle frontiere più affascinanti e in rapida evoluzione dell'intelligenza artificiale, con implicazioni profonde per il modo in cui interagiamo con la tecnologia e per come le organizzazioni operano.

È importante ricordare che, nonostante i progressi straordinari, sfide significative rimangono, e che comprendere i fondamenti, le capacità e i limiti dell'NLP è essenziale per sfruttarne efficacemente il potenziale.

Posso concludere con la citazione di Steven Pinker, che suggerisce una connessione profonda tra linguaggio e pensiero, e invitare i partecipanti a continuare a esplorare questo affascinante campo.

Domanda finale: "Quali aspetti dell'NLP vi hanno colpito di più e quali vorreste approfondire nei prossimi moduli?"
-->

---

# Riferimenti e approfondimenti 📚

- Jurafsky, D., & Martin, J. H. (2023). Speech and Language Processing (3rd ed. draft). [https://web.stanford.edu/~jurafsky/slp3/](https://web.stanford.edu/~jurafsky/slp3/)
- Vaswani, A., et al. (2017). Attention is All You Need. Advances in Neural Information Processing Systems, 30.
- Devlin, J., et al. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Proceedings of NAACL-HLT 2019.

<!-- 
In questa slide finale fornisco riferimenti bibliografici e risorse per l'approfondimento.

Posso sottolineare l'importanza del libro di Jurafsky e Martin, che rappresenta una risorsa fondamentale per chiunque voglia approfondire l'NLP, costantemente aggiornata per riflettere gli sviluppi più recenti.

Posso anche evidenziare l'importanza storica del paper "Attention is All You Need" che ha introdotto l'architettura Transformer, rivoluzionando il campo dell'NLP.

È utile menzionare che questi riferimenti coprono sia gli aspetti fondamentali e teorici dell'NLP, sia gli sviluppi più recenti e all'avanguardia.

Posso concludere invitando i partecipanti a esplorare queste risorse per approfondire gli argomenti che hanno trovato più interessanti durante il modulo.
-->

---

# Domande? 🙋‍♀️🙋‍♂️

![bg right:60% 80%](https://source.unsplash.com/random/800x600/?questions)

<!-- 
Questa slide finale è dedicata alle domande dei partecipanti.

È importante lasciare tempo sufficiente per le domande, in quanto spesso è durante questa fase che emergono le connessioni più interessanti e i chiarimenti più utili.

Posso incoraggiare domande di vario tipo: chiarimenti su concetti specifici, approfondimenti su applicazioni particolari, o riflessioni più ampie sulle implicazioni dell'NLP.

Se le domande non emergono spontaneamente, posso avere pronte alcune domande provocatorie per stimolare la discussione, come "Quali applicazioni dell'NLP pensate avranno il maggiore impatto sulla vostra vita quotidiana nei prossimi anni?" o "Quali aspetti etici dell'NLP vi preoccupano maggiormente?".

È un buon momento per fare collegamenti con i moduli successivi, anticipando come gli argomenti che verranno trattati si baseranno su quanto appreso in questo modulo introduttivo.
-->
