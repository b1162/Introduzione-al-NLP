---
marp: true
theme: default
paginate: true
---

# Modulo 3: Classificazione del Testo e Analisi del Sentiment ğŸ·ï¸ğŸ˜Š
### Corso di Natural Language Processing

<!-- 
In questa prima slide, introduco il tema centrale del modulo: la classificazione del testo e l'analisi del sentiment.

Punti da enfatizzare:
- Queste sono tra le applicazioni piÃ¹ pratiche e diffuse del NLP
- Hanno un impatto diretto sul business in quasi tutti i settori
- Rappresentano spesso il primo passo nell'implementazione di soluzioni NLP avanzate

Possibile domanda per la platea: "Chi di voi ha giÃ  utilizzato o incontrato sistemi di classificazione testuale nella vita quotidiana?" (esempi: filtri spam, categorizzazione di notizie, analisi delle recensioni)
-->

---

# ğŸ“‹ Contenuti del modulo

- ğŸ·ï¸ **Classificazione del testo**: concetti fondamentali
- ğŸ§® **Approcci tradizionali**: Naive Bayes, SVM, Logistic Regression
- ğŸ§  **Approcci neurali**: RNN, CNN, Transformer
- ğŸ˜Š **Analisi del sentiment**: teoria e sfide specifiche
- ğŸ’¼ **Applicazioni pratiche** in contesti aziendali
- ğŸ› ï¸ **Implementazione e considerazioni etiche**

<!-- 
Questa slide offre una panoramica completa degli argomenti che tratteremo.

Punti da enfatizzare:
- Il modulo segue un percorso logico: dalla teoria di base agli approcci avanzati
- Copre sia metodi classici che neurali, mostrando l'evoluzione del campo
- Include aspetti pratici e considerazioni etiche, non solo teoria

Possibile domanda: "Quali di questi argomenti vi interessa di piÃ¹ e perchÃ©?"
-->

---

# ğŸ·ï¸ Classificazione del testo: concetti fondamentali

> "La classificazione del testo Ã¨ il processo di assegnazione di categorie predefinite a documenti testuali."

- ğŸ“ **Input**: documento testuale (email, recensione, articolo, tweet...)
- ğŸ·ï¸ **Output**: una o piÃ¹ categorie/etichette
- ğŸ¯ **Obiettivo**: generalizzare dai dati di addestramento a nuovi documenti
- ğŸ”„ **Processo**: supervisionato (richiede esempi etichettati)

<!-- 
Questa slide introduce il concetto base di classificazione testuale.

Punti da enfatizzare:
- La classificazione Ã¨ un problema di apprendimento supervisionato
- La qualitÃ  e quantitÃ  dei dati etichettati Ã¨ cruciale per il successo
- A differenza di altri task NLP, qui abbiamo categorie predefinite
- Il vero valore sta nella capacitÃ  di generalizzare a nuovi documenti mai visti

Esempio concreto da menzionare: "Pensate a Gmail che classifica automaticamente le email in Primaria, Social, Promozioni - questo Ã¨ un classico esempio di classificazione multi-classe."

Possibile domanda: "Quali sono secondo voi le sfide principali nel creare un buon dataset etichettato per la classificazione?"
-->

---

# ğŸ·ï¸ Tipi di problemi di classificazione

- 0ï¸âƒ£1ï¸âƒ£ **Classificazione binaria**: due classi (spam/non-spam)
- ğŸ”¢ **Classificazione multi-classe**: piÃ¹ classi mutuamente esclusive (categorie di notizie)
- ğŸ·ï¸ **Classificazione multi-label**: piÃ¹ etichette contemporaneamente (tag di un articolo)
- ğŸ“Š **Classificazione gerarchica**: categorie organizzate in struttura ad albero

<!-- 
Questa slide distingue i diversi tipi di problemi di classificazione.

Punti da enfatizzare:
- La complessitÃ  aumenta passando da binaria a multi-label
- Ogni tipo richiede approcci e metriche di valutazione specifici
- La scelta del tipo dipende dall'applicazione e dai requisiti aziendali

Esempio pratico: "Un articolo di news puÃ² appartenere solo alla categoria 'Sport' (multi-classe) o contemporaneamente a 'Tecnologia' e 'Business' (multi-label)."

Possibile domanda: "Quali applicazioni aziendali potrebbero richiedere una classificazione multi-label invece che multi-classe?"
-->

---

# ğŸ§® Pipeline di classificazione del testo

![width:900px](https://miro.medium.com/max/1400/1*Vc4sWZDFO74iU3gn5CGILw.png)

1. ğŸ“¥ **Raccolta dati** etichettati
2. ğŸ§¹ **Preprocessing** del testo
3. ğŸ” **Feature extraction**
4. ğŸ§  **Addestramento** del modello
5. ğŸ“Š **Valutazione** delle performance
6. ğŸš€ **Deployment** in produzione

<!-- 
Questa slide illustra il workflow completo della classificazione testuale.

Punti da enfatizzare:
- Ãˆ un processo iterativo, non lineare
- Ogni fase ha un impatto significativo sul risultato finale
- Il preprocessing e la feature extraction sono cruciali quanto l'algoritmo stesso
- La valutazione deve guidare il miglioramento continuo

Approfondimento: "Il preprocessing puÃ² includere tokenizzazione, rimozione di stopwords, stemming o lemmatizzazione. La feature extraction puÃ² variare da semplici bag-of-words a sofisticati word embeddings."

Possibile domanda: "Quale fase ritenete piÃ¹ critica per il successo di un sistema di classificazione testuale e perchÃ©?"
-->

---

# ğŸ§¹ Preprocessing e Feature Extraction

### âœ‚ï¸ Preprocessing

- ğŸ”¤ **Tokenizzazione** â†’ dividere il testo in parole o token  
- ğŸ“ **Normalizzazione** â†’ minuscolo, rimozione punteggiatura  
- ğŸš« **Rimozione stopwords** â†’ eliminare parole comuni (â€œilâ€, â€œlaâ€, â€œeâ€...)  
- ğŸŒ± **Stemming / Lemmatizzazione** â†’ ridurre alla forma base (es. â€œcorrendoâ€ â†’ â€œcorrereâ€)

<!-- 
Commento speaker:
Qui spieghiamo come â€œpuliamoâ€ il testo per prepararlo allâ€™analisi.
Sono operazioni semplici ma fondamentali per ridurre rumore e standardizzare.
-->

---

### ğŸ” Feature Extraction

- ğŸ§® **Bag-of-Words (BoW)** â†’ conta quante volte appaiono le parole  
- ğŸ“Š **TF-IDF** â†’ pesa parole frequenti nel testo ma rare nei documenti  
- ğŸ”¤ **N-grams** â†’ sequenze di N parole consecutive  
- ğŸ§  **Word Embeddings** â†’ vettori densi (Word2Vec, GloVe, FastText)  
- ğŸ”„ **Embeddings contestuali** â†’ modelli avanzati (BERT, RoBERTa) che capiscono il contesto

<!-- 
Commento speaker:
Qui mostriamo come trasformiamo il testo in numeri.
Si parte da metodi piÃ¹ semplici (BoW, TF-IDF) a metodi piÃ¹ avanzati come gli embeddings,
che catturano significato e contesto.
-->

---

### â„¹ï¸ Note importanti

- Il preprocessing â€œpulisceâ€ il testo per prepararlo allâ€™analisi  
- La feature extraction trasforma il testo in numeri per i modelli  
- Si Ã¨ passati da metodi semplici e sparsi (BoW, TF-IDF) a metodi densi e complessi (embeddings)  
- âš ï¸ Esempio:  
  BoW â†’ â€œil cane morde lâ€™uomoâ€ â‰ˆ â€œlâ€™uomo morde il caneâ€  
  BERT â†’ distingue lâ€™ordine e il significato

<!-- 
Commento speaker:
Sottolineare che il preprocessing viene prima e la feature extraction dopo.
Fornire lâ€™esempio delle frasi per mostrare i limiti di BoW e la potenza degli embeddings.
-->

---

### ğŸ’¬ Domanda possibile

ğŸ‘‰ In quali casi conviene usare **BoW** invece di embeddings avanzati?

<!-- 
Commento speaker:
Stimolare la riflessione: BoW puÃ² essere utile in problemi semplici,
con pochi dati o quando servono modelli interpretabili.
-->

---

# ğŸ§® Approcci tradizionali: Naive Bayes

- ğŸ“Š Basato sul teorema di Bayes con assunzione di indipendenza
- ğŸ§® $P(y|x) \propto P(y) \prod_{i=1}^{n} P(x_i|y)$
- ğŸš€ Veloce, efficiente, poco costoso computazionalmente
- ğŸ‘ Funziona sorprendentemente bene per classificazione testuale

**Varianti**:
- ğŸ”¢ **Multinomial NB**: conta le occorrenze (per BoW)
- 0ï¸âƒ£1ï¸âƒ£ **Bernoulli NB**: presenza/assenza di feature (per testi brevi)
- ğŸ“ˆ **Gaussian NB**: per feature continue

<!-- 
Commento speaker:
Questa slide introduce Naive Bayes, uno degli algoritmi piÃ¹ semplici ma sorprendentemente efficaci. 
Il punto centrale da sottolineare Ã¨ che, anche se fa unâ€™assunzione ingenua di indipendenza tra le parole 
(ad esempio tratta â€œgattoâ€ e â€œneroâ€ come indipendenti, ignorando che â€œneroâ€ Ã¨ piÃ¹ probabile dopo â€œgattoâ€ 
che dopo altre parole), riesce comunque a dare ottimi risultati.

Ãˆ spesso usato come baseline per confrontare modelli piÃ¹ complessi, 
funziona molto bene su dataset piccoli e ha il vantaggio di essere estremamente veloce 
sia in fase di addestramento che di inferenza.

Domanda da lanciare al pubblico:
â€œPerchÃ© secondo voi un algoritmo cosÃ¬ semplice e con assunzioni irrealistiche funziona 
cosÃ¬ bene nella pratica per la classificazione testuale?â€
-->

---

# ğŸ§® Approcci tradizionali: Support Vector Machine (SVM)

![bg right:40% 80%](images/Support_vector_machine.png)

- ğŸ“ Trova l'iperpiano ottimale che separa le classi
- ğŸ” Massimizza il margine tra le classi
- ğŸ’ª Molto efficace per testi, specialmente con feature TF-IDF
- âš ï¸ PuÃ² essere lento su dataset molto grandi

<!-- 
Commento speaker:
Questa slide presenta le Support Vector Machine (SVM), un algoritmo molto potente per la classificazione. 
Il punto chiave Ã¨ che SVM cerca il confine decisionale ottimale tra le classi, 
massimizzando il margine, cioÃ¨ la distanza tra i punti piÃ¹ vicini delle classi opposte. 
Questo aiuta molto la capacitÃ  di generalizzazione del modello.

Un elemento importante Ã¨ il cosiddetto â€œkernel trickâ€: 
permette di trattare problemi non lineari mappando i dati in uno spazio a dimensione superiore, 
senza dover calcolare esplicitamente questa trasformazione.

Da ricordare che SVM funziona particolarmente bene con dati ad alta dimensionalitÃ , come il testo (es. con feature TF-IDF), 
ma puÃ² diventare lento su dataset molto grandi.

Domanda da proporre al pubblico:
â€œIn quali scenari SVM potrebbe essere preferibile a Naive Bayes, 
nonostante il maggior costo computazionale?â€
-->

---

# ğŸ§® Approcci tradizionali: Logistic Regression

- ğŸ“Š Modello lineare per classificazione probabilistica
- ğŸ§® $P(y=1|x) = \frac{1}{1 + e^{-w^T x}}$
- ğŸ¯ Ottimizza i pesi per massimizzare la verosimiglianza
- ğŸ‘ Semplice, interpretabile, efficace
- ğŸ”¢ Fornisce probabilitÃ  (non solo etichette)
- ğŸ› ï¸ Facilmente estendibile a classificazione multi-classe

<!-- 
Commento speaker:
Questa slide illustra la Regressione Logistica, un algoritmo spesso sottovalutato ma molto efficace per la classificazione. 
Ãˆ importante sottolineare che, nonostante il nome â€œregressioneâ€, si tratta di un modello per la classificazione. 
Un grande vantaggio Ã¨ che non restituisce solo unâ€™etichetta, ma anche una probabilitÃ , 
che puÃ² essere molto utile in contesti reali.

Il modello Ã¨ interpretabile: i pesi associati alle feature indicano quanto ciascuna contribuisce alla predizione. 
Inoltre, Ã¨ spesso competitivo anche rispetto a modelli piÃ¹ complessi, specialmente sui testi.

Esempio pratico da condividere:
â€œIn un sistema di rilevamento frodi, sapere che la probabilitÃ  Ã¨ del 95% rispetto al 51% 
fa una grande differenza, anche se in entrambi i casi il modello segnalerebbe una frode.â€

Domanda da proporre al pubblico:
â€œIn quali contesti aziendali la capacitÃ  di fornire probabilitÃ  ben calibrate, 
oltre alle semplici etichette, potrebbe essere particolarmente importante?â€
-->

---

# ğŸ§® Approcci tradizionali: Random Forest e Gradient Boosting

- ğŸŒ² **Random Forest**: ensemble di alberi decisionali
  - ğŸ”€ Addestra molti alberi su sottoinsiemi casuali di dati e feature
  - ğŸ—³ï¸ Combina le previsioni tramite voto di maggioranza
  - ğŸ›¡ï¸ Robusto all'overfitting, gestisce bene feature irrilevanti

- ğŸ“ˆ **Gradient Boosting**: costruisce modelli sequenzialmente
  - ğŸ”„ Ogni nuovo modello corregge gli errori dei precedenti
  - ğŸ’ª Spesso ottiene performance state-of-the-art (XGBoost, LightGBM)
  - âš™ï¸ Richiede tuning attento degli iperparametri

<!-- 
Commento speaker:
Questa slide copre i metodi ensemble, che combinano piÃ¹ modelli per migliorare le performance complessive. 
Lâ€™idea chiave Ã¨ â€œlâ€™unione fa la forzaâ€: anzichÃ© puntare su un singolo modello, 
ne combiniamo tanti per ottenere risultati piÃ¹ stabili e robusti.

Random Forest costruisce molti alberi decisionali su dati e feature casuali, 
Ã¨ molto robusto allâ€™overfitting e richiede meno tuning.

Gradient Boosting invece lavora in sequenza: 
ogni nuovo modello corregge gli errori del precedente. 
Ãˆ spesso considerato tra i migliori metodi tradizionali, 
specialmente nelle sue versioni ottimizzate come XGBoost e LightGBM, 
che hanno dominato le competizioni ML prima dellâ€™arrivo del deep learning.

Da sottolineare anche che entrambi permettono di valutare 
lâ€™importanza delle feature, utile in molti progetti pratici.

Domanda da lanciare al pubblico:
â€œQuali vantaggi e svantaggi vedete nellâ€™utilizzare metodi ensemble 
rispetto a singoli modelli in un contesto aziendale?â€
-->

---

# ğŸ§  Approcci neurali: Reti Neurali Feed-Forward

![bg right:40% 80%](images/feed-forward.png)

- ğŸ§© Input: rappresentazioni vettoriali del testo (BoW, TF-IDF, embeddings)
- ğŸ”„ Hidden layers con attivazioni non lineari
- ğŸ¯ Output layer con softmax per probabilitÃ  di classe
- ğŸ‘ PuÃ² catturare pattern complessi
- âš ï¸ Richiede piÃ¹ dati rispetto ai modelli classici
- ğŸ” Non cattura naturalmente la sequenzialitÃ  del testo

<!-- 
Commento speaker:
Questa slide introduce le reti neurali feed-forward, il modello neurale piÃ¹ semplice e il punto di partenza del deep learning. 
Sono un ponte tra i modelli tradizionali e le architetture neurali piÃ¹ avanzate.

Il vantaggio principale Ã¨ che possono apprendere pattern complessi direttamente dai dati, 
ma hanno anche delle limitazioni: non sono pensate per gestire dati sequenziali come il testo 
e richiedono una rappresentazione vettoriale fissa in input, come BoW, TF-IDF o embeddings.

Esempio concreto da menzionare:
â€œUna rete feed-forward puÃ² prendere in input un vettore TF-IDF 
con 10.000 dimensioni (una per parola del vocabolario) 
e restituire la probabilitÃ  che il testo appartenga a ciascuna categoria.â€

Domanda da proporre al pubblico:
â€œQuali vantaggi vedete nellâ€™usare una rete neurale feed-forward 
rispetto a modelli tradizionali come SVM per la classificazione testuale?â€
-->

---

# ğŸ§  Approcci neurali: Reti Neurali Ricorrenti (RNN)


- ğŸ”„ Processano sequenze elemento per elemento, mantenendo uno stato nascosto
- ğŸ§  Varianti avanzate: LSTM (Long Short-Term Memory) e GRU (Gated Recurrent Unit)
- ğŸ‘ Catturano dipendenze sequenziali e contestuali
- ğŸ“ Gestiscono input di lunghezza variabile
- âš ï¸ Addestramento piÃ¹ complesso, problemi di gradienti svanescenti
- ğŸ¢ Processamento sequenziale lento (non parallelizzabile)

<!-- 
Commento speaker:
Questa slide presenta le Reti Neurali Ricorrenti (RNN), 
progettate appositamente per lavorare con dati sequenziali come il testo. 
La loro caratteristica principale Ã¨ che mantengono una â€œmemoriaâ€ dello stato precedente, 
cioÃ¨ delle parole giÃ  lette, mentre processano la sequenza.

Le varianti avanzate, come LSTM e GRU, risolvono il problema dei gradienti svanescenti, 
che affligge le RNN vanilla, e permettono di catturare dipendenze anche a lungo termine. 
Sono state lo stato dellâ€™arte in NLP per anni, prima dellâ€™arrivo dei Transformer.

Approfondimento da menzionare:
â€œLe LSTM usano delle â€˜porteâ€™ per decidere cosa ricordare e cosa dimenticare, 
gestendo cosÃ¬ in modo efficace il flusso di informazioni lungo la sequenza.â€

Domanda da proporre al pubblico:
â€œIn quali tipi di testi pensate che la capacitÃ  di catturare dipendenze a lungo termine 
sia particolarmente importante?â€
-->

---

# ğŸ§  Approcci neurali: Reti Neurali Convoluzionali (CNN)


- ğŸ” Applicano filtri convoluzionali per catturare pattern locali
- ğŸ§© Architettura tipica: embedding â†’ convoluzione â†’ max-pooling â†’ fully connected
- ğŸ‘ Efficaci per catturare n-grammi e pattern locali
- ğŸš€ PiÃ¹ veloci da addestrare rispetto alle RNN
- ğŸ”„ Non catturano dipendenze a lungo termine come le RNN
- ğŸ’ª Sorprendentemente efficaci per la classificazione testuale

<!-- 
Commento speaker:
Questa slide illustra le Reti Neurali Convoluzionali (CNN), 
originariamente sviluppate per la computer vision ma risultate efficaci anche nellâ€™elaborazione del testo.

Il punto chiave Ã¨ che le CNN applicano dei filtri che scorrono sul testo 
per identificare pattern locali: ogni filtro puÃ² essere visto come un rilevatore di n-grammi, 
cioÃ¨ piccole sequenze di parole significative.

Un grande vantaggio Ã¨ la velocitÃ : 
le CNN sono molto piÃ¹ veloci da addestrare rispetto alle RNN perchÃ© possono essere parallelizzate. 
Tuttavia, non riescono a catturare bene le dipendenze a lungo termine, 
anche se sono sorprendentemente efficaci per la classificazione testuale.

Esempio pratico da menzionare:
â€œUn filtro convoluzionale puÃ² specializzarsi nel riconoscere frasi negative come 
â€˜non mi Ã¨ piaciutoâ€™ o â€˜davvero deludenteâ€™, indipendentemente da dove compaiono nel testo.â€

Domanda da proporre al pubblico:
â€œPerchÃ© secondo voi le CNN, nate per lâ€™analisi di immagini, 
funzionano bene anche per lâ€™analisi testuale?â€
-->

---

# ğŸ§  Approcci neurali: Transformer

- âš¡ Basati sul meccanismo di self-attention
- ğŸ”„ Processano l'intera sequenza in parallelo
- ğŸŒ Pre-addestrati su enormi corpora (BERT, RoBERTa, XLNet...)
- ğŸ¯ Fine-tuning per task specifici di classificazione
- ğŸ† State-of-the-art per la maggior parte dei task NLP
- âš ï¸ Computazionalmente costosi, richiedono GPU
- ğŸ“ Limitazioni sulla lunghezza dell'input

<!-- 
Commento speaker:
Questa slide presenta i Transformer, lâ€™architettura che ha rivoluzionato lâ€™NLP negli ultimi anni. 
Il cuore dei Transformer Ã¨ il meccanismo di self-attention, 
che permette a ogni parola di â€œprestare attenzioneâ€ a tutte le altre nella sequenza. 
Questo supera i limiti delle RNN, che devono processare parola per parola, 
e delle CNN, che vedono solo pattern locali.

Un aspetto fondamentale Ã¨ il pre-addestramento su enormi quantitÃ  di testo 
(BERT, RoBERTa, XLNet, ecc.) seguito da fine-tuning su task specifici. 
Questo ha cambiato radicalmente lâ€™approccio allâ€™NLP e ha portato i Transformer 
a diventare lo stato dellâ€™arte per la maggior parte dei task.

Approfondimento utile:
â€œBERT, per esempio, Ã¨ pre-addestrato su due task: 
Masked Language Modeling (predire parole mascherate) 
e Next Sentence Prediction. 
Questo gli permette di acquisire conoscenza linguistica generale 
prima del fine-tuning sul task specifico.â€

Domanda da proporre al pubblico:
â€œQuali sono le implicazioni pratiche dellâ€™utilizzo di modelli pre-addestrati come BERT 
rispetto allâ€™addestramento di modelli da zero?â€
-->

---

# Analisi del sentiment

![bg 100% 80%](images/sentiment.webp)

---

# ğŸ˜Š Analisi del sentiment: concetti fondamentali

> "L'analisi del sentiment Ã¨ il processo di determinazione dell'attitudine, opinione o emozione espressa in un testo."

- ğŸ¯ **Obiettivo**: identificare e quantificare il sentiment espresso
- ğŸ“Š **GranularitÃ **: documento, frase, aspetto, entitÃ 
- ğŸ” **Approcci**: basati su lessico, machine learning, ibridi
- ğŸ§  **Output**: categorico (pos/neg/neutro) o continuo (score)

<!-- 
Commento speaker:
Questa slide introduce lâ€™analisi del sentiment, 
che possiamo considerare uno degli esempi piÃ¹ famosi e diffusi di classificazione testuale. 
Lâ€™obiettivo non Ã¨ solo classificare il testo, 
ma capire lâ€™attitudine o lâ€™emozione espressa â€” per esempio, positiva, negativa o neutra.

Ãˆ importante sottolineare che lâ€™analisi del sentiment puÃ² lavorare a diversi livelli: 
dal documento intero, fino a singole frasi o addirittura aspetti ed entitÃ  specifiche. 
Gli approcci possono essere semplici, basati su dizionari di parole, 
oppure piÃ¹ sofisticati, usando machine learning o metodi ibridi.

Ha applicazioni molto concrete e ad alto impatto, 
per esempio nel monitoraggio del brand, nella voice of customer, 
o nellâ€™analisi automatica delle recensioni.

Esempio pratico da menzionare:
â€œAmazon usa lâ€™analisi del sentiment per monitorare le recensioni, 
individuare problemi emergenti e misurare la soddisfazione dei clienti.â€

Domanda da proporre al pubblico:
â€œQuali sono secondo voi le applicazioni piÃ¹ impattanti 
dellâ€™analisi del sentiment nel vostro settore?â€
-->

---

# ğŸ˜Š Livelli di analisi del sentiment

- ğŸ“ **Livello documento**: sentiment globale dell'intero documento
  - "Questo prodotto Ã¨ fantastico. Altamente consigliato!"

- ğŸ“‹ **Livello frase**: sentiment di singole frasi
  - "L'interfaccia Ã¨ intuitiva, ma la batteria si scarica velocemente."

- ğŸ¯ **Livello aspetto**: sentiment verso specifici aspetti/caratteristiche
  - "La fotocamera Ã¨ eccellente [+], ma il prezzo Ã¨ troppo alto [-]."

- ğŸ¢ **Livello entitÃ **: sentiment verso specifiche entitÃ 
  - "Apple ha rilasciato un ottimo prodotto, ma Samsung resta leader."

<!-- 
Commento speaker:
Questa slide spiega i diversi livelli di granularitÃ  dellâ€™analisi del sentiment, 
che vanno dal livello piÃ¹ generale, il documento, fino a livelli molto piÃ¹ dettagliati come aspetto ed entitÃ . 

Un punto importante da sottolineare Ã¨ che piÃ¹ aumentiamo la granularitÃ , 
piÃ¹ diventa complesso il task, ma anche piÃ¹ utile e ricco lâ€™insight che otteniamo. 
Lâ€™aspect-based sentiment analysis, cioÃ¨ lâ€™analisi per aspetto, 
Ã¨ particolarmente preziosa in ambito aziendale perchÃ© permette di capire esattamente 
cosa piace o non piace ai clienti.

Esempio pratico da citare:
â€œUnâ€™analisi a livello di documento ci direbbe che una recensione Ã¨ negativa, 
ma unâ€™analisi a livello di aspetto ci permetterebbe di capire 
che il cliente Ã¨ scontento del prezzo e del servizio clienti, 
ma soddisfatto della qualitÃ  del prodotto.â€

Domanda da proporre al pubblico:
â€œPer quali tipi di decisioni aziendali pensate sia cruciale 
unâ€™analisi del sentiment a livello di aspetto rispetto a una piÃ¹ semplice a livello documento?â€
-->

---

# ğŸ˜Š Approcci all'analisi del sentiment

- ğŸ“š **Approcci basati su lessico**:
  - Utilizzano dizionari di parole con polaritÃ  predefinite
  - Es: VADER, SentiWordNet, AFINN
  - ğŸ‘ Non richiedono addestramento
  - ğŸ‘ Limitati da espressioni complesse, sarcasmo, contesto

- ğŸ§  **Approcci basati su machine learning**:
  - Supervisionati: Naive Bayes, SVM, deep learning
  - ğŸ‘ Catturano pattern complessi
  - ğŸ‘ Richiedono dati etichettati

<!-- 
Commento speaker:
Questa slide mette a confronto i due principali approcci allâ€™analisi del sentiment: 
quello basato su lessico e quello basato su machine learning.

Gli approcci lessicali usano dizionari di parole con polaritÃ  giÃ  definite 
e hanno il vantaggio di non richiedere dati etichettati, 
ma sono limitati quando si trovano davanti a espressioni complesse, sarcasmo o mancanza di contesto.

Gli approcci basati su machine learning, invece, possono catturare pattern complessi 
e adattarsi meglio ai dati specifici, 
ma hanno bisogno di dataset etichettati per lâ€™addestramento.

Da ricordare che, nella pratica, spesso si ottengono i migliori risultati 
combinando i due approcci in modo ibrido, 
scegliendo in base alle risorse disponibili e alla complessitÃ  del dominio.

Approfondimento utile:
â€œVADER, per esempio, Ã¨ un lessico pensato apposta per i social media 
e gestisce anche emoji, slang e intensificatori come â€˜moltoâ€™ o â€˜estremamenteâ€™.â€

Domanda da proporre al pubblico:
â€œIn quali scenari preferireste un approccio basato su lessico 
rispetto a uno basato su machine learning, nonostante i suoi limiti?â€
-->
---

# ğŸ˜Š Sfide nell'analisi del sentiment

- ğŸ­ **Sarcasmo e ironia**: "Fantastico, un altro aggiornamento che rallenta tutto!"
- ğŸ”„ **Negazioni**: "Il prodotto non Ã¨ male" (positivo, non negativo)
- ğŸ“ **Intensificatori**: "molto buono" vs "buono"
- ğŸŒ **Espressioni idiomatiche**: "costare un occhio della testa"
- ğŸ§© **AmbiguitÃ **: "Il film era incredibile" (positivo o negativo?)
- ğŸŒ **Differenze culturali e linguistiche**: variazioni nell'espressione di emozioni
- ğŸ“± **Emoji e emoticon**: ğŸ˜Š vs ğŸ™„ (richiedono interpretazione specifica)

<!-- 
Commento speaker:
Questa slide mette in evidenza le principali sfide dellâ€™analisi del sentiment, 
che derivano soprattutto dalla complessitÃ  e dalla ricchezza del linguaggio umano.

Ãˆ importante sottolineare che elementi come sarcasmo e ironia 
sono difficili da riconoscere persino per i modelli piÃ¹ avanzati. 
Le negazioni possono ribaltare completamente il significato, 
mentre intensificatori, espressioni idiomatiche e ambiguitÃ  
aggiungono ulteriori livelli di complessitÃ .

Inoltre, le differenze culturali e linguistiche 
rendono lâ€™analisi multilingue ancora piÃ¹ sfidante, 
e le emoji portano con sÃ© un ulteriore livello interpretativo.

Esempio divertente da raccontare:
â€œQuando scrivo al mio collega â€˜Che meraviglia, un altro lunedÃ¬ mattina!â€™, 
lui capisce che sto facendo sarcasmo, 
ma un algoritmo potrebbe leggerlo come un commento positivo.â€

Domanda da proporre al pubblico:
â€œQuali strategie potremmo adottare per migliorare 
la capacitÃ  dei modelli di rilevare sarcasmo e ironia?â€
-->

---

# ğŸ“Š Valutazione dei classificatori testuali

- âœ… **Accuracy**: proporzione di previsioni corrette
  - $\text{Accuracy} = \frac{\text{Corrette}}{\text{Totale}}$

- ğŸ“Š **Precision**: proporzione di positivi identificati correttamente
  - $\text{Precision} = \frac{\text{True Positives}}{\text{True Positives + False Positives}}$

- ğŸ“ˆ **Recall**: proporzione di positivi reali identificati
  - $\text{Recall} = \frac{\text{True Positives}}{\text{True Positives + False Negatives}}$

- ğŸ” **F1-Score**: media armonica di precision e recall
  - $\text{F1} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$

<!-- 
Commento speaker:
Questa slide introduce le metriche principali per valutare i classificatori testuali. 
Ãˆ fondamentale capire che lâ€™accuracy, pur essendo la metrica piÃ¹ intuitiva, 
puÃ² essere fuorviante, soprattutto in presenza di classi sbilanciate.

Precision e recall rappresentano un trade-off importante: 
la precision misura quanti dei positivi previsti erano davvero positivi, 
mentre il recall misura quanti dei positivi reali siamo riusciti a trovare. 
Il F1-score combina queste due metriche in unâ€™unica misura bilanciata.

Ãˆ cruciale scegliere la metrica giusta in base allâ€™applicazione:
per esempio, in un sistema antifrode ci interessa massimizzare il recall 
per non perdere frodi reali, 
mentre in un sistema di filtraggio contenuti vogliamo alta precision 
per evitare falsi positivi.

Domanda da proporre al pubblico:
â€œIn quali scenari aziendali privilegereste la precision rispetto al recall, o viceversa?â€
-->

---

# ğŸ“Š Valutazione: Confusion Matrix

![bg right:50% 90%](images/confusion-matrix.png)

- ğŸ“Š Tabella che mostra le previsioni vs. realtÃ 
- ğŸ” Rivela pattern di errori specifici
- ğŸ§© Particolarmente utile per classi sbilanciate
- ğŸ“ˆ Base per calcolare precision, recall, F1
- ğŸ”„ Essenziale per comprendere il comportamento del modello oltre le metriche aggregate

<!-- 
Commento speaker:
Questa slide spiega la matrice di confusione, uno strumento fondamentale per analizzare 
gli errori di un classificatore. La confusion matrix ci mostra come le previsioni del modello 
si confrontano con la realtÃ , andando oltre le metriche aggregate come accuracy o F1.

Ãˆ utile perchÃ© ci permette di individuare classi problematiche, 
cioÃ¨ quelle che il modello tende a confondere piÃ¹ spesso, 
e diventa particolarmente preziosa quando lavoriamo con classi sbilanciate.

Oltre a dare numeri, fornisce insights qualitativi 
che possono guidare interventi mirati per migliorare il modello.

Esempio pratico:
â€œUna confusion matrix su un classificatore di notizie 
potrebbe rivelare che â€˜Tecnologiaâ€™ viene spesso confusa con â€˜Scienzaâ€™, 
ma quasi mai con â€˜Sportâ€™, suggerendo di concentrarci 
su feature che distinguano meglio i primi due domini.â€

Domanda da proporre al pubblico:
â€œCome utilizzereste le informazioni di una confusion matrix 
per migliorare un classificatore esistente?â€
-->

---

# ğŸ“Š Valutazione: ROC Curve e AUC

![bg right:40% 90%](images/roc-curve.png)

- ğŸ“ˆ **ROC**: Receiver Operating Characteristic
- ğŸ” Mostra il trade-off tra true positive rate e false positive rate
- ğŸ“Š **AUC**: Area Under the Curve
  - 1.0 = classificatore perfetto
  - 0.5 = classificatore casuale
- ğŸ‘ Robusta rispetto a classi sbilanciate
- ğŸ”„ Utile per confrontare modelli e scegliere soglie di decisione

<!-- 
Commento speaker:
Questa slide spiega due metriche avanzate per valutare i modelli di classificazione: 
la curva ROC e lâ€™AUC. 
Sono strumenti fondamentali, soprattutto quando lavoriamo con classi sbilanciate 
o quando dobbiamo prendere decisioni delicate 
sul compromesso tra diversi tipi di errore.

La curva ROC (Receiver Operating Characteristic) 
Ã¨ un grafico che mostra il trade-off tra il True Positive Rate (la percentuale di positivi corretti sul totale dei positivi reali) 
e il False Positive Rate (la percentuale di negativi sbagliati sul totale dei negativi reali). 
Si costruisce calcolando questi valori a tante soglie diverse 
e ci permette di vedere quanto guadagniamo in sensibilitÃ  
al prezzo di piÃ¹ falsi positivi.

Lâ€™AUC, cioÃ¨ lâ€™Area Under the Curve, 
Ã¨ il numero che riassume la curva in un solo valore tra 0 e 1. 
Un AUC di 0,5 significa che il modello Ã¨ casuale, 
mentre 1 indica un modello perfetto. 
In pratica, piÃ¹ Ã¨ alto lâ€™AUC, meglio il modello distingue tra classi positive e negative.

Domanda possibile per il pubblico:
â€œQuando e perchÃ© preferireste usare AUC e curva ROC invece di metriche come accuracy 
per confrontare i modelli?â€
-->

---

# ğŸ’¼ Caso di studio: Analisi delle recensioni dei clienti

**Azienda**: Catena di hotel internazionale

**Sfida**: Analizzare migliaia di recensioni per identificare punti di forza e debolezza

**Soluzione**:
1. ğŸ§¹ Preprocessing delle recensioni
2. ğŸ˜Š Analisi del sentiment a livello di aspetto (pulizia, personale, posizione, prezzo...)
3. ğŸ“Š Dashboard con trend temporali e confronto tra strutture
4. ğŸ” Alert automatici per problemi ricorrenti

**Risultato**: Miglioramento del 15% nella soddisfazione dei clienti in 6 mesi

<!-- 
Questa slide racconta un caso di studio reale legato allâ€™analisi del sentiment, mostrando in pratica come questa tecnologia possa generare valore concreto per le aziende.

Uno degli aspetti piÃ¹ interessanti Ã¨ lâ€™analisi a livello di aspetto: non ci si limita a capire se il sentiment generale Ã¨ positivo o negativo, ma si va piÃ¹ a fondo, individuando quali elementi specifici del servizio o prodotto stanno funzionando bene e quali invece creano insoddisfazione. Per esempio, in questo caso, lâ€™analisi ha permesso di scoprire che, mentre la posizione e la pulizia delle strutture ricevevano commenti positivi, il personale veniva spesso criticato. Questo ha dato allâ€™azienda unâ€™informazione preziosa su cui intervenire.

La visualizzazione temporale dei dati ha permesso di osservare lâ€™evoluzione del sentiment nel tempo e di capire se le azioni correttive intraprese (in questo caso, un programma di formazione per il personale) avevano portato miglioramenti. Grazie a questa vista nel tempo, non solo si capisce â€œcosaâ€ funziona o meno, ma anche â€œquandoâ€ e â€œcomeâ€ cambia la percezione dei clienti.

Un altro elemento chiave Ã¨ lâ€™uso di alert automatici: quando il sistema rileva un calo nel sentiment su un aspetto specifico, genera una segnalazione immediata. Questo permette allâ€™azienda di reagire tempestivamente, prevenendo crisi reputazionali o cali di soddisfazione.

Infine, il ROI (ritorno sullâ€™investimento) dellâ€™intero progetto Ã¨ chiaramente misurabile. In questo caso specifico, lâ€™intervento mirato ha portato a un miglioramento delle valutazioni sul personale, traducendosi in una crescita della soddisfazione complessiva dei clienti.

Per stimolare il pubblico, puoi lanciare una domanda riflessiva:
â€œCome potrebbe questa soluzione essere adattata ad altri settori come retail o servizi finanziari?â€
Questo aiuta a trasferire i concetti dal caso specifico ad altri contesti, facendo capire quanto lâ€™analisi del sentiment sia versatile e applicabile in tanti ambiti diversi.

Se vuoi, posso anche scriverti un testo pronto per lo speaker o prepararti una versione in Marp markdown! Vuoi che lo faccia?
-->

---

# ğŸ’¼ Caso di studio: Monitoraggio della reputazione del brand

**Azienda**: Produttore di elettronica di consumo

**Sfida**: Monitorare la percezione del brand sui social media e forum

**Soluzione**:
1. ğŸ” Raccolta continua di menzioni del brand
2. ğŸ·ï¸ Classificazione per tema (qualitÃ , prezzo, supporto, innovazione...)
3. ğŸ˜Š Analisi del sentiment per tema
4. ğŸ“Š Dashboard in tempo reale con alert

**Risultato**: Identificazione precoce di una potenziale crisi PR, con risposta rapida che ha limitato l'impatto negativo

<!-- 
Questa slide racconta un caso concreto di monitoraggio della reputazione, mostrando come le aziende possano proteggere il proprio brand grazie allâ€™uso intelligente dellâ€™analisi automatizzata.

Il primo punto chiave Ã¨ il monitoraggio in tempo reale, che permette di individuare rapidamente segnali di crisi. Nel caso specifico, quando un influencer ha pubblicato un video critico su un difetto del prodotto, il sistema ha immediatamente registrato un picco di commenti negativi. Questa rapiditÃ  di rilevamento ha consentito allâ€™azienda di reagire nel giro di poche ore, riducendo lâ€™impatto della crisi prima che degenerasse.

Un altro aspetto importante Ã¨ la classificazione per tema, cioÃ¨ la capacitÃ  del sistema di raggruppare i commenti e le conversazioni in base agli argomenti trattati. In questo modo, non solo si sa che câ€™Ã¨ un problema, ma si capisce subito dove sta il problema â€” ad esempio sul prodotto, sullâ€™assistenza, sulla comunicazione o su altri aspetti.

Lâ€™analisi del sentiment per tema aggiunge un ulteriore livello di comprensione, mostrando non solo quali aree sono problematiche, ma anche quale carica emotiva hanno. Per esempio, lamentele su piccoli difetti possono avere un impatto emotivo diverso rispetto a critiche legate alla sicurezza o allâ€™etica aziendale.

Il valore aziendale di questo approccio si manifesta nella possibilitÃ  di gestire le crisi in modo proattivo. Invece di scoprire i problemi quando ormai Ã¨ troppo tardi, lâ€™azienda puÃ² intervenire subito, rassicurare i clienti e contenere i danni, salvaguardando la propria reputazione e, di conseguenza, anche i risultati di business.

Per coinvolgere il pubblico, puoi proporre questa domanda:
â€œQuali altri segnali, oltre al sentiment, potrebbero essere monitorati per prevedere potenziali crisi PR?â€
Questa domanda stimola a riflettere su indicatori complementari, come i volumi di menzioni, la diffusione virale dei post o lâ€™attivitÃ  degli influencer.

Se vuoi, posso anche prepararti il testo giÃ  pronto in markdown per le slide o una versione con note per lo speaker. Vuoi che lo faccia?
-->

---

# ğŸ’¼ Caso di studio: Classificazione automatica di ticket di supporto

**Azienda**: Software as a Service (SaaS)

**Sfida**: Smistare automaticamente migliaia di ticket di supporto

**Soluzione**:
1. ğŸ§  Classificatore multi-classe basato su BERT
2. ğŸ¯ Categorizzazione in 20+ categorie (bug, domande di fatturazione, richieste di feature...)
3. ğŸ”„ Sistema di feedback per miglioramento continuo
4. ğŸ‘¥ Integrazione con sistema di assegnazione agli specialisti

<!-- 
Questa slide ci porta dentro un caso di studio pratico sullâ€™uso dellâ€™intelligenza artificiale per la classificazione automatica dei ticket di supporto â€” un tema che ha un impatto diretto sullâ€™efficienza operativa e sulla soddisfazione del cliente.

Il primo punto da sottolineare Ã¨ che grazie alla classificazione automatica, lâ€™azienda ha potuto ridurre in modo drastico i tempi di risposta. Prima dellâ€™implementazione, ogni ticket doveva essere letto, interpretato e assegnato manualmente al reparto giusto, con tempi di attesa iniziali anche di diverse ore. Dopo lâ€™introduzione del sistema AI, il 90% dei ticket viene classificato correttamente in pochi secondi, liberando risorse umane per attivitÃ  a maggior valore aggiunto.

Un elemento tecnico cruciale Ã¨ lâ€™uso di BERT, un modello linguistico avanzato capace di cogliere sfumature e contesti complessi nel linguaggio. Questo significa che il sistema non si limita a riconoscere parole chiave, ma riesce a interpretare la reale intenzione o il problema sottostante, anche quando espresso in modo indiretto o ambiguo.

Molto importante Ã¨ anche il sistema di feedback integrato: ogni volta che un ticket viene riclassificato o corretto manualmente, queste informazioni vengono reinserite nel modello, creando un ciclo virtuoso di apprendimento continuo e miglioramento delle performance.

Infine, lâ€™aspetto che massimizza il valore per lâ€™azienda Ã¨ lâ€™integrazione con i sistemi esistenti: il sistema AI non lavora isolato, ma si innesta nei processi e negli strumenti giÃ  in uso, assicurando un impatto concreto e immediato sul flusso di lavoro.

Per coinvolgere il pubblico, puoi lanciare questa domanda:
â€œQuali altri processi aziendali potrebbero beneficiare di un sistema di classificazione automatica simile?â€
Questo aiuta a stimolare riflessioni su applicazioni come la gestione delle email, la categorizzazione di documenti, o la prioritizzazione di richieste in ambito legale, sanitario o finanziario.

Se vuoi, posso trasformare anche questo testo in una slide Marp markdown con note per lo speaker. Ti preparo il file?
-->

---

# ğŸ› ï¸ Implementazione pratica: considerazioni tecniche

- ğŸ”„ **Pipeline end-to-end**: dalla raccolta dati al deployment
- ğŸš€ **ScalabilitÃ **: gestione di volumi crescenti di dati
- â±ï¸ **Latenza**: tempo di risposta accettabile per l'applicazione
- ğŸ›¡ï¸ **Robustezza**: gestione di input anomali e casi edge
- ğŸ“Š **Monitoraggio**: tracking delle performance nel tempo
- ğŸ”„ **Feedback loop**: meccanismi per miglioramento continuo
- ğŸ’° **Costi**: bilanciamento tra performance e risorse computazionali

<!-- 
Questa slide Ã¨ dedicata alle considerazioni tecniche fondamentali da affrontare quando si passa da un prototipo di classificazione testuale a un sistema realmente operativo in produzione.

Il primo punto da chiarire Ã¨ che un sistema in produzione non Ã¨ solo un modello di machine learning. Serve unâ€™infrastruttura completa che gestisca input, output, logging, sicurezza, e interazione con altri sistemi. Quindi, non basta â€œallenareâ€ un modello: bisogna pensare allâ€™intero ciclo di vita del sistema.

Un secondo aspetto cruciale Ã¨ la scalabilitÃ : il sistema deve poter gestire carichi crescenti, anche imprevedibili, senza perdere efficienza. Collegato a questo câ€™Ã¨ il tema della latenza, particolarmente importante nelle applicazioni real-time. Ad esempio, un classificatore di email aziendali deve essere in grado di processare migliaia di messaggi al minuto con una latenza di pochi millisecondi, garantendo allo stesso tempo affidabilitÃ  durante eventuali picchi di traffico.

Il monitoraggio continuo Ã¨ un altro pilastro: anche un modello che parte con ottime performance puÃ² degradare nel tempo, ad esempio perchÃ© cambiano i dati, il linguaggio usato dagli utenti o le esigenze di business. Monitorare indicatori chiave come accuratezza, tasso di errore e distribuzione dei dati in ingresso permette di intercettare tempestivamente problemi e intervenire prima che abbiano un impatto.

Infine, il feedback loop gioca un ruolo essenziale. Permette al sistema di apprendere dai propri errori, aggiornando regolarmente il modello con dati nuovi e correzioni umane. Senza questo meccanismo, le performance rischiano di deteriorarsi, specialmente in contesti dinamici.

Per coinvolgere il pubblico, puoi chiudere con questa domanda:
â€œQuali sono le principali sfide tecniche che potreste incontrare implementando un sistema di classificazione testuale nella vostra organizzazione?â€
Questo aiuta i partecipanti a collegare la teoria alla loro esperienza pratica, facendo emergere potenziali ostacoli come la gestione della privacy, lâ€™integrazione con software legacy o la disponibilitÃ  di dati di qualitÃ .

Se vuoi, posso anche scrivere tutto questo direttamente in Marp markdown con commenti per lo speaker! Vuoi che lo prepari?
-->

---

# ğŸ› ï¸ Considerazioni etiche e bias

- ğŸ§  **Bias nei dati di addestramento**: riflettono pregiudizi umani
- ğŸ” **Trasparenza algoritmica**: comprensione delle decisioni
- ğŸ›¡ï¸ **Privacy**: gestione di dati sensibili o personali
- ğŸŒ **Fairness**: equitÃ  tra gruppi demografici
- ğŸ”„ **Accountability**: responsabilitÃ  per le decisioni automatizzate
- ğŸ“Š **Audit regolari**: verifica continua di bias e performance
- ğŸ‘¥ **Human-in-the-loop**: supervisione umana per decisioni critiche

<!-- 

Questa slide ci porta al cuore delle considerazioni etiche, un tema che troppo spesso viene trascurato quando si parla di sistemi di classificazione automatica, ma che invece dovrebbe essere visto come un requisito fondamentale, non come un â€œnice to haveâ€.

Il primo punto da sottolineare Ã¨ il rischio legato ai bias. Se il modello viene addestrato su dati storici che contengono pregiudizi o squilibri â€” ad esempio legati a genere, etnia o etÃ  â€” rischiamo non solo di replicare quegli stessi bias, ma addirittura di amplificarli. Un esempio concreto Ã¨ un sistema di classificazione dei CV: se i dati storici riflettono pratiche di selezione sbilanciate, il modello potrebbe penalizzare inconsapevolmente candidati appartenenti a certi gruppi demografici.

La trasparenza Ã¨ un altro pilastro etico: Ã¨ fondamentale che le persone coinvolte â€” utenti, manager, clienti â€” sappiano come funziona il sistema, quali criteri usa e quali limiti ha. Solo cosÃ¬ si puÃ² costruire un rapporto di fiducia e legittimazione nei confronti della tecnologia.

Inoltre, dobbiamo chiarire che le considerazioni etiche non sono un lusso da affrontare â€œse avanza tempo o budgetâ€, ma sono vere e proprie condizioni di qualitÃ , indispensabili soprattutto in contesti regolamentati come sanitÃ , risorse umane o finanza.

Per garantire un equilibrio tra automazione e responsabilitÃ , una strategia molto efficace Ã¨ lâ€™approccio human-in-the-loop, dove il sistema automatico Ã¨ affiancato da un controllo umano. Questo permette di unire i vantaggi dellâ€™efficienza automatizzata con la capacitÃ  di giudizio, empatia e contestualizzazione delle persone, specialmente per i casi piÃ¹ delicati o borderline.

Per stimolare il pubblico, puoi chiudere con questa domanda:
â€œCome bilancereste lâ€™esigenza di automazione con la necessitÃ  di garantire decisioni etiche e non discriminatorie?â€
Questo aiuta a far riflettere su possibili soluzioni, come audit periodici, soglie di fiducia per lâ€™intervento umano o training specifici per ridurre i bias.

-->

---

# ğŸ› ï¸ Tecniche di interpretabilitÃ 

- ğŸ” **Feature importance**: quali parole influenzano maggiormente la decisione
- ğŸ“Š **LIME (Local Interpretable Model-agnostic Explanations)**: spiega singole predizioni
- ğŸ§® **SHAP (SHapley Additive exPlanations)**: contributo di ogni feature
- ğŸ‘ï¸ **Attention visualization**: visualizzazione dei pesi di attenzione
- ğŸ”„ **Counterfactual explanations**: "cosa cambierebbe la predizione?"
- ğŸ“ **Spiegazioni in linguaggio naturale**: traduzione delle decisioni in testo comprensibile

<!-- 
uesta slide introduce un tema fondamentale per il successo di qualsiasi sistema di classificazione: lâ€™interpretabilitÃ .
Un modello, per quanto accurato, rischia di non essere adottato o addirittura di generare sfiducia se non Ã¨ in grado di spiegare le sue decisioni in modo comprensibile.

Il primo punto da evidenziare Ã¨ che lâ€™interpretabilitÃ  Ã¨ essenziale per creare fiducia: gli utenti devono capire non solo â€œcosaâ€ il modello predice, ma anche â€œperchÃ©â€ fa quella predizione.

Esistono due grandi categorie di tecniche:
	â€¢	Da un lato ci sono i modelli intrinsecamente interpretabili, come le regressioni lineari o gli alberi decisionali, dove Ã¨ relativamente facile vedere come i fattori influenzano lâ€™output.
	â€¢	Dallâ€™altro ci sono i modelli cosiddetti black-box, come le reti neurali o i transformer, per i quali servono tecniche specifiche per estrarne spiegazioni. Un esempio Ã¨ LIME, che permette di capire quali caratteristiche di un input hanno pesato di piÃ¹ nella decisione del modello. Ad esempio, LIME puÃ² mostrare che unâ€™email Ã¨ stata classificata come spam soprattutto per la presenza delle parole â€œvinciâ€, â€œgratisâ€ e â€œofferta specialeâ€ â€” rendendo comprensibile una decisione altrimenti opaca.

Un altro aspetto importante Ã¨ che le spiegazioni devono essere adattate al pubblico:
	â€¢	Gli utenti tecnici potrebbero voler analizzare le feature importance o i gradienti.
	â€¢	I decisori non tecnici potrebbero preferire spiegazioni intuitive, visive o basate su esempi concreti.

Infine, lâ€™interpretabilitÃ  Ã¨ fondamentale non solo per motivi di fiducia, ma anche per motivi pratici: aiuta il team a fare debugging e migliorare i modelli, permettendo di capire dove e perchÃ© sbagliano.

Per coinvolgere il pubblico, puoi chiudere con questa domanda:
â€œQuali tipi di spiegazioni sarebbero piÃ¹ utili per diversi stakeholder nella vostra organizzazione?â€
Questa domanda aiuta a collegare il concetto ai bisogni concreti dellâ€™audience, stimolando riflessioni su come comunicare i risultati dellâ€™AI in modo efficace.
-->

---

# ğŸ› ï¸ Strumenti e librerie per classificazione testuale

- ğŸ§° **Scikit-learn**: implementazioni di algoritmi classici
- ğŸ§  **TensorFlow/Keras e PyTorch**: framework per deep learning
- ğŸ¤— **Hugging Face Transformers**: accesso a modelli pre-addestrati
- ğŸ˜Š **NLTK e TextBlob**: strumenti per analisi del sentiment basata su lessico
- ğŸ” **spaCy**: pipeline NLP end-to-end
- ğŸ“Š **LIME e SHAP**: strumenti per interpretabilitÃ  dei modelli
- ğŸ§ª **MLflow**: tracking di esperimenti e gestione di modelli

<!-- 
Un primo messaggio importante Ã¨ che lâ€™ecosistema Python Ã¨ oggi estremamente maturo, con strumenti robusti e affidabili per ogni fase del processo: dalla pulizia dei dati al preprocessing, dallâ€™addestramento dei modelli fino allâ€™interpretabilitÃ  e al monitoraggio.

La scelta degli strumenti va sempre fatta in base alle esigenze specifiche e alle competenze del team. Per esempio, un team piÃ¹ orientato alla ricerca potrebbe preferire TensorFlow o PyTorch, mentre uno piÃ¹ applicativo potrebbe trovare sufficiente scikit-learn, spaCy o semplici pipeline di Hugging Face.

Un punto cruciale Ã¨ lâ€™impatto che Hugging Face ha avuto nel settore: ha davvero democratizzato lâ€™accesso ai modelli piÃ¹ avanzati, come BERT, RoBERTa o GPT, permettendo di integrarli in progetti concreti con poche righe di codice. Questo ha abbassato enormemente la barriera dâ€™ingresso, rendendo possibile per team anche piccoli o con budget limitati lavorare con tecnologie state-of-the-art.

Infine, un aspetto che sta diventando sempre piÃ¹ rilevante Ã¨ che anche gli strumenti di interpretabilitÃ  sono ormai integrati nei workflow standard. Non si tratta piÃ¹ di unâ€™aggiunta opzionale, ma di componenti di serie per spiegare e validare le decisioni dei modelli.

Per coinvolgere il pubblico, puoi concludere con questa domanda:
â€œQuali di questi strumenti avete giÃ  utilizzato e quali vorreste esplorare?â€
Ãˆ un ottimo modo per stimolare uno scambio di esperienze pratiche tra i partecipanti e magari raccogliere spunti per discussioni piÃ¹ approfondite.
-->

---

# ğŸ’¡ Concetti chiave da ricordare

- ğŸ·ï¸ La classificazione testuale Ã¨ un task supervisionato fondamentale nell'NLP
- ğŸ§® Algoritmi classici (NB, SVM) sono ancora rilevanti per molti casi d'uso
- ğŸ§  Deep learning offre performance superiori ma richiede piÃ¹ dati e risorse
- ğŸ˜Š L'analisi del sentiment puÃ² essere applicata a diversi livelli di granularitÃ 
- ğŸ“Š La valutazione deve considerare metriche appropriate al contesto
- ğŸ’¼ Le applicazioni aziendali spaziano dal customer service al brand monitoring
- ğŸ› ï¸ Implementazione e considerazioni etiche sono cruciali per il successo

<!-- 
Questa slide riassume i concetti chiave del modulo.

Punti da enfatizzare:
- La classificazione testuale Ã¨ un campo maturo con tecniche consolidate
- Non esiste un approccio "one-size-fits-all" - la scelta dipende dal contesto
- Le considerazioni pratiche e etiche sono importanti quanto le performance tecniche
- Il valore aziendale deriva dall'integrazione efficace nei processi esistenti

Riflessione finale: "La classificazione del testo Ã¨ una delle applicazioni NLP con maggiore impatto immediato sul business, trasformando dati non strutturati in insights actionable."

Possibile domanda: "Quale di questi concetti vi ha sorpreso di piÃ¹ o vi sembra piÃ¹ rilevante per il vostro contesto?"
-->

---

# ğŸ“š Risorse per approfondire

- ğŸ“– **Paper**: "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding" (Devlin et al., 2019)
- ğŸ§ª **Dataset**: IMDB Reviews, Amazon Reviews, Twitter Sentiment
- ğŸ“ **Tutorial**: "Text Classification with BERT" (TensorFlow)
- ğŸ§° **Librerie**: VADER per sentiment analysis, Hugging Face per classificazione
- ğŸ“Š **Competizioni**: Kaggle text classification challenges
- ğŸ“š **Libro**: "Natural Language Processing with Transformers" (Lewis et al., 2021)

<!-- 
Questa slide fornisce risorse per approfondire gli argomenti trattati.

Punti da enfatizzare:
- Il campo Ã¨ in rapida evoluzione, quindi Ã¨ importante mantenersi aggiornati
- Le competizioni Kaggle offrono opportunitÃ  pratiche di apprendimento
- I tutorial hands-on sono il modo migliore per familiarizzare con le tecniche
- Le community online sono risorse preziose per risolvere problemi specifici

Suggerimento pratico: "Vi consiglio di iniziare con un tutorial pratico su Hugging Face, che vi permetterÃ  di implementare un classificatore BERT in poche righe di codice."

Possibile domanda: "Quali di queste risorse vi interesserebbe esplorare per primi?"
-->

---

# ğŸ™‹ Domande?

### Prossimo modulo: Modelli Linguistici e Sequence-to-Sequence

<!-- 
Questa slide conclude il modulo e apre lo spazio per le domande.

Punti da enfatizzare:
- Incoraggiare domande specifiche sugli argomenti trattati
- Collegare questo modulo al prossimo, evidenziando la continuitÃ 
- Ricordare le applicazioni pratiche discusse

Possibili domande da porre alla classe:
- "Quali applicazioni della classificazione testuale vedete piÃ¹ rilevanti nel vostro settore?"
- "Quali sfide specifiche prevedete nell'implementare queste tecniche?"
- "Quali aspetti vorreste approfondire ulteriormente?"
-->

---

# Grazie per l'attenzione! ğŸ‘‹

<!-- 
Slide finale di ringraziamento.

Punti da enfatizzare:
- Riassumere brevemente l'importanza della classificazione testuale nel panorama NLP
- Incoraggiare l'applicazione pratica dei concetti appresi
- Rendersi disponibili per approfondimenti futuri

Messaggio finale: "La classificazione del testo Ã¨ uno dei campi piÃ¹ maturi e immediatamente applicabili dell'NLP. Spero che questo modulo vi abbia fornito le basi per iniziare a esplorare queste tecniche nei vostri progetti."
-->