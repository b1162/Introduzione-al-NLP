<!DOCTYPE html><html lang="en-US"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,height=device-height,initial-scale=1.0"><meta name="apple-mobile-web-app-capable" content="yes"><meta http-equiv="X-UA-Compatible" content="ie=edge"><meta property="og:type" content="website"><meta name="twitter:card" content="summary"><style>@media screen{body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button,body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container button,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container button{appearance:none;background-color:initial;border:0;color:inherit;cursor:pointer;font-size:inherit;opacity:.8;outline:none;padding:0;transition:opacity .2s linear;-webkit-tap-highlight-color:transparent}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button:disabled,body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button:disabled,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container button:disabled,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container button:disabled{cursor:not-allowed;opacity:.15!important}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button:hover,body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button:hover,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container button:hover,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container button:hover{opacity:1}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button:hover:active,body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button:hover:active,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container button:hover:active,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container button:hover:active{opacity:.6}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button:hover:not(:disabled),body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button:hover:not(:disabled),body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container button:hover:not(:disabled),body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container button:hover:not(:disabled){transition:none}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=prev],body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=prev],body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container button.bespoke-marp-presenter-info-page-prev{background:#0000 url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxMDAgMTAwIj48cGF0aCBmaWxsPSJub25lIiBzdHJva2U9IiNmZmYiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIgc3Ryb2tlLWxpbmVqb2luPSJyb3VuZCIgc3Ryb2tlLXdpZHRoPSI1IiBkPSJNNjggOTAgMjggNTBsNDAtNDAiLz48L3N2Zz4=") no-repeat 50%;background-size:contain;overflow:hidden;text-indent:100%;white-space:nowrap}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=next],body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=next],body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container button.bespoke-marp-presenter-info-page-next{background:#0000 url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxMDAgMTAwIj48cGF0aCBmaWxsPSJub25lIiBzdHJva2U9IiNmZmYiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIgc3Ryb2tlLWxpbmVqb2luPSJyb3VuZCIgc3Ryb2tlLXdpZHRoPSI1IiBkPSJtMzIgOTAgNDAtNDAtNDAtNDAiLz48L3N2Zz4=") no-repeat 50%;background-size:contain;overflow:hidden;text-indent:100%;white-space:nowrap}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=fullscreen],body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=fullscreen]{background:#0000 url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxMDAgMTAwIj48ZGVmcz48c3R5bGU+LmF7ZmlsbDpub25lO3N0cm9rZTojZmZmO3N0cm9rZS1saW5lY2FwOnJvdW5kO3N0cm9rZS1saW5lam9pbjpyb3VuZDtzdHJva2Utd2lkdGg6NXB4fTwvc3R5bGU+PC9kZWZzPjxyZWN0IHdpZHRoPSI4MCIgaGVpZ2h0PSI2MCIgeD0iMTAiIHk9IjIwIiBjbGFzcz0iYSIgcng9IjUuNjciLz48cGF0aCBkPSJNNDAgNzBIMjBWNTBtMjAgMEwyMCA3MG00MC00MGgyMHYyMG0tMjAgMCAyMC0yMCIgY2xhc3M9ImEiLz48L3N2Zz4=") no-repeat 50%;background-size:contain;overflow:hidden;text-indent:100%;white-space:nowrap}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button.exit[data-bespoke-marp-osc=fullscreen],body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button.exit[data-bespoke-marp-osc=fullscreen]{background-image:url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxMDAgMTAwIj48ZGVmcz48c3R5bGU+LmF7ZmlsbDpub25lO3N0cm9rZTojZmZmO3N0cm9rZS1saW5lY2FwOnJvdW5kO3N0cm9rZS1saW5lam9pbjpyb3VuZDtzdHJva2Utd2lkdGg6NXB4fTwvc3R5bGU+PC9kZWZzPjxyZWN0IHdpZHRoPSI4MCIgaGVpZ2h0PSI2MCIgeD0iMTAiIHk9IjIwIiBjbGFzcz0iYSIgcng9IjUuNjciLz48cGF0aCBkPSJNMjAgNTBoMjB2MjBtLTIwIDAgMjAtMjBtNDAgMEg2MFYzMG0yMCAwTDYwIDUwIiBjbGFzcz0iYSIvPjwvc3ZnPg==")}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=presenter],body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=presenter]{background:#0000 url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxMDAgMTAwIj48cGF0aCBmaWxsPSJub25lIiBzdHJva2U9IiNmZmYiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIgc3Ryb2tlLWxpbmVqb2luPSJyb3VuZCIgc3Ryb2tlLXdpZHRoPSI1IiBkPSJNODcuOCA0Ny41Qzg5IDUwIDg3LjcgNTIgODUgNTJIMzVhOC43IDguNyAwIDAgMS03LjItNC41bC0xNS42LTMxQzExIDE0IDEyLjIgMTIgMTUgMTJoNTBhOC44IDguOCAwIDAgMSA3LjIgNC41ek02MCA1MnYzNm0tMTAgMGgyME00NSA0MmgyMCIvPjwvc3ZnPg==") no-repeat 50%;background-size:contain;overflow:hidden;text-indent:100%;white-space:nowrap}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container button.bespoke-marp-presenter-note-bigger{background:#0000 url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxMDAgMTAwIj48cGF0aCBzdHJva2U9IiNmZmYiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIgc3Ryb2tlLWxpbmVqb2luPSJyb3VuZCIgc3Ryb2tlLXdpZHRoPSI1IiBkPSJNMTIgNTBoODBNNTIgOTBWMTAiLz48L3N2Zz4=") no-repeat 50%;background-size:contain;overflow:hidden;text-indent:100%;white-space:nowrap}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container button.bespoke-marp-presenter-note-smaller{background:#0000 url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxMDAgMTAwIj48cGF0aCBmaWxsPSJub25lIiBzdHJva2U9IiNmZmYiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIgc3Ryb2tlLWxpbmVqb2luPSJyb3VuZCIgc3Ryb2tlLXdpZHRoPSI1IiBkPSJNMTIgNTBoODAiLz48L3N2Zz4=") no-repeat 50%;background-size:contain;overflow:hidden;text-indent:100%;white-space:nowrap}}@keyframes __bespoke_marp_transition_reduced_outgoing__{0%{opacity:1}to{opacity:0}}@keyframes __bespoke_marp_transition_reduced_incoming__{0%{mix-blend-mode:plus-lighter;opacity:0}to{mix-blend-mode:plus-lighter;opacity:1}}.bespoke-marp-note,.bespoke-marp-osc,.bespoke-progress-parent{display:none;transition:none}@media screen{::view-transition-group(*){animation-duration:var(--marp-bespoke-transition-animation-duration,.5s);animation-timing-function:ease}::view-transition-new(*),::view-transition-old(*){animation-delay:0s;animation-direction:var(--marp-bespoke-transition-animation-direction,normal);animation-duration:var(--marp-bespoke-transition-animation-duration,.5s);animation-fill-mode:both;animation-name:var(--marp-bespoke-transition-animation-name,var(--marp-bespoke-transition-animation-name-fallback,__bespoke_marp_transition_no_animation__));mix-blend-mode:normal}::view-transition-old(*){--marp-bespoke-transition-animation-name-fallback:__bespoke_marp_transition_reduced_outgoing__;animation-timing-function:ease}::view-transition-new(*){--marp-bespoke-transition-animation-name-fallback:__bespoke_marp_transition_reduced_incoming__;animation-timing-function:ease}::view-transition-new(root),::view-transition-old(root){animation-timing-function:linear}::view-transition-new(__bespoke_marp_transition_osc__),::view-transition-old(__bespoke_marp_transition_osc__){animation-duration:0s!important;animation-name:__bespoke_marp_transition_osc__!important}::view-transition-new(__bespoke_marp_transition_osc__){opacity:0!important}.bespoke-marp-transition-warming-up::view-transition-group(*),.bespoke-marp-transition-warming-up::view-transition-new(*),.bespoke-marp-transition-warming-up::view-transition-old(*){animation-play-state:paused!important}body,html{height:100%;margin:0}body{background:#000;overflow:hidden}svg.bespoke-marp-slide{content-visibility:hidden;opacity:0;pointer-events:none;z-index:-1}svg.bespoke-marp-slide:not(.bespoke-marp-active) *{view-transition-name:none!important}svg.bespoke-marp-slide.bespoke-marp-active{content-visibility:visible;opacity:1;pointer-events:auto;z-index:0}svg.bespoke-marp-slide.bespoke-marp-active.bespoke-marp-active-ready *{animation-name:__bespoke_marp__!important}@supports not (content-visibility:hidden){svg.bespoke-marp-slide[data-bespoke-marp-load=hideable]{display:none}svg.bespoke-marp-slide[data-bespoke-marp-load=hideable].bespoke-marp-active{display:block}}}@media screen and (prefers-reduced-motion:reduce){svg.bespoke-marp-slide *{view-transition-name:none!important}}@media screen{[data-bespoke-marp-fragment=inactive]{visibility:hidden}body[data-bespoke-view=""] .bespoke-marp-parent,body[data-bespoke-view=next] .bespoke-marp-parent{inset:0;position:absolute}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc,body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc{background:#000000a6;border-radius:7px;bottom:50px;color:#fff;contain:paint;display:block;font-family:Helvetica,Arial,sans-serif;font-size:16px;left:50%;line-height:0;opacity:1;padding:12px;position:absolute;touch-action:manipulation;transform:translateX(-50%);transition:opacity .2s linear;-webkit-user-select:none;user-select:none;white-space:nowrap;will-change:transform;z-index:1;view-transition-name:__bespoke_marp_transition_osc__}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>*,body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>*{margin-left:6px}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>:first-child,body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>:first-child{margin-left:0}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>span,body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>span{opacity:.8}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>span[data-bespoke-marp-osc=page],body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>span[data-bespoke-marp-osc=page]{display:inline-block;min-width:140px;text-align:center}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=fullscreen],body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=next],body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=presenter],body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=prev],body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=fullscreen],body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=next],body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=presenter],body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=prev]{height:32px;line-height:32px;width:32px}body[data-bespoke-view=""] .bespoke-marp-parent.bespoke-marp-inactive,body[data-bespoke-view=next] .bespoke-marp-parent.bespoke-marp-inactive{cursor:none}body[data-bespoke-view=""] .bespoke-marp-parent.bespoke-marp-inactive>.bespoke-marp-osc,body[data-bespoke-view=next] .bespoke-marp-parent.bespoke-marp-inactive>.bespoke-marp-osc{opacity:0;pointer-events:none}body[data-bespoke-view=""] svg.bespoke-marp-slide,body[data-bespoke-view=next] svg.bespoke-marp-slide{height:100%;left:0;position:absolute;top:0;width:100%}body[data-bespoke-view=""] .bespoke-progress-parent{background:#222;display:flex;height:5px;width:100%}body[data-bespoke-view=""] .bespoke-progress-parent+.bespoke-marp-parent{top:5px}body[data-bespoke-view=""] .bespoke-progress-parent .bespoke-progress-bar{background:#0288d1;flex:0 0 0;transition:flex-basis .2s cubic-bezier(0,1,1,1)}body[data-bespoke-view=next]{background:#0000}body[data-bespoke-view=presenter]{background:#161616}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container{display:grid;font-family:Helvetica,Arial,sans-serif;grid-template:"current dragbar next" minmax(140px,1fr) "current dragbar note" 2fr "info    dragbar note" 3em;grid-template-columns:minmax(3px,var(--bespoke-marp-presenter-split-ratio,66%)) 0 minmax(3px,1fr);height:100%;left:0;position:absolute;top:0;width:100%}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-parent{grid-area:current;overflow:hidden;position:relative}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-parent svg.bespoke-marp-slide{height:calc(100% - 40px);left:20px;pointer-events:none;position:absolute;top:20px;-webkit-user-select:none;user-select:none;width:calc(100% - 40px)}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-parent svg.bespoke-marp-slide.bespoke-marp-active{filter:drop-shadow(0 3px 10px rgba(0,0,0,.5))}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-dragbar-container{background:#0288d1;cursor:col-resize;grid-area:dragbar;margin-left:-3px;opacity:0;position:relative;transition:opacity .4s linear .1s;width:6px;z-index:10}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-dragbar-container:hover{opacity:1}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-dragbar-container.active{opacity:1;transition-delay:0s}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-next-container{background:#222;cursor:pointer;display:none;grid-area:next;overflow:hidden;position:relative}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-next-container.active{display:block}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-next-container iframe.bespoke-marp-presenter-next{background:#0000;border:0;display:block;filter:drop-shadow(0 3px 10px rgba(0,0,0,.5));height:calc(100% - 40px);left:20px;pointer-events:none;position:absolute;top:20px;-webkit-user-select:none;user-select:none;width:calc(100% - 40px)}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container{background:#222;color:#eee;grid-area:note;position:relative;z-index:1}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container button{height:1.5em;line-height:1.5em;width:1.5em}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-presenter-note-wrapper{display:block;inset:0;position:absolute}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-presenter-note-buttons{background:#000000a6;border-radius:4px;bottom:0;display:flex;gap:4px;margin:12px;opacity:0;padding:6px;pointer-events:none;position:absolute;right:0;transition:opacity .2s linear}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-presenter-note-buttons:focus-within,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-presenter-note-wrapper:focus-within+.bespoke-marp-presenter-note-buttons,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container:hover .bespoke-marp-presenter-note-buttons{opacity:1;pointer-events:auto}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-note{box-sizing:border-box;font-size:calc(1.1em*var(--bespoke-marp-note-font-scale, 1));height:calc(100% - 40px);margin:20px;overflow:auto;padding-right:3px;white-space:pre-wrap;width:calc(100% - 40px);word-wrap:break-word;scrollbar-color:#eeeeee80 #0000;scrollbar-width:thin}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-note::-webkit-scrollbar{width:6px}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-note::-webkit-scrollbar-track{background:#0000}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-note::-webkit-scrollbar-thumb{background:#eeeeee80;border-radius:6px}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-note:empty{pointer-events:none}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-note.active{display:block}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-note p:first-child{margin-top:0}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-note p:last-child{margin-bottom:0}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container{align-items:center;box-sizing:border-box;color:#eee;display:flex;flex-wrap:nowrap;grid-area:info;justify-content:center;overflow:hidden;padding:0 10px}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container .bespoke-marp-presenter-info-page,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container .bespoke-marp-presenter-info-time,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container .bespoke-marp-presenter-info-timer{box-sizing:border-box;display:block;padding:0 10px;white-space:nowrap;width:100%}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container button{height:1.5em;line-height:1.5em;width:1.5em}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container .bespoke-marp-presenter-info-page{order:2;text-align:center}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container .bespoke-marp-presenter-info-page .bespoke-marp-presenter-info-page-text{display:inline-block;min-width:120px;text-align:center}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container .bespoke-marp-presenter-info-time{color:#999;order:1;text-align:left}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container .bespoke-marp-presenter-info-timer{color:#999;order:3;text-align:right}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container .bespoke-marp-presenter-info-timer:hover{cursor:pointer}}@media print{.bespoke-marp-presenter-info-container,.bespoke-marp-presenter-next-container,.bespoke-marp-presenter-note-container{display:none}}</style><style>div#\:\$p > svg > foreignObject > section{width:1280px;height:720px;box-sizing:border-box;overflow:hidden;position:relative;scroll-snap-align:center center;-webkit-text-size-adjust:100%;text-size-adjust:100%}div#\:\$p > svg > foreignObject > section::after{bottom:0;content:attr(data-marpit-pagination);padding:inherit;pointer-events:none;position:absolute;right:0}div#\:\$p > svg > foreignObject > section:not([data-marpit-pagination])::after{display:none}div#\:\$p > svg > foreignObject > section :is(h1, marp-h1){font-size:2em;margin:0.67em 0}div#\:\$p > svg > foreignObject > section video::-webkit-media-controls{will-change:transform}@page {size:1280px 720px;margin:0}@media print{html, body{background-color:#fff;margin:0;page-break-inside:avoid;break-inside:avoid-page}div#\:\$p > svg > foreignObject > section{page-break-before:always;break-before:page}div#\:\$p > svg > foreignObject > section, div#\:\$p > svg > foreignObject > section *{-webkit-print-color-adjust:exact!important;animation-delay:0s!important;animation-duration:0s!important;color-adjust:exact!important;transition:none!important}div#\:\$p > svg[data-marpit-svg]{display:block;height:100vh;width:100vw}}div#\:\$p > svg > foreignObject > :where(section){container-type:size}div#\:\$p > svg > foreignObject > section img[data-marp-twemoji]{background:transparent;height:1em;margin:0 .05em 0 .1em;vertical-align:-.1em;width:1em}/*!
 * Marp default theme.
 *
 * @theme default
 * @author Yuki Hattori
 *
 * @auto-scaling true
 * @size 16:9 1280px 720px
 * @size 4:3 960px 720px
 */div#\:\$p > svg > foreignObject > section{--base-size-4:calc(var(--marpit-root-font-size, 1rem) * 0.25);--base-size-8:calc(var(--marpit-root-font-size, 1rem) * 0.5);--base-size-16:calc(var(--marpit-root-font-size, 1rem) * 1);--base-size-24:calc(var(--marpit-root-font-size, 1rem) * 1.5);--base-size-40:calc(var(--marpit-root-font-size, 1rem) * 2.5);--base-text-weight-normal:400;--base-text-weight-medium:500;--base-text-weight-semibold:600;--fontStack-monospace:ui-monospace, SFMono-Regular, SF Mono, Menlo, Consolas, Liberation Mono, monospace;--fgColor-accent:Highlight;}div#\:\$p > svg > foreignObject > section [data-theme=light],div#\:\$p > svg > foreignObject > section{color-scheme:light;--focus-outlineColor:#0969da;--fgColor-default:#1f2328;--fgColor-muted:#59636e;--fgColor-accent:#0969da;--fgColor-success:#1a7f37;--fgColor-attention:#9a6700;--fgColor-danger:#d1242f;--fgColor-done:#8250df;--bgColor-default:#fff;--bgColor-muted:#f6f8fa;--bgColor-neutral-muted:#818b981f;--bgColor-attention-muted:#fff8c5;--borderColor-default:#d1d9e0;--borderColor-muted:#d1d9e0b3;--borderColor-neutral-muted:#d1d9e0b3;--borderColor-accent-emphasis:#0969da;--borderColor-success-emphasis:#1a7f37;--borderColor-attention-emphasis:#9a6700;--borderColor-danger-emphasis:#cf222e;--borderColor-done-emphasis:#8250df;--color-prettylights-syntax-comment:#59636e;--color-prettylights-syntax-constant:#0550ae;--color-prettylights-syntax-constant-other-reference-link:#0a3069;--color-prettylights-syntax-entity:#6639ba;--color-prettylights-syntax-storage-modifier-import:#1f2328;--color-prettylights-syntax-entity-tag:#0550ae;--color-prettylights-syntax-keyword:#cf222e;--color-prettylights-syntax-string:#0a3069;--color-prettylights-syntax-variable:#953800;--color-prettylights-syntax-brackethighlighter-unmatched:#82071e;--color-prettylights-syntax-brackethighlighter-angle:#59636e;--color-prettylights-syntax-invalid-illegal-text:#f6f8fa;--color-prettylights-syntax-invalid-illegal-bg:#82071e;--color-prettylights-syntax-carriage-return-text:#f6f8fa;--color-prettylights-syntax-carriage-return-bg:#cf222e;--color-prettylights-syntax-string-regexp:#116329;--color-prettylights-syntax-markup-list:#3b2300;--color-prettylights-syntax-markup-heading:#0550ae;--color-prettylights-syntax-markup-italic:#1f2328;--color-prettylights-syntax-markup-bold:#1f2328;--color-prettylights-syntax-markup-deleted-text:#82071e;--color-prettylights-syntax-markup-deleted-bg:#ffebe9;--color-prettylights-syntax-markup-inserted-text:#116329;--color-prettylights-syntax-markup-inserted-bg:#dafbe1;--color-prettylights-syntax-markup-changed-text:#953800;--color-prettylights-syntax-markup-changed-bg:#ffd8b5;--color-prettylights-syntax-markup-ignored-text:#d1d9e0;--color-prettylights-syntax-markup-ignored-bg:#0550ae;--color-prettylights-syntax-meta-diff-range:#8250df;--color-prettylights-syntax-sublimelinter-gutter-mark:#818b98;}div#\:\$p > svg > foreignObject > section [data-theme=dark],div#\:\$p > svg > foreignObject > section:where(.invert){color-scheme:dark;--focus-outlineColor:#1f6feb;--fgColor-default:#f0f6fc;--fgColor-muted:#9198a1;--fgColor-accent:#4493f8;--fgColor-success:#3fb950;--fgColor-attention:#d29922;--fgColor-danger:#f85149;--fgColor-done:#ab7df8;--bgColor-default:#0d1117;--bgColor-muted:#151b23;--bgColor-neutral-muted:#656c7633;--bgColor-attention-muted:#bb800926;--borderColor-default:#3d444d;--borderColor-muted:#3d444db3;--borderColor-neutral-muted:#3d444db3;--borderColor-accent-emphasis:#1f6feb;--borderColor-success-emphasis:#238636;--borderColor-attention-emphasis:#9e6a03;--borderColor-danger-emphasis:#da3633;--borderColor-done-emphasis:#8957e5;--color-prettylights-syntax-comment:#9198a1;--color-prettylights-syntax-constant:#79c0ff;--color-prettylights-syntax-constant-other-reference-link:#a5d6ff;--color-prettylights-syntax-entity:#d2a8ff;--color-prettylights-syntax-storage-modifier-import:#f0f6fc;--color-prettylights-syntax-entity-tag:#7ee787;--color-prettylights-syntax-keyword:#ff7b72;--color-prettylights-syntax-string:#a5d6ff;--color-prettylights-syntax-variable:#ffa657;--color-prettylights-syntax-brackethighlighter-unmatched:#f85149;--color-prettylights-syntax-brackethighlighter-angle:#9198a1;--color-prettylights-syntax-invalid-illegal-text:#f0f6fc;--color-prettylights-syntax-invalid-illegal-bg:#8e1519;--color-prettylights-syntax-carriage-return-text:#f0f6fc;--color-prettylights-syntax-carriage-return-bg:#b62324;--color-prettylights-syntax-string-regexp:#7ee787;--color-prettylights-syntax-markup-list:#f2cc60;--color-prettylights-syntax-markup-heading:#1f6feb;--color-prettylights-syntax-markup-italic:#f0f6fc;--color-prettylights-syntax-markup-bold:#f0f6fc;--color-prettylights-syntax-markup-deleted-text:#ffdcd7;--color-prettylights-syntax-markup-deleted-bg:#67060c;--color-prettylights-syntax-markup-inserted-text:#aff5b4;--color-prettylights-syntax-markup-inserted-bg:#033a16;--color-prettylights-syntax-markup-changed-text:#ffdfb6;--color-prettylights-syntax-markup-changed-bg:#5a1e02;--color-prettylights-syntax-markup-ignored-text:#f0f6fc;--color-prettylights-syntax-markup-ignored-bg:#1158c7;--color-prettylights-syntax-meta-diff-range:#d2a8ff;--color-prettylights-syntax-sublimelinter-gutter-mark:#3d444d;}div#\:\$p > svg > foreignObject > section{-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;background-color:var(--bgColor-default);color:var(--fgColor-default);font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Noto Sans,Helvetica,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji;font-size:16px;line-height:1.5;margin:0;word-wrap:break-word}div#\:\$p > svg > foreignObject > section{--marpit-root-font-size:16px;}div#\:\$p > svg > foreignObject > section :is(h1, marp-h1):hover .anchor .octicon-link:before,div#\:\$p > svg > foreignObject > section :is(h2, marp-h2):hover .anchor .octicon-link:before,div#\:\$p > svg > foreignObject > section :is(h3, marp-h3):hover .anchor .octicon-link:before,div#\:\$p > svg > foreignObject > section :is(h4, marp-h4):hover .anchor .octicon-link:before,div#\:\$p > svg > foreignObject > section :is(h5, marp-h5):hover .anchor .octicon-link:before,div#\:\$p > svg > foreignObject > section :is(h6, marp-h6):hover .anchor .octicon-link:before{background-color:currentColor;content:" ";display:inline-block;height:16px;-webkit-mask-image:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 0 0 1.06 1.06l1.25-1.25a2 2 0 1 1 2.83 2.83l-2.5 2.5a2 2 0 0 1-2.83 0 .75.75 0 0 0-1.06 1.06 3.5 3.5 0 0 0 4.95 0l2.5-2.5a3.5 3.5 0 0 0-4.95-4.95zm-4.69 9.64a2 2 0 0 1 0-2.83l2.5-2.5a2 2 0 0 1 2.83 0 .75.75 0 0 0 1.06-1.06 3.5 3.5 0 0 0-4.95 0l-2.5 2.5a3.5 3.5 0 0 0 4.95 4.95l1.25-1.25a.75.75 0 0 0-1.06-1.06l-1.25 1.25a2 2 0 0 1-2.83 0"/></svg>');mask-image:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 0 0 1.06 1.06l1.25-1.25a2 2 0 1 1 2.83 2.83l-2.5 2.5a2 2 0 0 1-2.83 0 .75.75 0 0 0-1.06 1.06 3.5 3.5 0 0 0 4.95 0l2.5-2.5a3.5 3.5 0 0 0-4.95-4.95zm-4.69 9.64a2 2 0 0 1 0-2.83l2.5-2.5a2 2 0 0 1 2.83 0 .75.75 0 0 0 1.06-1.06 3.5 3.5 0 0 0-4.95 0l-2.5 2.5a3.5 3.5 0 0 0 4.95 4.95l1.25-1.25a.75.75 0 0 0-1.06-1.06l-1.25 1.25a2 2 0 0 1-2.83 0"/></svg>');width:16px}div#\:\$p > svg > foreignObject > section details,div#\:\$p > svg > foreignObject > section figcaption,div#\:\$p > svg > foreignObject > section figure{display:block}div#\:\$p > svg > foreignObject > section summary{display:list-item}div#\:\$p > svg > foreignObject > section [hidden]{display:none!important}div#\:\$p > svg > foreignObject > section a{background-color:transparent;color:var(--fgColor-accent);text-decoration:none}div#\:\$p > svg > foreignObject > section abbr[title]{border-bottom:none;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}div#\:\$p > svg > foreignObject > section b,div#\:\$p > svg > foreignObject > section strong{font-weight:var(--base-text-weight-semibold, 600)}div#\:\$p > svg > foreignObject > section dfn{font-style:italic}div#\:\$p > svg > foreignObject > section :is(h1, marp-h1){border-bottom:1px solid var(--borderColor-muted);font-size:2em;font-weight:var(--base-text-weight-semibold, 600);margin:.67em 0;padding-bottom:.3em}div#\:\$p > svg > foreignObject > section mark{background-color:var(--bgColor-attention-muted);color:var(--fgColor-default)}div#\:\$p > svg > foreignObject > section small{font-size:90%}div#\:\$p > svg > foreignObject > section sub,div#\:\$p > svg > foreignObject > section sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}div#\:\$p > svg > foreignObject > section sub{bottom:-.25em}div#\:\$p > svg > foreignObject > section sup{top:-.5em}div#\:\$p > svg > foreignObject > section img{border-style:none;box-sizing:content-box;max-width:100%}div#\:\$p > svg > foreignObject > section code,div#\:\$p > svg > foreignObject > section kbd,div#\:\$p > svg > foreignObject > section :is(pre, marp-pre),div#\:\$p > svg > foreignObject > section samp{font-family:monospace;font-size:1em}div#\:\$p > svg > foreignObject > section figure{margin:1em var(--base-size-40)}div#\:\$p > svg > foreignObject > section hr{background:transparent;background-color:var(--borderColor-default);border:0;box-sizing:content-box;height:.25em;margin:var(--base-size-24) 0;overflow:hidden;padding:0}div#\:\$p > svg > foreignObject > section input{font:inherit;font-family:inherit;font-size:inherit;line-height:inherit;margin:0;overflow:visible}div#\:\$p > svg > foreignObject > section [type=button],div#\:\$p > svg > foreignObject > section [type=reset],div#\:\$p > svg > foreignObject > section [type=submit]{-webkit-appearance:button;-moz-appearance:button;appearance:button}div#\:\$p > svg > foreignObject > section [type=checkbox],div#\:\$p > svg > foreignObject > section [type=radio]{box-sizing:border-box;padding:0}div#\:\$p > svg > foreignObject > section [type=number]::-webkit-inner-spin-button,div#\:\$p > svg > foreignObject > section [type=number]::-webkit-outer-spin-button{height:auto}div#\:\$p > svg > foreignObject > section [type=search]::-webkit-search-cancel-button,div#\:\$p > svg > foreignObject > section [type=search]::-webkit-search-decoration{-webkit-appearance:none;appearance:none}div#\:\$p > svg > foreignObject > section ::-webkit-input-placeholder{color:inherit;opacity:.54}div#\:\$p > svg > foreignObject > section ::-webkit-file-upload-button{-webkit-appearance:button;appearance:button;font:inherit}div#\:\$p > svg > foreignObject > section a:hover{text-decoration:underline}div#\:\$p > svg > foreignObject > section ::-moz-placeholder{color:var(--fgColor-muted);opacity:1}div#\:\$p > svg > foreignObject > section ::placeholder{color:var(--fgColor-muted);opacity:1}div#\:\$p > svg > foreignObject > section hr:after,div#\:\$p > svg > foreignObject > section hr:before{content:"";display:table}div#\:\$p > svg > foreignObject > section hr:after{clear:both}div#\:\$p > svg > foreignObject > section table{border-collapse:collapse;border-spacing:0;display:block;font-variant:tabular-nums;max-width:100%;overflow:auto;width:-moz-max-content;width:max-content}div#\:\$p > svg > foreignObject > section td,div#\:\$p > svg > foreignObject > section th{padding:0}div#\:\$p > svg > foreignObject > section details summary{cursor:pointer}div#\:\$p > svg > foreignObject > section [role=button]:focus,div#\:\$p > svg > foreignObject > section a:focus,div#\:\$p > svg > foreignObject > section input[type=checkbox]:focus,div#\:\$p > svg > foreignObject > section input[type=radio]:focus{box-shadow:none;outline:2px solid var(--focus-outlineColor);outline-offset:-2px}div#\:\$p > svg > foreignObject > section [role=button]:focus:not(:focus-visible),div#\:\$p > svg > foreignObject > section a:focus:not(:focus-visible),div#\:\$p > svg > foreignObject > section input[type=checkbox]:focus:not(:focus-visible),div#\:\$p > svg > foreignObject > section input[type=radio]:focus:not(:focus-visible){outline:1px solid transparent}div#\:\$p > svg > foreignObject > section [role=button]:focus-visible,div#\:\$p > svg > foreignObject > section a:focus-visible,div#\:\$p > svg > foreignObject > section input[type=checkbox]:focus-visible,div#\:\$p > svg > foreignObject > section input[type=radio]:focus-visible{box-shadow:none;outline:2px solid var(--focus-outlineColor);outline-offset:-2px}div#\:\$p > svg > foreignObject > section a:not([class]):focus,div#\:\$p > svg > foreignObject > section a:not([class]):focus-visible,div#\:\$p > svg > foreignObject > section input[type=checkbox]:focus,div#\:\$p > svg > foreignObject > section input[type=checkbox]:focus-visible,div#\:\$p > svg > foreignObject > section input[type=radio]:focus,div#\:\$p > svg > foreignObject > section input[type=radio]:focus-visible{outline-offset:0}div#\:\$p > svg > foreignObject > section kbd{background-color:var(--bgColor-muted);border-bottom-color:var(--borderColor-neutral-muted);border:1px solid var(--borderColor-neutral-muted);border-radius:6px;box-shadow:inset 0 -1px 0 var(--borderColor-neutral-muted);color:var(--fgColor-default);display:inline-block;font:11px var(--fontStack-monospace, ui-monospace, SFMono-Regular, SF Mono, Menlo, Consolas, Liberation Mono, monospace);line-height:10px;padding:var(--base-size-4);vertical-align:middle}div#\:\$p > svg > foreignObject > section :is(h1, marp-h1),div#\:\$p > svg > foreignObject > section :is(h2, marp-h2),div#\:\$p > svg > foreignObject > section :is(h3, marp-h3),div#\:\$p > svg > foreignObject > section :is(h4, marp-h4),div#\:\$p > svg > foreignObject > section :is(h5, marp-h5),div#\:\$p > svg > foreignObject > section :is(h6, marp-h6){font-weight:var(--base-text-weight-semibold, 600);line-height:1.25;margin-bottom:var(--base-size-16);margin-top:var(--base-size-24)}div#\:\$p > svg > foreignObject > section :is(h2, marp-h2){border-bottom:1px solid var(--borderColor-muted);font-size:1.5em;padding-bottom:.3em}div#\:\$p > svg > foreignObject > section :is(h2, marp-h2),div#\:\$p > svg > foreignObject > section :is(h3, marp-h3){font-weight:var(--base-text-weight-semibold, 600)}div#\:\$p > svg > foreignObject > section :is(h3, marp-h3){font-size:1.25em}div#\:\$p > svg > foreignObject > section :is(h4, marp-h4){font-size:1em}div#\:\$p > svg > foreignObject > section :is(h4, marp-h4),div#\:\$p > svg > foreignObject > section :is(h5, marp-h5){font-weight:var(--base-text-weight-semibold, 600)}div#\:\$p > svg > foreignObject > section :is(h5, marp-h5){font-size:.875em}div#\:\$p > svg > foreignObject > section :is(h6, marp-h6){color:var(--fgColor-muted);font-size:.85em;font-weight:var(--base-text-weight-semibold, 600)}div#\:\$p > svg > foreignObject > section p{margin-bottom:10px;margin-top:0}div#\:\$p > svg > foreignObject > section blockquote{border-left:.25em solid var(--borderColor-default);color:var(--fgColor-muted);margin:0;padding:0 1em}div#\:\$p > svg > foreignObject > section ol,div#\:\$p > svg > foreignObject > section ul{margin-bottom:0;margin-top:0;padding-left:2em}div#\:\$p > svg > foreignObject > section ol ol,div#\:\$p > svg > foreignObject > section ul ol{list-style-type:lower-roman}div#\:\$p > svg > foreignObject > section ol ol ol,div#\:\$p > svg > foreignObject > section ol ul ol,div#\:\$p > svg > foreignObject > section ul ol ol,div#\:\$p > svg > foreignObject > section ul ul ol{list-style-type:lower-alpha}div#\:\$p > svg > foreignObject > section dd{margin-left:0}div#\:\$p > svg > foreignObject > section code,div#\:\$p > svg > foreignObject > section :is(pre, marp-pre),div#\:\$p > svg > foreignObject > section samp,div#\:\$p > svg > foreignObject > section tt{font-family:var(--fontStack-monospace, ui-monospace, SFMono-Regular, SF Mono, Menlo, Consolas, Liberation Mono, monospace);font-size:12px}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre){margin-bottom:0;margin-top:0;word-wrap:normal}div#\:\$p > svg > foreignObject > section .octicon{display:inline-block;overflow:visible!important;vertical-align:text-bottom;fill:currentColor}div#\:\$p > svg > foreignObject > section input::-webkit-inner-spin-button,div#\:\$p > svg > foreignObject > section input::-webkit-outer-spin-button{-webkit-appearance:none;appearance:none;margin:0}div#\:\$p > svg > foreignObject > section .mr-2{margin-right:var(--base-size-8, 8px)!important}div#\:\$p > svg > foreignObject > section:after,div#\:\$p > svg > foreignObject > section:before{display:table}div#\:\$p > svg > foreignObject > section:after{clear:both}div#\:\$p > svg > foreignObject > section>:first-child{margin-top:0!important}div#\:\$p > svg > foreignObject > section>:last-child{margin-bottom:0!important}div#\:\$p > svg > foreignObject > section a:not([href]){color:inherit;text-decoration:none}div#\:\$p > svg > foreignObject > section .absent{color:var(--fgColor-danger)}div#\:\$p > svg > foreignObject > section .anchor{float:left;line-height:1;margin-left:-20px;padding-right:var(--base-size-4)}div#\:\$p > svg > foreignObject > section .anchor:focus{outline:none}div#\:\$p > svg > foreignObject > section blockquote,div#\:\$p > svg > foreignObject > section details,div#\:\$p > svg > foreignObject > section dl,div#\:\$p > svg > foreignObject > section ol,div#\:\$p > svg > foreignObject > section p,div#\:\$p > svg > foreignObject > section :is(pre, marp-pre),div#\:\$p > svg > foreignObject > section table,div#\:\$p > svg > foreignObject > section ul{margin-bottom:var(--base-size-16);margin-top:0}div#\:\$p > svg > foreignObject > section blockquote>:first-child{margin-top:0}div#\:\$p > svg > foreignObject > section blockquote>:last-child{margin-bottom:0}div#\:\$p > svg > foreignObject > section :is(h1, marp-h1) .octicon-link,div#\:\$p > svg > foreignObject > section :is(h2, marp-h2) .octicon-link,div#\:\$p > svg > foreignObject > section :is(h3, marp-h3) .octicon-link,div#\:\$p > svg > foreignObject > section :is(h4, marp-h4) .octicon-link,div#\:\$p > svg > foreignObject > section :is(h5, marp-h5) .octicon-link,div#\:\$p > svg > foreignObject > section :is(h6, marp-h6) .octicon-link{color:var(--fgColor-default);vertical-align:middle;visibility:hidden}div#\:\$p > svg > foreignObject > section :is(h1, marp-h1):hover .anchor,div#\:\$p > svg > foreignObject > section :is(h2, marp-h2):hover .anchor,div#\:\$p > svg > foreignObject > section :is(h3, marp-h3):hover .anchor,div#\:\$p > svg > foreignObject > section :is(h4, marp-h4):hover .anchor,div#\:\$p > svg > foreignObject > section :is(h5, marp-h5):hover .anchor,div#\:\$p > svg > foreignObject > section :is(h6, marp-h6):hover .anchor{text-decoration:none}div#\:\$p > svg > foreignObject > section :is(h1, marp-h1):hover .anchor .octicon-link,div#\:\$p > svg > foreignObject > section :is(h2, marp-h2):hover .anchor .octicon-link,div#\:\$p > svg > foreignObject > section :is(h3, marp-h3):hover .anchor .octicon-link,div#\:\$p > svg > foreignObject > section :is(h4, marp-h4):hover .anchor .octicon-link,div#\:\$p > svg > foreignObject > section :is(h5, marp-h5):hover .anchor .octicon-link,div#\:\$p > svg > foreignObject > section :is(h6, marp-h6):hover .anchor .octicon-link{visibility:visible}div#\:\$p > svg > foreignObject > section :is(h1, marp-h1) code,div#\:\$p > svg > foreignObject > section :is(h1, marp-h1) tt,div#\:\$p > svg > foreignObject > section :is(h2, marp-h2) code,div#\:\$p > svg > foreignObject > section :is(h2, marp-h2) tt,div#\:\$p > svg > foreignObject > section :is(h3, marp-h3) code,div#\:\$p > svg > foreignObject > section :is(h3, marp-h3) tt,div#\:\$p > svg > foreignObject > section :is(h4, marp-h4) code,div#\:\$p > svg > foreignObject > section :is(h4, marp-h4) tt,div#\:\$p > svg > foreignObject > section :is(h5, marp-h5) code,div#\:\$p > svg > foreignObject > section :is(h5, marp-h5) tt,div#\:\$p > svg > foreignObject > section :is(h6, marp-h6) code,div#\:\$p > svg > foreignObject > section :is(h6, marp-h6) tt{font-size:inherit;padding:0 .2em}div#\:\$p > svg > foreignObject > section summary :is(h1, marp-h1),div#\:\$p > svg > foreignObject > section summary :is(h2, marp-h2),div#\:\$p > svg > foreignObject > section summary :is(h3, marp-h3),div#\:\$p > svg > foreignObject > section summary :is(h4, marp-h4),div#\:\$p > svg > foreignObject > section summary :is(h5, marp-h5),div#\:\$p > svg > foreignObject > section summary :is(h6, marp-h6){display:inline-block}div#\:\$p > svg > foreignObject > section summary :is(h1, marp-h1) .anchor,div#\:\$p > svg > foreignObject > section summary :is(h2, marp-h2) .anchor,div#\:\$p > svg > foreignObject > section summary :is(h3, marp-h3) .anchor,div#\:\$p > svg > foreignObject > section summary :is(h4, marp-h4) .anchor,div#\:\$p > svg > foreignObject > section summary :is(h5, marp-h5) .anchor,div#\:\$p > svg > foreignObject > section summary :is(h6, marp-h6) .anchor{margin-left:-40px}div#\:\$p > svg > foreignObject > section summary :is(h1, marp-h1),div#\:\$p > svg > foreignObject > section summary :is(h2, marp-h2){border-bottom:0;padding-bottom:0}div#\:\$p > svg > foreignObject > section ol.no-list,div#\:\$p > svg > foreignObject > section ul.no-list{list-style-type:none;padding:0}div#\:\$p > svg > foreignObject > section ol[type="a s"]{list-style-type:lower-alpha}div#\:\$p > svg > foreignObject > section ol[type="A s"]{list-style-type:upper-alpha}div#\:\$p > svg > foreignObject > section ol[type="i s"]{list-style-type:lower-roman}div#\:\$p > svg > foreignObject > section ol[type="I s"]{list-style-type:upper-roman}div#\:\$p > svg > foreignObject > section div>ol:not([type]),div#\:\$p > svg > foreignObject > section ol[type="1"]{list-style-type:decimal}div#\:\$p > svg > foreignObject > section ol ol,div#\:\$p > svg > foreignObject > section ol ul,div#\:\$p > svg > foreignObject > section ul ol,div#\:\$p > svg > foreignObject > section ul ul{margin-bottom:0;margin-top:0}div#\:\$p > svg > foreignObject > section li>p{margin-top:var(--base-size-16)}div#\:\$p > svg > foreignObject > section li+li{margin-top:.25em}div#\:\$p > svg > foreignObject > section dl{padding:0}div#\:\$p > svg > foreignObject > section dl dt{font-size:1em;font-style:italic;font-weight:var(--base-text-weight-semibold, 600);margin-top:var(--base-size-16);padding:0}div#\:\$p > svg > foreignObject > section dl dd{margin-bottom:var(--base-size-16);padding:0 var(--base-size-16)}div#\:\$p > svg > foreignObject > section table th{font-weight:var(--base-text-weight-semibold, 600)}div#\:\$p > svg > foreignObject > section table td,div#\:\$p > svg > foreignObject > section table th{border:1px solid var(--borderColor-default);padding:6px 13px}div#\:\$p > svg > foreignObject > section table td>:last-child{margin-bottom:0}div#\:\$p > svg > foreignObject > section table tr{background-color:var(--bgColor-default);border-top:1px solid var(--borderColor-muted)}div#\:\$p > svg > foreignObject > section table tr:nth-child(2n){background-color:var(--bgColor-muted)}div#\:\$p > svg > foreignObject > section table img{background-color:transparent}div#\:\$p > svg > foreignObject > section img[align=right]{padding-left:20px}div#\:\$p > svg > foreignObject > section img[align=left]{padding-right:20px}div#\:\$p > svg > foreignObject > section .emoji{background-color:transparent;max-width:none;vertical-align:text-top}div#\:\$p > svg > foreignObject > section :is(span, marp-span).frame,div#\:\$p > svg > foreignObject > section :is(span, marp-span).frame>:is(span, marp-span){display:block;overflow:hidden}div#\:\$p > svg > foreignObject > section :is(span, marp-span).frame>:is(span, marp-span){border:1px solid var(--borderColor-default);float:left;margin:13px 0 0;padding:7px;width:auto}div#\:\$p > svg > foreignObject > section :is(span, marp-span).frame :is(span, marp-span) img{display:block;float:left}div#\:\$p > svg > foreignObject > section :is(span, marp-span).frame :is(span, marp-span) :is(span, marp-span){clear:both;color:var(--fgColor-default);display:block;padding:5px 0 0}div#\:\$p > svg > foreignObject > section :is(span, marp-span).align-center{clear:both;display:block;overflow:hidden}div#\:\$p > svg > foreignObject > section :is(span, marp-span).align-center>:is(span, marp-span){display:block;margin:13px auto 0;overflow:hidden;text-align:center}div#\:\$p > svg > foreignObject > section :is(span, marp-span).align-center :is(span, marp-span) img{margin:0 auto;text-align:center}div#\:\$p > svg > foreignObject > section :is(span, marp-span).align-right{clear:both;display:block;overflow:hidden}div#\:\$p > svg > foreignObject > section :is(span, marp-span).align-right>:is(span, marp-span){display:block;margin:13px 0 0;overflow:hidden;text-align:right}div#\:\$p > svg > foreignObject > section :is(span, marp-span).align-right :is(span, marp-span) img{margin:0;text-align:right}div#\:\$p > svg > foreignObject > section :is(span, marp-span).float-left{display:block;float:left;margin-right:13px;overflow:hidden}div#\:\$p > svg > foreignObject > section :is(span, marp-span).float-left :is(span, marp-span){margin:13px 0 0}div#\:\$p > svg > foreignObject > section :is(span, marp-span).float-right{display:block;float:right;margin-left:13px;overflow:hidden}div#\:\$p > svg > foreignObject > section :is(span, marp-span).float-right>:is(span, marp-span){display:block;margin:13px auto 0;overflow:hidden;text-align:right}div#\:\$p > svg > foreignObject > section code,div#\:\$p > svg > foreignObject > section tt{background-color:var(--bgColor-neutral-muted);border-radius:6px;font-size:85%;margin:0;padding:.2em .4em;white-space:break-spaces}div#\:\$p > svg > foreignObject > section code br,div#\:\$p > svg > foreignObject > section tt br{display:none}div#\:\$p > svg > foreignObject > section del code{text-decoration:inherit}div#\:\$p > svg > foreignObject > section samp{font-size:85%}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) code{font-size:100%}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre)>code{background:transparent;border:0;margin:0;padding:0;white-space:pre;word-break:normal}div#\:\$p > svg > foreignObject > section .highlight{margin-bottom:var(--base-size-16)}div#\:\$p > svg > foreignObject > section .highlight :is(pre, marp-pre){margin-bottom:0;word-break:normal}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre){background-color:var(--bgColor-muted);border-radius:6px;color:var(--fgColor-default);font-size:85%;line-height:1.45;overflow:auto;padding:var(--base-size-16)}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) code,div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) tt{display:inline;line-height:inherit;margin:0;max-width:auto;overflow:visible;padding:0;word-wrap:normal;background-color:transparent;border:0}div#\:\$p > svg > foreignObject > section .csv-data td,div#\:\$p > svg > foreignObject > section .csv-data th{font-size:12px;line-height:1;overflow:hidden;padding:5px;text-align:left;white-space:nowrap}div#\:\$p > svg > foreignObject > section .csv-data .blob-num{background:var(--bgColor-default);border:0;padding:10px var(--base-size-8) 9px;text-align:right}div#\:\$p > svg > foreignObject > section .csv-data tr{border-top:0}div#\:\$p > svg > foreignObject > section .csv-data th{background:var(--bgColor-muted);border-top:0;font-weight:var(--base-text-weight-semibold, 600)}div#\:\$p > svg > foreignObject > section [data-footnote-ref]:before{content:"["}div#\:\$p > svg > foreignObject > section [data-footnote-ref]:after{content:"]"}div#\:\$p > svg > foreignObject > section .footnotes{border-top:1px solid var(--borderColor-default);color:var(--fgColor-muted);font-size:12px}div#\:\$p > svg > foreignObject > section div#\:\$p > svg > foreignObject > section section.footnotes{--marpit-root-font-size:12px;}div#\:\$p > svg > foreignObject > section .footnotes ol,div#\:\$p > svg > foreignObject > section .footnotes ol ul{padding-left:var(--base-size-16)}div#\:\$p > svg > foreignObject > section .footnotes ol ul{display:inline-block;margin-top:var(--base-size-16)}div#\:\$p > svg > foreignObject > section .footnotes li{position:relative}div#\:\$p > svg > foreignObject > section .footnotes li:target:before{border:2px solid var(--borderColor-accent-emphasis);border-radius:6px;bottom:calc(var(--base-size-8)*-1);content:"";left:calc(var(--base-size-24)*-1);pointer-events:none;position:absolute;right:calc(var(--base-size-8)*-1);top:calc(var(--base-size-8)*-1)}div#\:\$p > svg > foreignObject > section .footnotes li:target{color:var(--fgColor-default)}div#\:\$p > svg > foreignObject > section .footnotes .data-footnote-backref g-emoji{font-family:monospace}div#\:\$p > svg > foreignObject > section body:has(:modal){padding-right:var(--dialog-scrollgutter)!important}div#\:\$p > svg > foreignObject > section .pl-c{color:var(--color-prettylights-syntax-comment)}div#\:\$p > svg > foreignObject > section .pl-c1,div#\:\$p > svg > foreignObject > section .pl-s .pl-v{color:var(--color-prettylights-syntax-constant)}div#\:\$p > svg > foreignObject > section .pl-e,div#\:\$p > svg > foreignObject > section .pl-en{color:var(--color-prettylights-syntax-entity)}div#\:\$p > svg > foreignObject > section .pl-s .pl-s1,div#\:\$p > svg > foreignObject > section .pl-smi{color:var(--color-prettylights-syntax-storage-modifier-import)}div#\:\$p > svg > foreignObject > section .pl-ent{color:var(--color-prettylights-syntax-entity-tag)}div#\:\$p > svg > foreignObject > section .pl-k{color:var(--color-prettylights-syntax-keyword)}div#\:\$p > svg > foreignObject > section .pl-pds,div#\:\$p > svg > foreignObject > section .pl-s,div#\:\$p > svg > foreignObject > section .pl-s .pl-pse .pl-s1,div#\:\$p > svg > foreignObject > section .pl-sr,div#\:\$p > svg > foreignObject > section .pl-sr .pl-cce,div#\:\$p > svg > foreignObject > section .pl-sr .pl-sra,div#\:\$p > svg > foreignObject > section .pl-sr .pl-sre{color:var(--color-prettylights-syntax-string)}div#\:\$p > svg > foreignObject > section .pl-smw,div#\:\$p > svg > foreignObject > section .pl-v{color:var(--color-prettylights-syntax-variable)}div#\:\$p > svg > foreignObject > section .pl-bu{color:var(--color-prettylights-syntax-brackethighlighter-unmatched)}div#\:\$p > svg > foreignObject > section .pl-ii{background-color:var(--color-prettylights-syntax-invalid-illegal-bg);color:var(--color-prettylights-syntax-invalid-illegal-text)}div#\:\$p > svg > foreignObject > section .pl-c2{background-color:var(--color-prettylights-syntax-carriage-return-bg);color:var(--color-prettylights-syntax-carriage-return-text)}div#\:\$p > svg > foreignObject > section .pl-sr .pl-cce{color:var(--color-prettylights-syntax-string-regexp);font-weight:700}div#\:\$p > svg > foreignObject > section .pl-ml{color:var(--color-prettylights-syntax-markup-list)}div#\:\$p > svg > foreignObject > section .pl-mh,div#\:\$p > svg > foreignObject > section .pl-mh .pl-en,div#\:\$p > svg > foreignObject > section .pl-ms{color:var(--color-prettylights-syntax-markup-heading);font-weight:700}div#\:\$p > svg > foreignObject > section .pl-mi{color:var(--color-prettylights-syntax-markup-italic);font-style:italic}div#\:\$p > svg > foreignObject > section .pl-mb{color:var(--color-prettylights-syntax-markup-bold);font-weight:700}div#\:\$p > svg > foreignObject > section .pl-md{background-color:var(--color-prettylights-syntax-markup-deleted-bg);color:var(--color-prettylights-syntax-markup-deleted-text)}div#\:\$p > svg > foreignObject > section .pl-mi1{background-color:var(--color-prettylights-syntax-markup-inserted-bg);color:var(--color-prettylights-syntax-markup-inserted-text)}div#\:\$p > svg > foreignObject > section .pl-mc{background-color:var(--color-prettylights-syntax-markup-changed-bg);color:var(--color-prettylights-syntax-markup-changed-text)}div#\:\$p > svg > foreignObject > section .pl-mi2{background-color:var(--color-prettylights-syntax-markup-ignored-bg);color:var(--color-prettylights-syntax-markup-ignored-text)}div#\:\$p > svg > foreignObject > section .pl-mdr{color:var(--color-prettylights-syntax-meta-diff-range);font-weight:700}div#\:\$p > svg > foreignObject > section .pl-ba{color:var(--color-prettylights-syntax-brackethighlighter-angle)}div#\:\$p > svg > foreignObject > section .pl-sg{color:var(--color-prettylights-syntax-sublimelinter-gutter-mark)}div#\:\$p > svg > foreignObject > section .pl-corl{color:var(--color-prettylights-syntax-constant-other-reference-link);text-decoration:underline}div#\:\$p > svg > foreignObject > section [role=button]:focus:not(:focus-visible),div#\:\$p > svg > foreignObject > section [role=tabpanel][tabindex="0"]:focus:not(:focus-visible),div#\:\$p > svg > foreignObject > section a:focus:not(:focus-visible),div#\:\$p > svg > foreignObject > section button:focus:not(:focus-visible),div#\:\$p > svg > foreignObject > section summary:focus:not(:focus-visible){box-shadow:none;outline:none}div#\:\$p > svg > foreignObject > section [tabindex="0"]:focus:not(:focus-visible),div#\:\$p > svg > foreignObject > section details-dialog:focus:not(:focus-visible){outline:none}div#\:\$p > svg > foreignObject > section g-emoji{display:inline-block;font-family:Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol;font-size:1em;font-style:normal!important;font-weight:var(--base-text-weight-normal, 400);line-height:1;min-width:1ch;vertical-align:-.075em}div#\:\$p > svg > foreignObject > section g-emoji img{height:1em;width:1em}div#\:\$p > svg > foreignObject > section .task-list-item{list-style-type:none}div#\:\$p > svg > foreignObject > section .task-list-item label{font-weight:var(--base-text-weight-normal, 400)}div#\:\$p > svg > foreignObject > section .task-list-item.enabled label{cursor:pointer}div#\:\$p > svg > foreignObject > section .task-list-item+.task-list-item{margin-top:var(--base-size-4)}div#\:\$p > svg > foreignObject > section .task-list-item .handle{display:none}div#\:\$p > svg > foreignObject > section .task-list-item-checkbox{margin:0 .2em .25em -1.4em;vertical-align:middle}div#\:\$p > svg > foreignObject > section ul:dir(rtl) .task-list-item-checkbox{margin:0 -1.6em .25em .2em}div#\:\$p > svg > foreignObject > section ol:dir(rtl) .task-list-item-checkbox{margin:0 -1.6em .25em .2em}div#\:\$p > svg > foreignObject > section .contains-task-list:focus-within .task-list-item-convert-container,div#\:\$p > svg > foreignObject > section .contains-task-list:hover .task-list-item-convert-container{display:block;height:24px;overflow:visible;width:auto;clip:auto}div#\:\$p > svg > foreignObject > section ::-webkit-calendar-picker-indicator{filter:invert(50%)}div#\:\$p > svg > foreignObject > section .markdown-alert{border-left:.25em solid var(--borderColor-default);color:inherit;margin-bottom:var(--base-size-16);padding:var(--base-size-8) var(--base-size-16)}div#\:\$p > svg > foreignObject > section .markdown-alert>:first-child{margin-top:0}div#\:\$p > svg > foreignObject > section .markdown-alert>:last-child{margin-bottom:0}div#\:\$p > svg > foreignObject > section .markdown-alert .markdown-alert-title{align-items:center;display:flex;font-weight:var(--base-text-weight-medium, 500);line-height:1}div#\:\$p > svg > foreignObject > section .markdown-alert.markdown-alert-note{border-left-color:var(--borderColor-accent-emphasis)}div#\:\$p > svg > foreignObject > section .markdown-alert.markdown-alert-note .markdown-alert-title{color:var(--fgColor-accent)}div#\:\$p > svg > foreignObject > section .markdown-alert.markdown-alert-important{border-left-color:var(--borderColor-done-emphasis)}div#\:\$p > svg > foreignObject > section .markdown-alert.markdown-alert-important .markdown-alert-title{color:var(--fgColor-done)}div#\:\$p > svg > foreignObject > section .markdown-alert.markdown-alert-warning{border-left-color:var(--borderColor-attention-emphasis)}div#\:\$p > svg > foreignObject > section .markdown-alert.markdown-alert-warning .markdown-alert-title{color:var(--fgColor-attention)}div#\:\$p > svg > foreignObject > section .markdown-alert.markdown-alert-tip{border-left-color:var(--borderColor-success-emphasis)}div#\:\$p > svg > foreignObject > section .markdown-alert.markdown-alert-tip .markdown-alert-title{color:var(--fgColor-success)}div#\:\$p > svg > foreignObject > section .markdown-alert.markdown-alert-caution{border-left-color:var(--borderColor-danger-emphasis)}div#\:\$p > svg > foreignObject > section .markdown-alert.markdown-alert-caution .markdown-alert-title{color:var(--fgColor-danger)}div#\:\$p > svg > foreignObject > section>:first-child>.heading-element:first-child{margin-top:0!important}div#\:\$p > svg > foreignObject > section .highlight :is(pre, marp-pre):has(+.zeroclipboard-container){min-height:52px}div#\:\$p > svg > foreignObject > section :is(h1, marp-h1){color:var(--h1-color);font-size:1.6em}div#\:\$p > svg > foreignObject > section :is(h1, marp-h1),div#\:\$p > svg > foreignObject > section :is(h2, marp-h2){border-bottom:none}div#\:\$p > svg > foreignObject > section :is(h2, marp-h2){font-size:1.3em}div#\:\$p > svg > foreignObject > section :is(h3, marp-h3){font-size:1.1em}div#\:\$p > svg > foreignObject > section :is(h4, marp-h4){font-size:1.05em}div#\:\$p > svg > foreignObject > section :is(h5, marp-h5){font-size:1em}div#\:\$p > svg > foreignObject > section :is(h6, marp-h6){font-size:.9em}div#\:\$p > svg > foreignObject > section :is(h1, marp-h1) strong,div#\:\$p > svg > foreignObject > section :is(h2, marp-h2) strong,div#\:\$p > svg > foreignObject > section :is(h3, marp-h3) strong,div#\:\$p > svg > foreignObject > section :is(h4, marp-h4) strong,div#\:\$p > svg > foreignObject > section :is(h5, marp-h5) strong,div#\:\$p > svg > foreignObject > section :is(h6, marp-h6) strong{color:var(--heading-strong-color);font-weight:inherit}div#\:\$p > svg > foreignObject > section :is(h1, marp-h1)::part(auto-scaling),div#\:\$p > svg > foreignObject > section :is(h2, marp-h2)::part(auto-scaling),div#\:\$p > svg > foreignObject > section :is(h3, marp-h3)::part(auto-scaling),div#\:\$p > svg > foreignObject > section :is(h4, marp-h4)::part(auto-scaling),div#\:\$p > svg > foreignObject > section :is(h5, marp-h5)::part(auto-scaling),div#\:\$p > svg > foreignObject > section :is(h6, marp-h6)::part(auto-scaling){max-height:563px}div#\:\$p > svg > foreignObject > section hr{height:0;padding-top:.25em}div#\:\$p > svg > foreignObject > section img{background-color:transparent}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre){border:1px solid var(--borderColor-default);line-height:1.15;overflow:visible}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre)::part(auto-scaling){max-height:529px}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs){color:var(--color-prettylights-syntax-storage-modifier-import)}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-doctag),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-keyword),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-meta .hljs-keyword),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-template-tag),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-template-variable),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-type),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-variable.language_){color:var(--color-prettylights-syntax-keyword)}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-title),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-title.class_),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-title.class_.inherited__),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-title.function_){color:var(--color-prettylights-syntax-entity)}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-attr),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-attribute),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-literal),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-meta),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-number),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-operator),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-selector-attr),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-selector-class),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-selector-id),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-variable){color:var(--color-prettylights-syntax-constant)}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-meta .hljs-string),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-regexp),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-string){color:var(--color-prettylights-syntax-string)}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-built_in),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-symbol){color:var(--color-prettylights-syntax-variable)}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-code),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-comment),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-formula){color:var(--color-prettylights-syntax-comment)}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-name),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-quote),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-selector-pseudo),div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-selector-tag){color:var(--color-prettylights-syntax-entity-tag)}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-subst){color:var(--color-prettylights-syntax-storage-modifier-import)}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-section){color:var(--color-prettylights-syntax-markup-heading);font-weight:700}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-bullet){color:var(--color-prettylights-syntax-markup-list)}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-emphasis){color:var(--color-prettylights-syntax-markup-italic);font-style:italic}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-strong){color:var(--color-prettylights-syntax-markup-bold);font-weight:700}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-addition){background-color:var(--color-prettylights-syntax-markup-inserted-bg);color:var(--color-prettylights-syntax-markup-inserted-text)}div#\:\$p > svg > foreignObject > section :is(pre, marp-pre) :where(.hljs-deletion){background-color:var(--color-prettylights-syntax-markup-deleted-bg);color:var(--color-prettylights-syntax-markup-deleted-text)}div#\:\$p > svg > foreignObject > section footer,div#\:\$p > svg > foreignObject > section header{color:var(--header-footer-color);font-size:18px;left:30px;margin:0;position:absolute}div#\:\$p > svg > foreignObject > section header{top:21px}div#\:\$p > svg > foreignObject > section footer{bottom:21px}div#\:\$p > svg > foreignObject > section{--h1-color:#246;--header-footer-color:hsla(0,0%,40%,.75);--heading-strong-color:#48c;--paginate-color:#777;--base-size-4:4px;--base-size-8:8px;--base-size-16:16px;--base-size-24:24px;--base-size-40:40px;align-items:stretch;display:block;flex-flow:column nowrap;font-size:29px;height:720px;padding:78.5px;place-content:safe center center;width:1280px}div#\:\$p > svg > foreignObject > section{--marpit-root-font-size:29px;}div#\:\$p > svg > foreignObject > section:where(.invert){--h1-color:#cee7ff;--header-footer-color:hsla(0,0%,60%,.75);--heading-strong-color:#7bf;--paginate-color:#999;}div#\:\$p > svg > foreignObject > section>:last-child,div#\:\$p > svg > foreignObject > section[data-footer]>:nth-last-child(2){margin-bottom:0}div#\:\$p > svg > foreignObject > section>:first-child,div#\:\$p > svg > foreignObject > section>header:first-child+*{margin-top:0}div#\:\$p > svg > foreignObject > section:after{bottom:21px;color:var(--paginate-color);font-size:24px;padding:0;position:absolute;right:30px}div#\:\$p > svg > foreignObject > section:after{--marpit-root-font-size:24px;}div#\:\$p > svg > foreignObject > section[data-color] :is(h1, marp-h1),div#\:\$p > svg > foreignObject > section[data-color] :is(h2, marp-h2),div#\:\$p > svg > foreignObject > section[data-color] :is(h3, marp-h3),div#\:\$p > svg > foreignObject > section[data-color] :is(h4, marp-h4),div#\:\$p > svg > foreignObject > section[data-color] :is(h5, marp-h5),div#\:\$p > svg > foreignObject > section[data-color] :is(h6, marp-h6){color:currentcolor}div#\:\$p > svg > foreignObject > section{width:1280px;height:720px}div#\:\$p > svg > foreignObject > section[data-marpit-advanced-background="background"]{columns:initial!important;display:block!important;padding:0!important}div#\:\$p > svg > foreignObject > section[data-marpit-advanced-background="background"]::before, div#\:\$p > svg > foreignObject > section[data-marpit-advanced-background="background"]::after, div#\:\$p > svg > foreignObject > section[data-marpit-advanced-background="content"]::before, div#\:\$p > svg > foreignObject > section[data-marpit-advanced-background="content"]::after{display:none!important}div#\:\$p > svg > foreignObject > section[data-marpit-advanced-background="background"] > div[data-marpit-advanced-background-container]{all:initial;display:flex;flex-direction:row;height:100%;overflow:hidden;width:100%}div#\:\$p > svg > foreignObject > section[data-marpit-advanced-background="background"] > div[data-marpit-advanced-background-container][data-marpit-advanced-background-direction="vertical"]{flex-direction:column}div#\:\$p > svg > foreignObject > section[data-marpit-advanced-background="background"][data-marpit-advanced-background-split] > div[data-marpit-advanced-background-container]{width:var(--marpit-advanced-background-split, 50%)}div#\:\$p > svg > foreignObject > section[data-marpit-advanced-background="background"][data-marpit-advanced-background-split="right"] > div[data-marpit-advanced-background-container]{margin-left:calc(100% - var(--marpit-advanced-background-split, 50%))}div#\:\$p > svg > foreignObject > section[data-marpit-advanced-background="background"] > div[data-marpit-advanced-background-container] > figure{all:initial;background-position:center;background-repeat:no-repeat;background-size:cover;flex:auto;margin:0}div#\:\$p > svg > foreignObject > section[data-marpit-advanced-background="background"] > div[data-marpit-advanced-background-container] > figure > figcaption{position:absolute;border:0;clip:rect(0, 0, 0, 0);height:1px;margin:-1px;overflow:hidden;padding:0;white-space:nowrap;width:1px}div#\:\$p > svg > foreignObject > section[data-marpit-advanced-background="content"], div#\:\$p > svg > foreignObject > section[data-marpit-advanced-background="pseudo"]{background:transparent!important}div#\:\$p > svg > foreignObject > section[data-marpit-advanced-background="pseudo"], div#\:\$p > svg[data-marpit-svg] > foreignObject[data-marpit-advanced-background="pseudo"]{pointer-events:none!important}div#\:\$p > svg > foreignObject > section[data-marpit-advanced-background-split]{width:100%;height:100%}
</style></head><body><div class="bespoke-marp-osc"><button data-bespoke-marp-osc="prev" tabindex="-1" title="Previous slide">Previous slide</button><span data-bespoke-marp-osc="page"></span><button data-bespoke-marp-osc="next" tabindex="-1" title="Next slide">Next slide</button><button data-bespoke-marp-osc="fullscreen" tabindex="-1" title="Toggle fullscreen (f)">Toggle fullscreen</button><button data-bespoke-marp-osc="presenter" tabindex="-1" title="Open presenter view (p)">Open presenter view</button></div><div id=":$p"><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="1" data-paginate="true" data-background-color="white" data-class="lead" data-theme="default" lang="en-US" class="lead" data-marpit-pagination="1" style="--paginate:true;--background-color:white;--class:lead;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h1 id="modulo-2-rappresentazione-del-testo-e-word-embeddings-%F0%9F%93%9D">Modulo 2: Rappresentazione del Testo e Word Embeddings <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f4dd.svg" data-marp-twemoji=""/></h1>
<h3 id="corso-di-natural-language-processing">Corso di Natural Language Processing</h3>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="2" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="2" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="indice-dei-contenuti-%F0%9F%93%8B">Indice dei Contenuti <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f4cb.svg" data-marp-twemoji=""/></h2>
<ul>
<li>Introduzione alla rappresentazione del testo</li>
<li>Rappresentazioni tradizionali del testo</li>
<li>Word Embeddings: rappresentare le parole come vettori</li>
<li>Visualizzazione e interpretazione dei word embeddings</li>
<li>Applicazioni dei word embeddings</li>
<li>Sentence Embeddings e Document Embeddings</li>
<li>Sfide e limitazioni dei word embeddings</li>
<li>Implementazione pratica dei word embeddings</li>
<li>Conclusione</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="3" data-paginate="true" data-background-color="white" data-class="lead" data-theme="default" lang="en-US" class="lead" data-marpit-pagination="3" style="--paginate:true;--background-color:white;--class:lead;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h1 id="introduzione-alla-rappresentazione-del-testo-%F0%9F%94%A4">Introduzione alla rappresentazione del testo <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f524.svg" data-marp-twemoji=""/></h1>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="4" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;--marpit-advanced-background-split:40%;" data-marpit-pagination-total="48" data-size="16:9" data-marpit-advanced-background="background" data-marpit-advanced-background-split="right"><div data-marpit-advanced-background-container="true" data-marpit-advanced-background-direction="horizontal"><figure style="background-image:url(&quot;images/text_representation.png&quot;);background-size:80%;"></figure></div></section></foreignObject><foreignObject width="60%" height="720"><section id="4" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="4" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;--marpit-advanced-background-split:40%;" data-marpit-pagination-total="48" data-size="16:9" data-marpit-advanced-background="content" data-marpit-advanced-background-split="right">
<h2 id="cos%C3%A8-la-rappresentazione-del-testo-%F0%9F%A4%94">Cos' la rappresentazione del testo? <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f914.svg" data-marp-twemoji=""/></h2>
<ul>
<li>Processo di <strong>trasformazione</strong> del linguaggio naturale in un formato elaborabile dai computer</li>
<li>Passaggio fondamentale: da testo comprensibile agli umani a rappresentazioni numeriche/vettoriali</li>
<li>I computer non &quot;comprendono&quot; naturalmente il linguaggio umano</li>
</ul>
</section>
</foreignObject><foreignObject width="1280" height="720" data-marpit-advanced-background="pseudo"><section data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="4" style="" data-marpit-pagination-total="48" data-size="16:9" data-marpit-advanced-background="pseudo" data-marpit-advanced-background-split="right"></section></foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="5" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="5" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="importanza-della-rappresentazione-%F0%9F%8E%AF">Importanza della rappresentazione <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f3af.svg" data-marp-twemoji=""/></h2>
<ul>
<li>La <strong>qualit della rappresentazione</strong> influenza direttamente l'efficacia dei sistemi NLP</li>
<li>Una rappresentazione inadeguata limita anche gli algoritmi pi sofisticati</li>
<li>Una rappresentazione efficace permette buoni risultati anche con modelli semplici</li>
</ul>
<blockquote>
<p>&quot;La rappresentazione  pi importante dell'algoritmo&quot; - dominio dell'apprendimento automatico</p>
</blockquote>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="6" data-paginate="true" data-background-color="white" data-class="lead" data-theme="default" lang="en-US" class="lead" data-marpit-pagination="6" style="--paginate:true;--background-color:white;--class:lead;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h1 id="rappresentazioni-tradizionali-del-testo-%F0%9F%93%9A">Rappresentazioni tradizionali del testo <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f4da.svg" data-marp-twemoji=""/></h1>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="7" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;--marpit-advanced-background-split:40%;" data-marpit-pagination-total="48" data-size="16:9" data-marpit-advanced-background="background" data-marpit-advanced-background-split="right"><div data-marpit-advanced-background-container="true" data-marpit-advanced-background-direction="horizontal"><figure style="background-image:url(&quot;images/one_hot.png&quot;);background-size:140%;"></figure></div></section></foreignObject><foreignObject width="60%" height="720"><section id="7" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="7" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;--marpit-advanced-background-split:40%;" data-marpit-pagination-total="48" data-size="16:9" data-marpit-advanced-background="content" data-marpit-advanced-background-split="right">
<h2 id="one-hot-encoding-%E2%9A%A1">One-Hot Encoding <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a1.svg" data-marp-twemoji=""/></h2>
<ul>
<li>Ogni parola  un vettore con dimensione = dimensione del vocabolario</li>
<li>Un 1 nella posizione corrispondente alla parola, 0 in tutte le altre</li>
</ul>
<p><strong>Limitazioni:</strong></p>
<ul>
<li>Alta dimensionalit (vettori enormi per vocabolari realistici)</li>
<li>Nessuna informazione semantica (tutte le parole equidistanti)</li>
<li>Nessuna generalizzazione</li>
</ul>
</section>
</foreignObject><foreignObject width="1280" height="720" data-marpit-advanced-background="pseudo"><section data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="7" style="" data-marpit-pagination-total="48" data-size="16:9" data-marpit-advanced-background="pseudo" data-marpit-advanced-background-split="right"></section></foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="8" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="8" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="bag-of-words-bow-%F0%9F%91%9C">Bag-of-Words (BoW) <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f45c.svg" data-marp-twemoji=""/></h2>
<ul>
<li>Rappresenta un documento come vettore di conteggi di parole</li>
<li>Ignora l'ordine delle parole, considera solo la frequenza</li>
</ul>
<p><strong>Esempio:</strong><br />
&quot;Il gatto insegue il topo&quot;  [2, 1, 1, 1, 0, 0, ...]<br />
(il, gatto, insegue, topo, ...)</p>
<p><strong>Limitazioni:</strong></p>
<ul>
<li>Perdita dell'ordine delle parole</li>
<li>Perdita di contesto</li>
<li>Alta dimensionalit</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="9" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="9" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="term-frequency-inverse-document-frequency-tf-idf-%F0%9F%93%8A">Term Frequency-Inverse Document Frequency (TF-IDF) <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f4ca.svg" data-marp-twemoji=""/></h2>
<p>Formula: TF-IDF(t, d, D) = TF(t, d)  IDF(t, D)</p>
<ul>
<li><strong>TF(t, d)</strong>: frequenza del termine t nel documento d</li>
<li><strong>IDF(t, D)</strong>: logaritmo del rapporto tra numero totale di documenti e numero di documenti contenenti il termine t</li>
</ul>
<p><strong>Vantaggi:</strong></p>
<ul>
<li>Migliore capacit discriminativa rispetto a BoW</li>
<li>Penalizza parole comuni e valorizza parole distintive</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="10" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="10" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="n-grams-%F0%9F%94%84">N-grams <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f504.svg" data-marp-twemoji=""/></h2>
<ul>
<li>Estensione del BoW che considera sequenze di N parole consecutive</li>
<li>Cattura parzialmente l'ordine locale delle parole</li>
</ul>
<p><strong>Esempio (bi-grams):</strong><br />
&quot;Il gatto insegue il topo&quot;  [&quot;il gatto&quot;, &quot;gatto insegue&quot;, &quot;insegue il&quot;, &quot;il topo&quot;]</p>
<p><strong>Limitazioni:</strong></p>
<ul>
<li>Dimensionalit aumenta esponenzialmente con N</li>
<li>Sparsit dei dati</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="11" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="11" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="applicazione-aziendale-analisi-dei-brevetti-con-tf-idf-%F0%9F%92%BC">Applicazione Aziendale: Analisi dei Brevetti con TF-IDF <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f4bc.svg" data-marp-twemoji=""/></h2>
<p>Le aziende tecnologiche utilizzano TF-IDF per analizzare brevetti:</p>
<ul>
<li>Estrazione dei termini pi distintivi da migliaia di documenti brevettuali</li>
<li>Identificazione di tecnologie emergenti in specifici settori</li>
<li>Monitoraggio delle attivit di brevettazione dei concorrenti</li>
<li>Valutazione di potenziali acquisizioni basata su portfolio brevetti</li>
</ul>
<blockquote>
<p><strong>Esempio:</strong> IBM utilizza analisi TF-IDF avanzata per monitorare il panorama brevettuale in settori strategici come l'intelligenza artificiale</p>
</blockquote>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="12" data-paginate="true" data-background-color="white" data-class="lead" data-theme="default" lang="en-US" class="lead" data-marpit-pagination="12" style="--paginate:true;--background-color:white;--class:lead;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h1 id="word-embeddings-rappresentare-le-parole-come-vettori-%F0%9F%A7%A0">Word Embeddings: Rappresentare le Parole come Vettori <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f9e0.svg" data-marp-twemoji=""/></h1>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="13" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="13" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="cos%C3%A8-un-word-embedding-%F0%9F%94%8D">Cos' un word embedding? <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f50d.svg" data-marp-twemoji=""/></h2>
<ul>
<li>Rappresentazione vettoriale di una parola in uno spazio multidimensionale continuo</li>
<li>Ogni parola  vettore di numeri reali (tipicamente 100-300 dimensioni)</li>
<li>La posizione nello spazio vettoriale cattura relazioni semantiche e sintattiche</li>
</ul>
<p><strong>Differenze dalle rappresentazioni one-hot:</strong></p>
<ul>
<li><strong>Densi</strong> vs sparsi</li>
<li><strong>Semanticamente significativi</strong> vs arbitrari</li>
<li><strong>Dimensionalit ridotta</strong> vs alta dimensionalit</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="14" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="14" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="propriet%C3%A0-sorprendenti-dei-word-embeddings-%E2%9C%A8">Propriet sorprendenti dei word embeddings <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/2728.svg" data-marp-twemoji=""/></h2>
<p>I word embeddings catturano analogie e relazioni semantiche attraverso operazioni vettoriali:</p>
<pre is="marp-pre" data-auto-scaling="downscale-only"><code>vector(&quot;re&quot;) - vector(&quot;uomo&quot;) + vector(&quot;donna&quot;)  vector(&quot;regina&quot;)
</code></pre>
<p>Questa propriet emerge naturalmente durante l'addestramento!</p>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="15" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="15" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="principi-di-funzionamento-%F0%9F%A7%A9">Principi di funzionamento <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f9e9.svg" data-marp-twemoji=""/></h2>
<ul>
<li>
<p>Basati sull'<strong>ipotesi distribuzionale</strong> della semantica:</p>
<blockquote>
<p>&quot;You shall know a word by the company it keeps&quot; (J.R. Firth)</p>
</blockquote>
</li>
<li>
<p>Parole che appaiono in contesti simili tendono ad avere significati simili</p>
</li>
<li>
<p>Addestrati su obiettivi predittivi:</p>
<ul>
<li>Predire una parola dato il suo contesto (CBOW)</li>
<li>Predire il contesto data una parola (Skip-gram)</li>
<li>Predire la probabilit di co-occorrenza (GloVe)</li>
</ul>
</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="16" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;--marpit-advanced-background-split:40%;" data-marpit-pagination-total="48" data-size="16:9" data-marpit-advanced-background="background" data-marpit-advanced-background-split="right"><div data-marpit-advanced-background-container="true" data-marpit-advanced-background-direction="horizontal"><figure style="background-image:url(&quot;images/word2vec.png&quot;);background-size:80%;"></figure></div></section></foreignObject><foreignObject width="60%" height="720"><section id="16" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="16" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;--marpit-advanced-background-split:40%;" data-marpit-pagination-total="48" data-size="16:9" data-marpit-advanced-background="content" data-marpit-advanced-background-split="right">
<h2 id="word2vec-%F0%9F%94%84">Word2Vec <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f504.svg" data-marp-twemoji=""/></h2>
<p>Sviluppato da Google nel 2013, due varianti principali:</p>
<ul>
<li>
<p><strong>Continuous Bag of Words (CBOW)</strong>:<br />
Predice una parola target dato il contesto circostante</p>
</li>
<li>
<p><strong>Skip-gram</strong>:<br />
Predice il contesto circostante data una parola target</p>
</li>
</ul>
<p>Utilizza una rete neurale shallow con un singolo strato nascosto.</p>
</section>
</foreignObject><foreignObject width="1280" height="720" data-marpit-advanced-background="pseudo"><section data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="16" style="" data-marpit-pagination-total="48" data-size="16:9" data-marpit-advanced-background="pseudo" data-marpit-advanced-background-split="right"></section></foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="17" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="17" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="glove-global-vectors-%F0%9F%8C%90">GloVe (Global Vectors) <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f310.svg" data-marp-twemoji=""/></h2>
<p>Sviluppato da Stanford nel 2014:</p>
<ul>
<li>Combina vantaggi dei metodi basati su contesto locale con statistiche globali di co-occorrenza</li>
<li>Costruisce una matrice di co-occorrenza delle parole</li>
<li>Addestra un modello per predire il logaritmo delle probabilit di co-occorrenza</li>
</ul>
<p><strong>Vantaggi:</strong></p>
<ul>
<li>Cattura sia informazioni locali che globali</li>
<li>Migliore performance su alcune relazioni semantiche</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="18" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="18" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="fasttext-%F0%9F%9A%80">FastText <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f680.svg" data-marp-twemoji=""/></h2>
<p>Sviluppato da Facebook AI Research nel 2016:</p>
<ul>
<li>Estende Word2Vec considerando i caratteri n-gram all'interno delle parole</li>
<li>Apprende vettori per frammenti di parole (n-gram di caratteri)</li>
<li>Rappresenta una parola come somma dei vettori dei suoi n-gram</li>
</ul>
<p><strong>Vantaggi:</strong></p>
<ul>
<li>Gestione di parole fuori vocabolario (OOV)</li>
<li>Migliore per lingue morfologicamente ricche (italiano, tedesco, finlandese)</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="19" data-paginate="true" data-background-color="white" data-class="lead" data-theme="default" lang="en-US" class="lead" data-marpit-pagination="19" style="--paginate:true;--background-color:white;--class:lead;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h1 id="visualizzazione-e-interpretazione-dei-word-embeddings-%F0%9F%91%81%EF%B8%8F">Visualizzazione e interpretazione dei word embeddings <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f441.svg" data-marp-twemoji=""/></h1>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="20" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="20" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="tecniche-di-riduzione-della-dimensionalit%C3%A0-%F0%9F%93%89">Tecniche di riduzione della dimensionalit <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f4c9.svg" data-marp-twemoji=""/></h2>
<p>Per visualizzare gli embeddings (da 100-300D a 2-3D):</p>
<ul>
<li>
<p><strong>Principal Component Analysis (PCA)</strong>:<br />
Identifica direzioni di massima varianza</p>
</li>
<li>
<p><strong>t-Distributed Stochastic Neighbor Embedding (t-SNE)</strong>:<br />
Preserva relazioni di vicinanza locale</p>
</li>
<li>
<p><strong>Uniform Manifold Approximation and Projection (UMAP)</strong>:<br />
Preserva sia struttura locale che globale</p>
</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="21" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="21" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="interpretazione-delle-dimensioni-%F0%9F%94%AC">Interpretazione delle dimensioni <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f52c.svg" data-marp-twemoji=""/></h2>
<ul>
<li>Le singole dimensioni non hanno generalmente un'interpretazione semantica chiara</li>
<li> possibile identificare <strong>direzioni significative</strong>:
<ul>
<li>Direzione di genere: &quot;uomo&quot;-&quot;donna&quot;, &quot;re&quot;-&quot;regina&quot;</li>
<li>Direzione di formalit/informalit</li>
<li>Direzione di positivit/negativit</li>
</ul>
</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="22" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="22" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="valutazione-degli-embeddings-%F0%9F%93%8F">Valutazione degli embeddings <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f4cf.svg" data-marp-twemoji=""/></h2>
<ul>
<li><strong>Test di analogia</strong>: &quot;a sta a b come c sta a ?&quot;</li>
<li><strong>Test di similarit</strong>: correlazione tra similarit coseno e giudizi umani</li>
<li><strong>Valutazione estrinseca</strong>: performance in compiti downstream (classificazione, NER)</li>
</ul>
<blockquote>
<p>Diversi embeddings possono eccellere in diversi tipi di valutazione</p>
</blockquote>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="23" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="23" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="applicazione-aziendale-ricerca-semantica-nei-documenti-legali-%E2%9A%96%EF%B8%8F">Applicazione Aziendale: Ricerca Semantica nei Documenti Legali <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/2696.svg" data-marp-twemoji=""/></h2>
<p>Gli studi legali utilizzano word embeddings per:</p>
<ul>
<li>Ricerca di concetti legali simili anche con terminologia diversa</li>
<li>Identificazione di precedenti rilevanti basata sulla similarit semantica</li>
<li>Organizzazione automatica di grandi archivi di documenti legali</li>
<li>Suggerimento di clausole contrattuali pertinenti</li>
<li>Vector DB Creazione del contesto nei Retrieval-Augmented Generation</li>
</ul>
<blockquote>
<p><strong>Esempio:</strong> Analizzare contratti e documenti legali, estraendo informazioni rilevanti da migliaia di documenti in una frazione del tempo</p>
</blockquote>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="24" data-paginate="true" data-background-color="white" data-class="lead" data-theme="default" lang="en-US" class="lead" data-marpit-pagination="24" style="--paginate:true;--background-color:white;--class:lead;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h1 id="applicazioni-dei-word-embeddings-%F0%9F%9B%A0%EF%B8%8F">Applicazioni dei word embeddings <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f6e0.svg" data-marp-twemoji=""/></h1>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="25" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;--marpit-advanced-background-split:40%;" data-marpit-pagination-total="48" data-size="16:9" data-marpit-advanced-background="background" data-marpit-advanced-background-split="right"><div data-marpit-advanced-background-container="true" data-marpit-advanced-background-direction="horizontal"><figure style="background-image:url(&quot;images/semantic_search.webp&quot;);background-size:100%;"></figure></div></section></foreignObject><foreignObject width="60%" height="720"><section id="25" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="25" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;--marpit-advanced-background-split:40%;" data-marpit-pagination-total="48" data-size="16:9" data-marpit-advanced-background="content" data-marpit-advanced-background-split="right">
<h2 id="miglioramento-della-ricerca-semantica-%F0%9F%94%8D">Miglioramento della ricerca semantica <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f50d.svg" data-marp-twemoji=""/></h2>
<ul>
<li>Comprensione del significato delle query, non solo parole esatte</li>
<li>Risultati pertinenti anche con sinonimi o termini correlati</li>
</ul>
<p><strong>Applicazioni:</strong></p>
<ul>
<li><strong>E-commerce</strong>: ricerca di prodotti con descrizioni generiche</li>
<li><strong>Editoria digitale</strong>: trovare articoli rilevanti basati su concetti</li>
</ul>
</section>
</foreignObject><foreignObject width="1280" height="720" data-marpit-advanced-background="pseudo"><section data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="25" style="" data-marpit-pagination-total="48" data-size="16:9" data-marpit-advanced-background="pseudo" data-marpit-advanced-background-split="right"></section></foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="26" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="26" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="categorizzazione-avanzata-dei-documenti-%F0%9F%93%82">Categorizzazione avanzata dei documenti <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f4c2.svg" data-marp-twemoji=""/></h2>
<ul>
<li>Maggiore accuratezza nella classificazione dei testi</li>
<li>Categorizzazione corretta anche con terminologie diverse</li>
</ul>
<p><strong>Applicazioni:</strong></p>
<ul>
<li><strong>Settore assicurativo</strong>: categorizzazione automatica delle richieste di risarcimento</li>
<li><strong>Analisi social media</strong>: categorizzazione di post per temi, sentiment o intenti</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="27" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="27" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="sistemi-di-raccomandazione-basati-su-contenuto-%F0%9F%91%8D">Sistemi di raccomandazione basati su contenuto <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f44d.svg" data-marp-twemoji=""/></h2>
<ul>
<li>Rappresentazioni vettoriali di documenti, prodotti o contenuti</li>
<li>Calcolo di similarit semantiche per raccomandazioni pertinenti</li>
</ul>
<p><strong>Applicazioni:</strong></p>
<ul>
<li><strong>Media e intrattenimento</strong>: analisi di descrizioni e metadati per raccomandazioni</li>
<li><strong>Recruiting</strong>: matching tra curriculum e offerte di lavoro</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="28" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="28" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="analisi-del-sentiment-pi%C3%B9-accurata-%F0%9F%98%8A%F0%9F%98%A0">Analisi del sentiment pi accurata <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f60a.svg" data-marp-twemoji=""/><img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f620.svg" data-marp-twemoji=""/></h2>
<ul>
<li>Migliore generalizzazione per riconoscere il tono emotivo</li>
<li>Riconoscimento del sentiment anche con parole non presenti nel dataset</li>
</ul>
<p><strong>Applicazioni:</strong></p>
<ul>
<li><strong>Settore finanziario</strong>: analisi di notizie economiche e social media</li>
<li><strong>Ristorazione e ospitalit</strong>: insights granulari dalle recensioni dei clienti</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="29" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="29" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="rilevamento-di-temi-emergenti-%F0%9F%93%88">Rilevamento di temi emergenti <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f4c8.svg" data-marp-twemoji=""/></h2>
<ul>
<li>Identificazione di temi o problemi emergenti nelle comunicazioni</li>
<li>Analisi di cluster di parole nello spazio degli embeddings</li>
</ul>
<p><strong>Applicazioni:</strong></p>
<ul>
<li><strong>Settore farmaceutico</strong>: identificazione precoce di effetti collaterali</li>
<li><strong>Marketing</strong>: identificazione di nuove tendenze di consumo</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="30" data-paginate="true" data-background-color="white" data-class="lead" data-theme="default" lang="en-US" class="lead" data-marpit-pagination="30" style="--paginate:true;--background-color:white;--class:lead;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h1 id="sentence-embeddings-e-document-embeddings-%F0%9F%93%84">Sentence Embeddings e Document Embeddings <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f4c4.svg" data-marp-twemoji=""/></h1>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="31" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="31" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="da-word-embeddings-a-sentence-embeddings-%F0%9F%94%84">Da word embeddings a sentence embeddings <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f504.svg" data-marp-twemoji=""/></h2>
<p>Approcci semplici:</p>
<ul>
<li>Media o somma pesata dei word embeddings delle parole</li>
</ul>
<p>Approcci pi sofisticati:</p>
<ul>
<li><strong>Smooth Inverse Frequency (SIF)</strong>: media pesata con pesi inversamente proporzionali alla frequenza</li>
<li><strong>Doc2Vec</strong>: estensione di Word2Vec per documenti</li>
<li><strong>Universal Sentence Encoder (USE)</strong>: modello pre-addestrato per similarit semantica</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="32" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="32" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="modelli-avanzati-per-sentence-embeddings-%F0%9F%9A%80">Modelli avanzati per sentence embeddings <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f680.svg" data-marp-twemoji=""/></h2>
<p>Modelli basati su architetture Transformer:</p>
<ul>
<li><strong>BERT Sentence Embeddings</strong>: rappresentazione del token [CLS] o media dei token</li>
<li><strong>Sentence-BERT (SBERT)</strong>: modificazione di BERT ottimizzata per sentence embeddings</li>
<li><strong>SimCSE</strong>: utilizza tecniche di apprendimento contrastivo</li>
</ul>
<blockquote>
<p>Questi modelli catturano molto meglio il significato complessivo delle frasi</p>
</blockquote>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="33" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="33" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="applicazioni-dei-sentence-embeddings-%F0%9F%9B%A0%EF%B8%8F">Applicazioni dei sentence embeddings <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f6e0.svg" data-marp-twemoji=""/></h2>
<ul>
<li><strong>Clustering semantico di documenti</strong></li>
<li><strong>Rilevamento di duplicati e near-duplicates</strong></li>
<li><strong>Sistemi di risposta a domande</strong></li>
<li><strong>Riassunto estrattivo</strong></li>
</ul>
<p><strong>Settori di applicazione:</strong></p>
<ul>
<li>Bancario: analisi e categorizzazione di comunicazioni con clienti</li>
<li>Ricerca accademica: scoperta di letteratura rilevante</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="34" data-paginate="true" data-background-color="white" data-class="lead" data-theme="default" lang="en-US" class="lead" data-marpit-pagination="34" style="--paginate:true;--background-color:white;--class:lead;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h1 id="sfide-e-limitazioni-dei-word-embeddings-%E2%9A%A0%EF%B8%8F">Sfide e limitazioni dei word embeddings <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/26a0.svg" data-marp-twemoji=""/></h1>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="35" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="35" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="polisemia-e-ambiguit%C3%A0-%F0%9F%94%84">Polisemia e ambiguit <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f504.svg" data-marp-twemoji=""/></h2>
<ul>
<li>Word embeddings tradizionali assegnano un <strong>singolo vettore</strong> a ogni parola</li>
<li>Problematico per parole polisemiche con significati diversi in contesti diversi</li>
</ul>
<p><strong>Esempio:</strong><br />
&quot;calcio&quot;  sport, elemento chimico, azione di colpire</p>
<p><strong>Impatto:</strong></p>
<ul>
<li>Rappresentazione &quot;media&quot; non ottimale per nessun significato specifico</li>
<li>Problemi in applicazioni come traduzione automatica</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="36" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="36" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="bias-e-stereotipi-%F0%9F%9A%AB">Bias e stereotipi <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f6ab.svg" data-marp-twemoji=""/></h2>
<ul>
<li>Gli embeddings ereditano bias presenti nei dati di addestramento</li>
<li>Associazioni problematiche: professioni-genere, etnia-attributi, ecc.</li>
</ul>
<p><strong>Impatto:</strong></p>
<ul>
<li>Propagazione e amplificazione di bias nelle applicazioni</li>
<li>Risultati potenzialmente discriminatori (es. screening CV)</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="37" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="37" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="dipendenza-dalla-qualit%C3%A0-e-quantit%C3%A0-dei-dati-%F0%9F%93%8A">Dipendenza dalla qualit e quantit dei dati <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f4ca.svg" data-marp-twemoji=""/></h2>
<ul>
<li>Qualit degli embeddings dipende fortemente dai dati di addestramento</li>
<li>Embeddings generici potrebbero non catturare terminologia di dominio</li>
</ul>
<p><strong>Problematiche:</strong></p>
<ul>
<li>Termini specialistici o acronimi mal rappresentati</li>
<li>Lingue con risorse limitate hanno embeddings di qualit inferiore</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="38" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="38" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="mancanza-di-comprensione-profonda-%F0%9F%A7%A0">Mancanza di comprensione profonda <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f9e0.svg" data-marp-twemoji=""/></h2>
<ul>
<li>Catturano relazioni semantiche superficiali, ma non vera &quot;comprensione&quot;</li>
<li>Non catturano relazioni logiche complesse o conoscenza del mondo reale</li>
</ul>
<p><strong>Esempio:</strong><br />
Riconoscere che &quot;Parigi&quot; e &quot;Francia&quot; sono correlati  comprendere che Parigi  la capitale della Francia</p>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="39" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="39" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="evoluzione-verso-embeddings-contestuali-%F0%9F%94%84">Evoluzione verso embeddings contestuali <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f504.svg" data-marp-twemoji=""/></h2>
<p>Per superare queste limitazioni  embeddings contestuali:</p>
<ul>
<li>La rappresentazione di una parola dipende dal contesto specifico</li>
<li>Modelli come ELMo, BERT e GPT generano embeddings dinamici</li>
</ul>
<p><strong>Esempio:</strong><br />
In BERT, &quot;calcio&quot; ha rappresentazioni diverse in:</p>
<ul>
<li>&quot;Io gioco a calcio&quot;</li>
<li>&quot;Giocando mi hanno dato un calcio&quot;</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="40" data-paginate="true" data-background-color="white" data-class="lead" data-theme="default" lang="en-US" class="lead" data-marpit-pagination="40" style="--paginate:true;--background-color:white;--class:lead;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h1 id="implementazione-pratica-dei-word-embeddings-%F0%9F%92%BB">Implementazione pratica dei word embeddings <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f4bb.svg" data-marp-twemoji=""/></h1>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="41" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="41" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="scelta-del-modello-di-embedding-%F0%9F%94%8D">Scelta del modello di embedding <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f50d.svg" data-marp-twemoji=""/></h2>
<p>Fattori da considerare:</p>
<ul>
<li><strong>Dominio applicativo</strong>: embeddings specialistici vs generici</li>
<li><strong>Lingua</strong>: disponibilit e qualit per lingue diverse dall'inglese</li>
<li><strong>Risorse computazionali</strong>: complessit del modello</li>
<li><strong>Compito specifico</strong>: alcuni modelli performano meglio per certi compiti</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="42" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="42" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="embeddings-pre-addestrati-vs-addestramento-custom-%F0%9F%94%84">Embeddings pre-addestrati vs addestramento custom <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f504.svg" data-marp-twemoji=""/></h2>
<p><strong>Pre-addestrati:</strong></p>
<ul>
<li>Word2Vec su Google News</li>
<li>GloVe su Wikipedia e Gigaword</li>
<li>FastText su Wikipedia, Common Crawl</li>
</ul>
<p><strong>Addestramento custom vantaggioso quando:</strong></p>
<ul>
<li>Terminologia di dominio molto specifica</li>
<li>Grandi quantit di dati proprietari</li>
<li>Necessit di ottimizzazione per compiti specifici</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="43" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="43" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="integrazione-nelle-pipeline-nlp-%F0%9F%94%84">Integrazione nelle pipeline NLP <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f504.svg" data-marp-twemoji=""/></h2>
<p>Modalit di integrazione:</p>
<ul>
<li><strong>Feature engineering</strong>: input per modelli ML tradizionali</li>
<li><strong>Layer di embedding in reti neurali</strong>: inizializzazione con embeddings pre-addestrati</li>
<li><strong>Calcolo di similarit</strong>: similarit coseno per ricerca o clustering</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="44" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="44" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="tecniche-di-debiasing-%F0%9F%9B%A0%EF%B8%8F">Tecniche di debiasing <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f6e0.svg" data-marp-twemoji=""/></h2>
<p>Per mitigare i bias negli embeddings:</p>
<ul>
<li><strong>Hard debiasing</strong>: neutralizza esplicitamente componenti di bias</li>
<li><strong>Soft debiasing</strong>: regolarizzazione durante l'addestramento</li>
<li><strong>Augmentation dei dati</strong>: arricchimento con esempi che contrastano stereotipi</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="45" data-paginate="true" data-background-color="white" data-class="lead" data-theme="default" lang="en-US" class="lead" data-marpit-pagination="45" style="--paginate:true;--background-color:white;--class:lead;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h1 id="conclusione-%F0%9F%8E%AF">Conclusione <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f3af.svg" data-marp-twemoji=""/></h1>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="46" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="46" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="riepilogo-del-modulo-%F0%9F%93%8B">Riepilogo del Modulo <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f4cb.svg" data-marp-twemoji=""/></h2>
<ul>
<li>La rappresentazione del testo  fondamentale per l'NLP</li>
<li>Le tecniche tradizionali (BoW, TF-IDF) hanno limitazioni significative</li>
<li>I word embeddings rappresentano le parole come vettori densi che catturano relazioni semantiche</li>
<li>Word2Vec, GloVe e FastText sono le principali tecniche, ciascuna con punti di forza specifici</li>
<li>I sentence embeddings estendono il concetto oltre le singole parole</li>
<li>Le applicazioni spaziano dalla ricerca semantica all'analisi del sentiment</li>
<li>Nonostante le limitazioni, i word embeddings hanno trasformato l'NLP</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="47" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="47" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="evoluzione-e-futuro-%F0%9F%94%AE">Evoluzione e futuro <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f52e.svg" data-marp-twemoji=""/></h2>
<ul>
<li>I word embeddings hanno posto le basi per i modelli contestuali pi avanzati</li>
<li>L'evoluzione verso embeddings contestuali (BERT, GPT) supera molte limitazioni</li>
<li>I principi fondamentali della rappresentazione vettoriale rimangono centrali</li>
</ul>
<blockquote>
<p>Nel prossimo modulo: classificazione del testo e analisi del sentiment</p>
</blockquote>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="48" data-paginate="true" data-background-color="white" data-theme="default" lang="en-US" data-marpit-pagination="48" style="--paginate:true;--background-color:white;--theme:default;background-color:white;background-image:none;" data-marpit-pagination-total="48" data-size="16:9">
<h2 id="riferimenti-e-approfondimenti-%F0%9F%93%9A">Riferimenti e Approfondimenti <img class="emoji" draggable="false" alt="" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f4da.svg" data-marp-twemoji=""/></h2>
<ul>
<li>Mikolov, T., et al. (2013). Distributed Representations of Words and Phrases and their Compositionality.</li>
<li>Pennington, J., Socher, R., &amp; Manning, C. D. (2014). GloVe: Global Vectors for Word Representation.</li>
<li>Bojanowski, P., et al. (2017). Enriching Word Vectors with Subword Information.</li>
<li>Bolukbasi, T., et al. (2016). Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings.</li>
<li>Reimers, N., &amp; Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks.</li>
</ul>
</section>
<script>!function(){"use strict";const t={h1:{proto:()=>HTMLHeadingElement,attrs:{role:"heading","aria-level":"1"},style:"display: block; font-size: 2em; margin-block-start: 0.67em; margin-block-end: 0.67em; margin-inline-start: 0px; margin-inline-end: 0px; font-weight: bold;"},h2:{proto:()=>HTMLHeadingElement,attrs:{role:"heading","aria-level":"2"},style:"display: block; font-size: 1.5em; margin-block-start: 0.83em; margin-block-end: 0.83em; margin-inline-start: 0px; margin-inline-end: 0px; font-weight: bold;"},h3:{proto:()=>HTMLHeadingElement,attrs:{role:"heading","aria-level":"3"},style:"display: block; font-size: 1.17em; margin-block-start: 1em; margin-block-end: 1em; margin-inline-start: 0px; margin-inline-end: 0px; font-weight: bold;"},h4:{proto:()=>HTMLHeadingElement,attrs:{role:"heading","aria-level":"4"},style:"display: block; margin-block-start: 1.33em; margin-block-end: 1.33em; margin-inline-start: 0px; margin-inline-end: 0px; font-weight: bold;"},h5:{proto:()=>HTMLHeadingElement,attrs:{role:"heading","aria-level":"5"},style:"display: block; font-size: 0.83em; margin-block-start: 1.67em; margin-block-end: 1.67em; margin-inline-start: 0px; margin-inline-end: 0px; font-weight: bold;"},h6:{proto:()=>HTMLHeadingElement,attrs:{role:"heading","aria-level":"6"},style:"display: block; font-size: 0.67em; margin-block-start: 2.33em; margin-block-end: 2.33em; margin-inline-start: 0px; margin-inline-end: 0px; font-weight: bold;"},span:{proto:()=>HTMLSpanElement},pre:{proto:()=>HTMLElement,style:"display: block; font-family: monospace; white-space: pre; margin: 1em 0; --marp-auto-scaling-white-space: pre;"}},e="data-marp-auto-scaling-wrapper",i="data-marp-auto-scaling-svg",n="data-marp-auto-scaling-container";class s extends HTMLElement{container;containerSize;containerObserver;svg;svgComputedStyle;svgPreserveAspectRatio="xMinYMid meet";wrapper;wrapperSize;wrapperObserver;constructor(){super();const t=t=>([e])=>{const{width:i,height:n}=e.contentRect;this[t]={width:i,height:n},this.updateSVGRect()};this.attachShadow({mode:"open"}),this.containerObserver=new ResizeObserver(t("containerSize")),this.wrapperObserver=new ResizeObserver(((...e)=>{t("wrapperSize")(...e),this.flushSvgDisplay()}))}static get observedAttributes(){return["data-downscale-only"]}connectedCallback(){this.shadowRoot.innerHTML=`\n<style>\n  svg[${i}] { display: block; width: 100%; height: auto; vertical-align: top; }\n  span[${n}] { display: table; white-space: var(--marp-auto-scaling-white-space, nowrap); width: max-content; }\n</style>\n<div ${e}>\n  <svg part="svg" ${i}>\n    <foreignObject><span ${n}><slot></slot></span></foreignObject>\n  </svg>\n</div>\n    `.split(/\n\s*/).join(""),this.wrapper=this.shadowRoot.querySelector(`div[${e}]`)??void 0;const t=this.svg;this.svg=this.wrapper?.querySelector(`svg[${i}]`)??void 0,this.svg!==t&&(this.svgComputedStyle=this.svg?window.getComputedStyle(this.svg):void 0),this.container=this.svg?.querySelector(`span[${n}]`)??void 0,this.observe()}disconnectedCallback(){this.svg=void 0,this.svgComputedStyle=void 0,this.wrapper=void 0,this.container=void 0,this.observe()}attributeChangedCallback(){this.observe()}flushSvgDisplay(){const{svg:t}=this;t&&(t.style.display="inline",requestAnimationFrame((()=>{t.style.display=""})))}observe(){this.containerObserver.disconnect(),this.wrapperObserver.disconnect(),this.wrapper&&this.wrapperObserver.observe(this.wrapper),this.container&&this.containerObserver.observe(this.container),this.svgComputedStyle&&this.observeSVGStyle(this.svgComputedStyle)}observeSVGStyle(t){const e=()=>{const i=(()=>{const e=t.getPropertyValue("--preserve-aspect-ratio");if(e)return e.trim();return`x${(({textAlign:t,direction:e})=>{if(t.endsWith("left"))return"Min";if(t.endsWith("right"))return"Max";if("start"===t||"end"===t){let i="rtl"===e;return"end"===t&&(i=!i),i?"Max":"Min"}return"Mid"})(t)}YMid meet`})();i!==this.svgPreserveAspectRatio&&(this.svgPreserveAspectRatio=i,this.updateSVGRect()),t===this.svgComputedStyle&&requestAnimationFrame(e)};e()}updateSVGRect(){let t=Math.ceil(this.containerSize?.width??0);const e=Math.ceil(this.containerSize?.height??0);void 0!==this.dataset.downscaleOnly&&(t=Math.max(t,this.wrapperSize?.width??0));const i=this.svg?.querySelector(":scope > foreignObject");if(i?.setAttribute("width",`${t}`),i?.setAttribute("height",`${e}`),this.svg&&(this.svg.setAttribute("viewBox",`0 0 ${t} ${e}`),this.svg.setAttribute("preserveAspectRatio",this.svgPreserveAspectRatio),this.svg.style.height=t<=0||e<=0?"0":""),this.container){const t=this.svgPreserveAspectRatio.toLowerCase();this.container.style.marginLeft=t.startsWith("xmid")||t.startsWith("xmax")?"auto":"0",this.container.style.marginRight=t.startsWith("xmi")?"auto":"0"}}}const r=(t,{attrs:e={},style:i})=>class extends t{constructor(...t){super(...t);for(const[t,i]of Object.entries(e))this.hasAttribute(t)||this.setAttribute(t,i);this._shadow()}static get observedAttributes(){return["data-auto-scaling"]}connectedCallback(){this._update()}attributeChangedCallback(){this._update()}_shadow(){if(!this.shadowRoot)try{this.attachShadow({mode:"open"})}catch(t){if(!(t instanceof Error&&"NotSupportedError"===t.name))throw t}return this.shadowRoot}_update(){const t=this._shadow();if(t){const e=i?`<style>:host { ${i} }</style>`:"";let n="<slot></slot>";const{autoScaling:s}=this.dataset;if(void 0!==s){n=`<marp-auto-scaling exportparts="svg:auto-scaling" ${"downscale-only"===s?"data-downscale-only":""}>${n}</marp-auto-scaling>`}t.innerHTML=e+n}}};let o;const a=Symbol();let l;const c="marpitSVGPolyfill:setZoomFactor,",d=Symbol(),h=Symbol();const g=()=>{const t="Apple Computer, Inc."===navigator.vendor,e=t?[u]:[],i={then:e=>(t?(async()=>{if(void 0===l){const t=document.createElement("canvas");t.width=10,t.height=10;const e=t.getContext("2d"),i=new Image(10,10),n=new Promise((t=>{i.addEventListener("load",(()=>t()))}));i.crossOrigin="anonymous",i.src="data:image/svg+xml;charset=utf8,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2210%22%20height%3D%2210%22%20viewBox%3D%220%200%201%201%22%3E%3CforeignObject%20width%3D%221%22%20height%3D%221%22%20requiredExtensions%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxhtml%22%3E%3Cdiv%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxhtml%22%20style%3D%22width%3A%201px%3B%20height%3A%201px%3B%20background%3A%20red%3B%20position%3A%20relative%22%3E%3C%2Fdiv%3E%3C%2FforeignObject%3E%3C%2Fsvg%3E",await n,e.drawImage(i,0,0),l=e.getImageData(5,5,1,1).data[3]<128}return l})().then((t=>{null==e||e(t?[u]:[])})):null==e||e([]),i)};return Object.assign(e,i)};let p,m;function u(t){const e="object"==typeof t&&t.target||document,i="object"==typeof t?t.zoom:t;window[h]||(Object.defineProperty(window,h,{configurable:!0,value:!0}),document.body.style.zoom=1.0001,document.body.offsetHeight,document.body.style.zoom=1,window.addEventListener("message",(({data:t,origin:e})=>{if(e===window.origin)try{if(t&&"string"==typeof t&&t.startsWith(c)){const[,e]=t.split(","),i=Number.parseFloat(e);Number.isNaN(i)||(m=i)}}catch(t){console.error(t)}})));let n=!1;Array.from(e.querySelectorAll("svg[data-marpit-svg]"),(t=>{var e,s,r,o;t.style.transform||(t.style.transform="translateZ(0)");const a=i||m||t.currentScale||1;p!==a&&(p=a,n=a);const l=t.getBoundingClientRect(),{length:c}=t.children;for(let i=0;i<c;i+=1){const n=t.children[i];if(n.getScreenCTM){const t=n.getScreenCTM();if(t){const i=null!==(s=null===(e=n.x)||void 0===e?void 0:e.baseVal.value)&&void 0!==s?s:0,c=null!==(o=null===(r=n.y)||void 0===r?void 0:r.baseVal.value)&&void 0!==o?o:0,d=n.children.length;for(let e=0;e<d;e+=1){const s=n.children[e];if("SECTION"===s.tagName){const{style:e}=s;e.transformOrigin||(e.transformOrigin=`${-i}px ${-c}px`),e.transform=`scale(${a}) matrix(${t.a}, ${t.b}, ${t.c}, ${t.d}, ${t.e-l.left}, ${t.f-l.top}) translateZ(0.0001px)`;break}}}}}})),!1!==n&&Array.from(e.querySelectorAll("iframe"),(({contentWindow:t})=>{null==t||t.postMessage(`${c}${n}`,"null"===window.origin?"*":window.origin)}))}function v({once:t=!1,target:e=document}={}){const i=function(t=document){if(t[d])return t[d];let e=!0;const i=()=>{e=!1,delete t[d]};Object.defineProperty(t,d,{configurable:!0,value:i});let n=[],s=!1;(async()=>{try{n=await g()}finally{s=!0}})();const r=()=>{for(const e of n)e({target:t});s&&0===n.length||e&&window.requestAnimationFrame(r)};return r(),i}(e);return t?(i(),()=>{}):i}p=1,m=void 0;const w=Symbol(),b=(e=document)=>{if("undefined"==typeof window)throw new Error("Marp Core's browser script is valid only in browser context.");if(((e=document)=>{const i=window[a];i||customElements.define("marp-auto-scaling",s);for(const n of Object.keys(t)){const s=`marp-${n}`,a=t[n].proto();(o??(o=!!document.createElement("div",{is:"marp-auto-scaling"}).outerHTML.startsWith("<div is"),o))&&a!==HTMLElement?i||customElements.define(s,r(a,{style:t[n].style}),{extends:n}):(i||customElements.define(s,r(HTMLElement,t[n])),e.querySelectorAll(`${n}[is="${s}"]`).forEach((t=>{t.outerHTML=t.outerHTML.replace(new RegExp(`^<${n}`,"i"),`<${s}`).replace(new RegExp(`</${n}>$`,"i"),`</${s}>`)})))}window[a]=!0})(e),e[w])return e[w];const i=v({target:e}),n=()=>{i(),delete e[w]},l=Object.assign(n,{cleanup:n,update:()=>b(e)});return Object.defineProperty(e,w,{configurable:!0,value:l}),l},y=document.currentScript;b(y?y.getRootNode():document)}();
</script></foreignObject></svg></div><div class="bespoke-marp-note" data-index="0" tabindex="0"><p> In questa introduzione, presenter uno dei concetti fondamentali dell'NLP: come trasformiamo il testo in qualcosa che i computer possano comprendere. Questo modulo  cruciale perch la rappresentazione del testo  alla base di qualsiasi applicazione di NLP.

Potrei iniziare chiedendo alla classe: &quot;Come pensate che un computer 'veda' un testo come una frase o un documento?&quot; per stimolare la riflessione sul divario tra linguaggio umano e elaborazione computazionale.

L'evoluzione delle tecniche di rappresentazione del testo che vedremo oggi riflette l'intera storia dell'NLP, dalle rappresentazioni sparse degli anni '90 fino ai moderni embedding contestuali che alimentano i sistemi pi avanzati.</p></div><div class="bespoke-marp-note" data-index="1" tabindex="0"><p> Questa  la roadmap del nostro viaggio di oggi. Partiremo dalle basi, esplorando perch abbiamo bisogno di rappresentare il testo in formati comprensibili per i computer.

Passeremo poi dalle tecniche tradizionali, che hanno dominato il campo per decenni, ai moderni word embeddings che hanno rivoluzionato l'NLP dal 2013 in poi.

Vedremo non solo la teoria ma anche applicazioni pratiche in vari settori aziendali, per comprendere l'impatto reale di queste tecnologie.

Potrei chiedere: &quot;Quali di questi argomenti vi interessano di pi?&quot; per personalizzare leggermente la presentazione in base agli interessi della classe.</p></div><div class="bespoke-marp-note" data-index="2" tabindex="0"><p> Questa sezione  fondamentale per stabilire le basi concettuali. Voglio che gli studenti comprendano che l'NLP affronta una sfida fondamentale: il divario tra il modo in cui noi umani comprendiamo il linguaggio e il modo in cui i computer elaborano i dati.

 importante sottolineare che questo non  solo un problema tecnico ma concettuale: come traduciamo il significato, le sfumature e la ricchezza del linguaggio umano in rappresentazioni matematiche che un computer possa manipolare?</p></div><div class="bespoke-marp-note" data-index="3" tabindex="0"><p> Qui sto introducendo il concetto fondamentale: i computer non &quot;leggono&quot; come noi. Per loro, il testo  solo una sequenza di caratteri senza significato intrinseco.

Posso usare un'analogia: &quot; come se dovessimo comunicare con qualcuno che non conosce nessuna lingua umana - dobbiamo trovare un sistema di traduzione che trasformi le nostre parole in qualcosa che possa comprendere.&quot;

Una domanda stimolante per la classe potrebbe essere: &quot;Pensate a come spieghereste il concetto di 'felicit' a un computer. Quali caratteristiche numeriche usereste per rappresentarlo?&quot;

Questo aiuta a far capire la complessit della sfida: trasformare concetti astratti e sfumati in rappresentazioni precise e calcolabili.</p></div><div class="bespoke-marp-note" data-index="4" tabindex="0"><p> Questo  un punto cruciale che voglio enfatizzare: la rappresentazione  spesso pi importante dell'algoritmo stesso!

Posso usare un'analogia culinaria: &quot;Potete avere lo chef pi talentuoso del mondo, ma se gli date ingredienti scadenti, il piatto non sar mai eccellente. Allo stesso modo, anche l'algoritmo pi sofisticato non pu fare miracoli con una rappresentazione povera del testo.&quot;

Una domanda interessante per stimolare la discussione: &quot;Perch pensate che per decenni l'NLP abbia avuto progressi limitati nonostante l'aumento della potenza computazionale?&quot; La risposta  proprio legata ai limiti delle rappresentazioni tradizionali che vedremo nella prossima sezione.

Potrei anche menzionare che molti dei recenti progressi nell'NLP sono dovuti pi a migliori rappresentazioni che a algoritmi pi complessi.</p></div><div class="bespoke-marp-note" data-index="5" tabindex="0"><p> In questa sezione, far un viaggio nel passato dell'NLP per comprendere le fondamenta su cui si basa tutto il campo.

 importante comprendere queste tecniche tradizionali per tre motivi:
1. Sono ancora utilizzate in molti contesti pratici per la loro semplicit ed efficienza
2. Aiutano a comprendere per contrasto i vantaggi dei moderni word embeddings
3. Molti concetti fondamentali dell'NLP sono nati con queste tecniche

Domanda: &quot;Qualcuno di voi ha mai sentito parlare di Bag-of-Words o TF-IDF?&quot; per valutare il livello di familiarit della classe con questi concetti.</p></div><div class="bespoke-marp-note" data-index="6" tabindex="0"><p>Partirei spiegando il meccanismo di base: &quot;Immaginate di avere un vocabolario di 50.000 parole. Con il one-hot encoding, ogni parola diventa un vettore di 50.000 elementi, dove solo uno di questi elementi  1 - precisamente quello corrispondente alla posizione della parola nel vocabolario - mentre tutti gli altri sono 0.&quot;

Per renderlo pi concreto, farei un esempio pratico: &quot;Se il nostro vocabolario fosse semplicemente ['cane', 'gatto', 'topo'], la parola 'gatto' sarebbe rappresentata come [0,1,0]. Ogni parola diventa quindi un vettore con un solo valore attivo.&quot;

Quando arrivo alle limitazioni, enfatizzerei questi punti critici:

Alta dimensionalit: &quot;Un vocabolario realistico pu contenere centinaia di migliaia di parole. Questo significa che ogni parola diventa un vettore enorme, per lo pi composto da zeri - estremamente inefficiente dal punto di vista computazionale e di memoria.&quot;

Mancanza di informazione semantica: &quot;In questo spazio vettoriale, tutte le parole sono equidistanti tra loro. Matematicamente, la distanza tra 'cane' e 'gatto'  identica alla distanza tra 'cane' e 'asteroide', il che non riflette la realt semantica del linguaggio.&quot;

Nessuna generalizzazione: &quot;Se il modello impara qualcosa sulla parola 'cane', questa conoscenza non si trasferisce automaticamente a parole simili come 'cagnolino' o 'canile'.&quot;

Domande che potrei porre all'audience:

&quot;Quali problemi pratici potrebbe causare questa rappresentazione in un'applicazione NLP reale?&quot;
&quot;Come pensate si potrebbe migliorare questa rappresentazione per catturare relazioni semantiche?&quot;
Concluderei accennando che: &quot;Queste limitazioni hanno spinto la ricerca verso rappresentazioni pi sofisticate come i word embeddings, che vedremo nelle prossime slide. Questi metodi riescono a catturare relazioni semantiche tra parole, riducendo drasticamente la dimensionalit e permettendo generalizzazioni pi efficaci.&quot; </p></div><div class="bespoke-marp-note" data-index="7" tabindex="0"><p>&quot;Il Bag-of-Words, letteralmente 'sacchetto di parole',  un modello che rappresenta un documento come un vettore numerico basato sulla frequenza delle parole. Come suggerisce il nome, immaginate di mettere tutte le parole di un documento in un sacchetto, perdendo completamente l'informazione sull'ordine in cui appaiono.&quot;

Per l'esempio nella slide: &quot;Prendiamo la frase 'Il gatto insegue il topo'. Con BoW, questa diventa un vettore dove ogni posizione corrisponde a una parola del nostro vocabolario. Il valore in ciascuna posizione indica quante volte quella parola appare nel documento. Quindi abbiamo 2 occorrenze di 'il', 1 di 'gatto', 1 di 'insegue', 1 di 'topo', e 0 per tutte le altre parole del vocabolario.&quot;

Sulle limitazioni, approfondirei ciascun punto:

Perdita dell'ordine delle parole: &quot;Frasi come 'Il gatto insegue il topo' e 'Il topo insegue il gatto' producono esattamente lo stesso vettore BoW, nonostante abbiano significati completamente diversi. Questa  una limitazione critica quando il significato dipende dalla sintassi.&quot;

Perdita di contesto: &quot;BoW non cattura relazioni contestuali tra le parole. Ad esempio, non distingue tra 'non sono felice' e 'sono felice', perdendo la negazione che cambia completamente il significato.&quot;

Alta dimensionalit: &quot;Come per il one-hot encoding, la dimensione del vettore  pari alla dimensione del vocabolario, creando vettori molto sparsi (con molti zeri) per documenti brevi.&quot;

Domande stimolanti per l'audience:

&quot;In quali applicazioni NLP pensate che il BoW possa essere comunque efficace, nonostante queste limitazioni?&quot;
&quot;Come potremmo modificare questo approccio per preservare almeno parte dell'informazione sull'ordine delle parole?&quot;
Concluderei con un collegamento: &quot;Nonostante queste limitazioni, il BoW  ancora utilizzato in molte applicazioni di base come la classificazione di documenti o l'analisi dei sentimenti. Nelle prossime slide vedremo come il modello TF-IDF costruisce su questo approccio per migliorarne l'efficacia, e successivamente esploreremo tecniche pi avanzate che preservano meglio le informazioni contestuali.&quot; </p></div><div class="bespoke-marp-note" data-index="8" tabindex="0"><p>Term Frequency-Inverse Document Frequency (TF-IDF) 
In questa slide introduco TF-IDF, un'evoluzione fondamentale del modello Bag-of-Words che risolve alcuni dei suoi problemi principali. 

Inizierei spiegando il concetto base: &quot;TF-IDF  una tecnica statistica che valuta l'importanza di una parola in un documento rispetto a una collezione di documenti. A differenza del semplice conteggio delle parole nel BoW, TF-IDF considera quanto una parola  distintiva per un particolare documento.&quot;

Per la formula, la scomporrei nei suoi componenti: &quot;La formula TF-IDF  il prodotto di due componenti. Il primo, Term Frequency (TF), misura quanto frequentemente una parola appare in un documento - simile a quanto facciamo con BoW. Il secondo, Inverse Document Frequency (IDF), misura quanto  rara quella parola nell'intera collezione di documenti.&quot;

Approfondirei l'IDF con un esempio concreto: &quot;Immaginate di avere 1000 articoli di giornale. Parole come 'il' o 'e' appariranno in quasi tutti i 1000 documenti, quindi il loro IDF sar log(1000/1000)  0. Al contrario, una parola tecnica come 'trasformatore' potrebbe apparire solo in 10 documenti, quindi il suo IDF sar log(1000/10)  2. Moltiplicando questo valore per la TF, diamo molto pi peso alle parole rare e distintive.&quot;

Sui vantaggi, enfatizzerei:

Migliore capacit discriminativa: &quot;TF-IDF riesce a identificare le parole veramente importanti in un documento. Mentre BoW tratta tutte le parole allo stesso modo, TF-IDF d pi peso alle parole che sono frequenti in un documento ma rare negli altri, catturando meglio l'unicit tematica di ciascun testo.&quot;

Penalizzazione delle parole comuni: &quot;Parole come articoli, preposizioni e congiunzioni, che appaiono in quasi tutti i documenti, ricevono un peso IDF vicino a zero, riducendo automaticamente il loro impatto. Questo  un vantaggio enorme rispetto al BoW, dove queste parole poco informative possono dominare la rappresentazione.&quot;

Domande stimolanti per l'audience:

&quot;Quali tipi di applicazioni NLP potrebbero beneficiare maggiormente di questa ponderazione delle parole?&quot;
&quot;Pensate a un caso in cui TF-IDF potrebbe non essere sufficiente. Quali informazioni linguistiche rimangono comunque non catturate?&quot;
Concluderei con un'osservazione pratica: &quot;TF-IDF  ancora oggi ampiamente utilizzato in molte applicazioni reali come motori di ricerca, sistemi di raccomandazione e classificazione di documenti.  un ottimo esempio di come una formula relativamente semplice possa migliorare significativamente le prestazioni rispetto all'approccio base. Tuttavia, come vedremo nelle prossime slide, anche TF-IDF ha i suoi limiti, soprattutto nella capacit di catturare relazioni semantiche tra parole, problema che sar affrontato dai word embeddings.&quot; </p></div><div class="bespoke-marp-note" data-index="9" tabindex="0"><p>Speaker Notes: N-grams 
In questa slide presento gli N-grams, un'evoluzione importante del modello Bag-of-Words che cerca di risolvere uno dei suoi problemi principali: la perdita dell'ordine delle parole. 

Inizierei spiegando il concetto base: &quot;Gli N-grams sono sequenze contigue di N elementi (parole, caratteri o token) estratti da un testo. A differenza del BoW che considera solo parole singole, gli N-grams mantengono una parte dell'informazione sull'ordine catturando gruppi di parole consecutive.&quot;

Chiarire la terminologia: &quot;In base al valore di N, abbiamo diversi tipi di N-grams: unigrams (N=1, equivalenti al BoW), bigrams (N=2), trigrams (N=3) e cos via. Pi alto  il valore di N, pi informazione contestuale viene preservata.&quot;

Per l'esempio nella slide: &quot;Prendiamo la frase 'Il gatto insegue il topo'. Con i bigrams, invece di considerare le singole parole, consideriamo coppie di parole consecutive: 'il gatto', 'gatto insegue', 'insegue il', 'il topo'. Notate come ora possiamo distinguere tra 'il gatto insegue il topo' e 'il topo insegue il gatto', cosa impossibile con il semplice BoW.&quot;

Sulle limitazioni, approfondirei:

Dimensionalit aumenta esponenzialmente con N: &quot;Se il nostro vocabolario contiene V parole, il numero potenziale di bigrams  V, di trigrams  V, e cos via. Questo porta rapidamente a una esplosione combinatoria che rende computazionalmente proibitivo lavorare con N-grams di ordine elevato.&quot;

Sparsit dei dati: &quot;Con l'aumentare di N, la probabilit di incontrare esattamente la stessa sequenza di N parole in documenti diversi diminuisce drasticamente. Questo fenomeno, noto come 'data sparsity', significa che la maggior parte degli N-grams possibili non appare mai nei dati, rendendo difficile per i modelli generalizzare efficacemente.&quot;

Domande stimolanti per l'audience:

&quot;Quale valore di N pensate possa offrire il miglior compromesso tra cattura del contesto e gestibilit computazionale?&quot;
&quot;In quali applicazioni specifiche gli N-grams potrebbero essere particolarmente utili rispetto al semplice BoW?&quot;
Concluderei con un'osservazione pratica: &quot;Gli N-grams sono stati ampiamente utilizzati in molte applicazioni NLP tradizionali, come il completamento automatico, la correzione ortografica e i modelli linguistici statistici. Rappresentano un tentativo di bilanciare la semplicit computazionale del BoW con la necessit di catturare relazioni sequenziali nel testo. Tuttavia, come vedremo, anche gli N-grams hanno limiti significativi che hanno spinto la ricerca verso rappresentazioni pi sofisticate come i word embeddings e i modelli basati su reti neurali.&quot; </p></div><div class="bespoke-marp-note" data-index="12" tabindex="0"><p>Speaker Notes: Cos' un word embedding? 
In questa slide introduco il concetto di word embedding, che rappresenta una vera e propria rivoluzione nella rappresentazione delle parole per l'NLP. 

Inizierei con una definizione chiara: &quot;I word embeddings sono rappresentazioni vettoriali dense di parole in uno spazio continuo multidimensionale. A differenza delle rappresentazioni precedenti come one-hot encoding o BoW, gli embeddings catturano relazioni semantiche tra le parole posizionandole in uno spazio vettoriale dove la vicinanza e la direzione hanno un significato linguistico.&quot;

Spiegherei il concetto con un'analogia: &quot;Immaginate di poter mappare ogni parola del vocabolario in un universo multidimensionale, dove parole con significati simili si trovano vicine tra loro. Ad esempio, in questo spazio 'cane' e 'gatto' sarebbero relativamente vicini perch entrambi animali domestici, mentre 'automobile' sarebbe pi distante. Non solo: in questo spazio le relazioni semantiche diventano operazioni matematiche sui vettori.&quot;

Per rendere concreto il concetto: &quot;Un famoso esempio  l'analogia 're - uomo + donna = regina'. Nel giusto spazio di embedding, se prendiamo il vettore della parola 're', sottraiamo il vettore di 'uomo' e aggiungiamo quello di 'donna', otteniamo un vettore molto vicino a quello della parola 'regina'. Questo dimostra come gli embeddings catturino relazioni semantiche complesse.&quot;

Sulle differenze con le rappresentazioni one-hot, enfatizzerei:

Densi vs sparsi: &quot;Mentre i vettori one-hot sono composti quasi interamente da zeri con un solo valore a 1, gli embeddings sono vettori densi dove ogni dimensione contribuisce con un valore significativo.&quot;

Semanticamente significativi vs arbitrari: &quot;Nei vettori one-hot, la posizione del valore 1  arbitraria e non dice nulla sul significato della parola. Negli embeddings, invece, ogni dimensione contribuisce a codificare qualche aspetto semantico o sintattico della parola.&quot;

Dimensionalit ridotta vs alta dimensionalit: &quot;Passiamo da vettori con dimensionalit pari al vocabolario (potenzialmente centinaia di migliaia) a vettori tipicamente di 100-300 dimensioni, rendendo il calcolo molto pi efficiente.&quot;

Domande stimolanti per l'audience:

&quot;Quali tipi di relazioni linguistiche pensate possano essere catturate da questi vettori?&quot;
&quot;Come potrebbe un algoritmo imparare automaticamente queste rappresentazioni vettoriali a partire da testi non annotati?&quot;
Concluderei con un'osservazione sull'impatto: &quot;L'introduzione dei word embeddings ha segnato un punto di svolta nell'NLP, permettendo ai modelli di catturare sfumature semantiche prima inaccessibili. Nelle prossime slide vedremo come questi embeddings vengono effettivamente generati attraverso algoritmi come Word2Vec, GloVe e FastText, e come hanno aperto la strada ai moderni modelli linguistici basati su architetture neurali pi complesse.&quot; </p></div><div class="bespoke-marp-note" data-index="13" tabindex="0"><p># Speaker Notes: Propriet sorprendenti dei word embeddings 

In questa slide mostro una delle caratteristiche pi affascinanti dei word embeddings, che ha stupito anche i ricercatori quando  stata scoperta. 

Inizierei creando un momento di suspense: &quot;Quello che sto per mostrarvi  qualcosa che ha sorpreso la comunit scientifica quando  emerso dai primi esperimenti con i word embeddings. Non era un obiettivo esplicito degli algoritmi, ma  emerso spontaneamente durante l'addestramento.&quot;

Presenterei l'esempio principale con entusiasmo: &quot;Guardate questa equazione vettoriale: vector('re') - vector('uomo') + vector('donna')  vector('regina'). Cosa significa? Se prendiamo il vettore della parola 're', sottraiamo le caratteristiche semantiche di 'uomo' e aggiungiamo quelle di 'donna', otteniamo un vettore che  estremamente vicino a quello della parola 'regina'! In altre parole, l'algoritmo ha implicitamente imparato la relazione 're sta a regina come uomo sta a donna'.&quot;

Aggiungerei altri esempi per rafforzare il concetto: &quot;E non  l'unico caso. Funziona con relazioni come capitali e paesi: vector('Francia') - vector('Parigi') + vector('Roma')  vector('Italia'). O con tempi verbali: vector('cammina') - vector('camminare') + vector('correre')  vector('corre').&quot;

Enfatizzerei l'aspetto sorprendente: &quot;La cosa pi straordinaria  che nessuno ha programmato esplicitamente queste relazioni! Sono emerse naturalmente dal processo di addestramento, che ha semplicemente cercato di predire quali parole appaiono in contesti simili.  come se l'algoritmo avesse scoperto autonomamente la struttura semantica e grammaticale del linguaggio.&quot;

Spiegherei il significato pi profondo: &quot;Questo fenomeno ci dice qualcosa di fondamentale: le relazioni semantiche nel linguaggio possono essere codificate come relazioni geometriche in uno spazio vettoriale.  una conferma matematica dell'intuizione linguistica che il significato delle parole  definito dalle relazioni con altre parole.&quot;

Domande stimolanti per l'audience:
- &quot;Quali altre relazioni linguistiche pensate possano essere catturate da queste operazioni vettoriali?&quot;
- &quot;Cosa ci dice questo fenomeno sulla natura del linguaggio stesso e su come potrebbe essere rappresentato nel cervello umano?&quot;

Concluderei con una riflessione: &quot;Questa propriet ha implicazioni profonde. Significa che possiamo manipolare matematicamente i concetti linguistici, aprendo la strada a sistemi che 'ragionano' con le parole.  uno dei primi esempi in cui vediamo un sistema di AI che sembra catturare qualcosa di simile alla comprensione semantica, anche se in forma rudimentale. Nelle prossime slide vedremo come queste propriet vengono sfruttate in applicazioni pratiche e come hanno influenzato lo sviluppo di modelli linguistici ancora pi avanzati.&quot; </p></div><div class="bespoke-marp-note" data-index="14" tabindex="0"><p># Speaker Notes: Principi di funzionamento 

In questa slide spiego i principi fondamentali che stanno alla base dei word embeddings e come vengono effettivamente creati. 

Inizierei con l'ipotesi distribuzionale: &quot;Alla base di tutti i moderni word embeddings c' un'intuizione linguistica fondamentale chiamata 'ipotesi distribuzionale', sintetizzata perfettamente dalla celebre frase del linguista J.R. Firth: 'You shall know a word by the company it keeps' - 'Conoscerai una parola dalla compagnia che frequenta'. In altre parole, il significato di una parola  strettamente legato al contesto in cui appare.&quot;

Spiegherei il concetto con esempi concreti: &quot;Pensate a parole come 'banca' e 'istituto'. Entrambe tendono ad apparire vicino a parole come 'prestito', 'denaro', 'interesse', 'conto'. Questa somiglianza contestuale suggerisce una somiglianza semantica. Al contrario, la parola 'mela' appare in contesti completamente diversi, vicino a parole come 'frutta', 'mangiare', 'dolce', segnalando un significato distante.&quot;

Sul principio generale: &quot;L'idea chiave  che parole che appaiono in contesti simili tendono ad avere significati simili. Gli algoritmi di word embedding sfruttano questa regolarit statistica per posizionare parole semanticamente simili vicine nello spazio vettoriale.&quot;

Sui diversi approcci di addestramento, entrerei nel dettaglio:

1. **CBOW (Continuous Bag of Words)**: &quot;In questo approccio, il modello cerca di predire una parola target date le parole di contesto che la circondano. Ad esempio, dato 'Il ____ abbaia forte', il modello dovrebbe predire 'cane'. Questo costringe il modello a catturare il significato delle parole dal loro contesto.&quot;

2. **Skip-gram**: &quot; l'inverso del CBOW: data una parola, il modello cerca di predire le parole di contesto che probabilmente la circondano. Ad esempio, data la parola 'cane', il modello potrebbe predire parole come 'abbaia', 'cucciolo', 'zampe'. Questo approccio funziona particolarmente bene con parole rare.&quot;

3. **GloVe (Global Vectors)**: &quot;A differenza dei primi due che sono predittivi, GloVe si basa sulle statistiche globali di co-occorrenza delle parole nell'intero corpus. Cerca di catturare quanto spesso le parole appaiono insieme, considerando l'intero corpus simultaneamente invece di finestre di contesto locali.&quot;

Domande stimolanti per l'audience:
- &quot;Quali tipi di relazioni semantiche pensate siano pi facilmente catturabili attraverso questi metodi? E quali potrebbero essere pi difficili?&quot;
- &quot;Come potrebbe influire la dimensione della finestra di contesto (quante parole consideriamo intorno a quella target) sulla qualit degli embeddings?&quot;

Concluderei con un'osservazione pratica: &quot;Questi diversi approcci hanno ciascuno i propri punti di forza. Word2Vec (che implementa CBOW e Skip-gram)  computazionalmente efficiente e cattura bene analogie, GloVe sfrutta meglio le statistiche globali, mentre FastText (una variante di Word2Vec) lavora a livello di subword, gestendo meglio parole sconosciute e morfologicamente complesse. La scelta dell'algoritmo dipende spesso dall'applicazione specifica e dalle caratteristiche della lingua con cui si lavora.&quot; </p></div><div class="bespoke-marp-note" data-index="15" tabindex="0"><p># Speaker Notes: Word2Vec 

In questa slide presento Word2Vec, uno degli algoritmi pi influenti nella storia recente dell'NLP, che ha davvero rivoluzionato il modo in cui rappresentiamo le parole. 

Inizierei con il contesto storico: &quot;Word2Vec  stato sviluppato da un team di ricercatori di Google guidato da Tomas Mikolov nel 2013.  importante sottolineare che questo algoritmo ha rappresentato un punto di svolta nell'NLP, non tanto per l'idea di base (gli embeddings esistevano gi), quanto per l'efficienza computazionale che ha reso possibile addestrare embeddings di alta qualit su corpora testuali enormi in tempi ragionevoli.&quot;

Sulle due varianti principali, spiegherei con esempi concreti:

1. **CBOW (Continuous Bag of Words)**: &quot;In questo modello, prendiamo le parole che circondano una posizione e cerchiamo di predire quale parola dovrebbe trovarsi in quella posizione. Ad esempio, dato 'Il ____  sul tavolo', il modello cerca di predire 'libro'.  come un esercizio di riempimento degli spazi vuoti. Questo approccio  pi veloce da addestrare e tende a funzionare meglio con parole frequenti.&quot;

2. **Skip-gram**: &quot;Questo modello fa l'opposto: data una parola, cerca di predire le parole che probabilmente la circondano. Ad esempio, data la parola 'libro', il modello potrebbe predire parole come 'leggere', 'pagine', 'autore'. Questo approccio  computazionalmente pi intensivo ma funziona meglio con parole rare e produce embeddings di qualit superiore per la maggior parte delle applicazioni.&quot;

Sull'architettura: &quot;Nonostante i risultati impressionanti, l'architettura di Word2Vec  sorprendentemente semplice: una rete neurale con un solo strato nascosto. Questo  un esempio perfetto del principio che in machine learning a volte modelli pi semplici ma ben progettati possono superare architetture pi complesse. La magia sta nel modo in cui l'algoritmo  ottimizzato e nell'intuizione linguistica che lo guida.&quot;

Aggiungerei un dettaglio tecnico importante: &quot;Un aspetto cruciale di Word2Vec  che non siamo realmente interessati alla sua capacit predittiva. Il suo obiettivo di predire parole  solo un pretesto, un 'compito surrogato'. Ci che ci interessa davvero sono i pesi appresi dallo strato nascosto della rete, che diventano i nostri word embeddings.  un esempio brillante di apprendimento non supervisionato mascherato da task supervisionato.&quot;

Domande stimolanti per l'audience:
- &quot;Perch pensate che un'architettura cos semplice riesca a catturare relazioni semantiche complesse?&quot;
- &quot;Quali vantaggi e svantaggi vedete nelle due varianti CBOW e Skip-gram per diverse applicazioni?&quot;

Concluderei con l'impatto: &quot;Word2Vec ha avuto un impatto enorme non solo per i suoi risultati tecnici, ma anche perch ha ispirato una nuova ondata di ricerca sulle rappresentazioni distribuite. Ha dimostrato che con il giusto obiettivo di addestramento, anche modelli relativamente semplici possono catturare strutture semantiche complesse. Molti degli algoritmi che vedremo successivamente, fino ai moderni transformer, si basano su intuizioni simili ma con architetture pi sofisticate.&quot; </p></div><div class="bespoke-marp-note" data-index="16" tabindex="0"><p># Speaker Notes: GloVe (Global Vectors) 

In questa slide presento GloVe, un algoritmo che rappresenta un'evoluzione importante nel campo dei word embeddings, sviluppato poco dopo Word2Vec. 

Inizierei con il contesto: &quot;GloVe, acronimo di Global Vectors,  stato sviluppato nel 2014 da un team di ricercatori dell'Universit di Stanford guidato da Jeffrey Pennington, Richard Socher e Christopher Manning.  nato come tentativo di combinare i punti di forza di due approcci precedenti: i metodi predittivi come Word2Vec e i metodi basati su matrici di co-occorrenza.&quot;

Spiegherei l'intuizione fondamentale: &quot;L'intuizione chiave dietro GloVe  che le informazioni sulla relazione tra parole non sono contenute solo nei contesti locali (come in Word2Vec), ma anche nelle statistiche globali di co-occorrenza nell'intero corpus. In altre parole, quanto spesso due parole appaiono insieme in tutto il corpus  un segnale importante del loro rapporto semantico.&quot;

Sul funzionamento tecnico: &quot;GloVe opera in due fasi principali. Prima costruisce una matrice di co-occorrenza, contando quante volte ogni parola appare vicino a ogni altra parola nell'intero corpus. Poi addestra un modello per predire il logaritmo delle probabilit di co-occorrenza. Questo approccio  elegante perch trasforma un problema di conteggio in un problema di regressione logistica, permettendo di catturare relazioni pi sottili.&quot;

Farei un esempio concreto: &quot;Immaginate di analizzare un grande corpus e scoprire che la parola 'ghiaccio' appare vicino a 'freddo' 300 volte, ma vicino a 'vapore' solo 5 volte. Questa asimmetria nelle co-occorrenze rivela qualcosa sulla relazione semantica tra queste parole. GloVe  progettato specificamente per catturare queste relazioni attraverso il rapporto tra probabilit di co-occorrenza.&quot;

Sui vantaggi, enfatizzerei:

1. **Cattura sia informazioni locali che globali**: &quot;A differenza di Word2Vec che lavora con finestre di contesto locali, GloVe considera l'intero corpus simultaneamente, permettendo di catturare relazioni a lungo raggio che potrebbero essere perse in un approccio puramente locale.&quot;

2. **Migliore performance su alcune relazioni semantiche**: &quot;Gli studi empirici hanno mostrato che GloVe tende a performare meglio in task che richiedono la comprensione di relazioni semantiche pi sottili e complesse, come analogie e similarit semantiche.&quot;

Aggiungerei un confronto: &quot; interessante notare che mentre Word2Vec  un modello predittivo addestrato con discesa del gradiente stocastica, GloVe  essenzialmente un modello di fattorizzazione di matrice. Questa differenza di approccio porta a embeddings con caratteristiche leggermente diverse, ognuno con i propri punti di forza.&quot;

Domande stimolanti per l'audience:
- &quot;In quali tipi di applicazioni pensate che la capacit di GloVe di catturare statistiche globali potrebbe essere particolarmente vantaggiosa?&quot;
- &quot;Quali tipi di relazioni semantiche potrebbero essere difficili da catturare anche con questo approccio pi sofisticato?&quot;

Concluderei con un'osservazione pratica: &quot;Nella pratica, sia Word2Vec che GloVe producono embeddings di alta qualit, e la scelta tra i due spesso dipende dall'applicazione specifica e dal dominio. Molti professionisti NLP mantengono entrambi nel loro arsenale di strumenti.  anche comune utilizzare embeddings pre-addestrati su corpora enormi e poi affinarli per compiti specifici, risparmiando risorse computazionali significative.&quot; </p></div><div class="bespoke-marp-note" data-index="17" tabindex="0"><p># Speaker Notes: FastText 

In questa slide presento FastText, un'evoluzione significativa degli algoritmi di word embedding che affronta alcune limitazioni fondamentali dei suoi predecessori. 

Inizierei con il contesto: &quot;FastText  stato sviluppato da Facebook AI Research nel 2016, guidato da ricercatori come Tomas Mikolov (lo stesso di Word2Vec) e Armand Joulin.  nato per risolvere uno dei problemi pi frustranti dei precedenti modelli di embedding: l'incapacit di gestire parole mai viste durante l'addestramento.&quot;

Spiegherei l'innovazione principale: &quot;L'intuizione geniale di FastText  considerare le parole non come unit atomiche indivisibili, ma come composizioni di frammenti pi piccoli. Invece di apprendere un vettore per l'intera parola, FastText apprende vettori per n-grammi di caratteri, cio sequenze di n caratteri consecutivi.&quot;

Farei un esempio concreto: &quot;Prendiamo la parola 'gatto'. Con n=3 (trigrammi), FastText la scompone in '&lt;ga', 'gat', 'att', 'tto', 'to&gt;' (dove &lt; e &gt; sono marcatori di inizio e fine parola). Ogni trigramma riceve un proprio vettore, e il vettore finale della parola 'gatto'  semplicemente la somma di questi vettori di trigrammi. Questo approccio  radicalmente diverso da Word2Vec e GloVe, che trattano 'gatto' come un'entit indivisibile.&quot;

Sui vantaggi, enfatizzerei:

1. **Gestione di parole fuori vocabolario (OOV)**: &quot;Questo  il vantaggio pi rivoluzionario. Se incontriamo una parola mai vista durante l'addestramento, come 'gattino', possiamo comunque generare un embedding sensato scomponendola nei suoi n-grammi, molti dei quali ('att', 'tto') saranno stati visti in altre parole. Con Word2Vec o GloVe, saremmo completamente bloccati.&quot;

2. **Migliore per lingue morfologicamente ricche**: &quot;In lingue come l'italiano, il tedesco o il finlandese, dove una radice pu generare molte forme flesse o parole composte, FastText brilla particolarmente. Ad esempio, in italiano, 'gatto', 'gatta', 'gattino', 'gattini' condividono molti n-grammi, permettendo al modello di catturare la loro relazione morfologica anche se alcune forme sono rare nel corpus.&quot;

Aggiungerei un dettaglio tecnico importante: &quot; interessante notare che FastText non abbandona l'architettura di Word2Vec, ma la estende. Utilizza ancora CBOW o Skip-gram come obiettivi di addestramento, ma cambia la rappresentazione interna delle parole. Questo dimostra come innovazioni significative possano venire non solo da nuove architetture, ma anche da nuove rappresentazioni dei dati.&quot;

Domande stimolanti per l'audience:
- &quot;In quali scenari applicativi pensate che la capacit di gestire parole sconosciute sia particolarmente critica?&quot;
- &quot;Quali compromessi potrebbero esserci tra la rappresentazione a livello di parola e quella a livello di carattere?&quot;

Concluderei con un'osservazione pratica: &quot;FastText ha avuto un impatto enorme soprattutto nell'elaborazione di lingue diverse dall'inglese e in domini con vocabolari specialistici o in rapida evoluzione.  anche computazionalmente efficiente e gli embeddings pre-addestrati di FastText sono disponibili per 157 lingue, rendendolo uno strumento estremamente versatile. Questa evoluzione ci mostra come il campo dell'NLP continui a progredire affrontando le limitazioni pratiche dei modelli precedenti.&quot; </p></div><div class="bespoke-marp-note" data-index="19" tabindex="0"><p># Speaker Notes: Tecniche di riduzione della dimensionalit 

In questa slide affronto un aspetto pratico ma fondamentale quando lavoriamo con i word embeddings: come visualizzarli e interpretarli. 

Inizierei con il problema di base: &quot;Gli embeddings che abbiamo discusso finora esistono in spazi ad alta dimensionalit, tipicamente da 100 a 300 dimensioni. Questo li rende estremamente potenti per catturare relazioni semantiche complesse, ma presenta un problema: come possiamo visualizzarli? Il cervello umano non  in grado di concepire visivamente pi di 3 dimensioni. Ecco perch abbiamo bisogno di tecniche di riduzione della dimensionalit, che proiettano questi vettori ad alta dimensionalit in spazi 2D o 3D che possiamo effettivamente visualizzare.&quot;

Spiegherei poi le tre tecniche principali:

1. **PCA (Principal Component Analysis)**: &quot;Questa  la tecnica pi semplice e classica. PCA identifica le direzioni (componenti principali) lungo le quali i dati mostrano la massima varianza, e proietta i dati su queste direzioni.  come trovare gli assi pi informativi nello spazio originale. Il vantaggio di PCA  la sua semplicit e velocit, ma tende a preservare meglio le relazioni globali a scapito di quelle locali. Nelle visualizzazioni di word embeddings con PCA, spesso vediamo cluster generali di parole semanticamente correlate, ma le relazioni pi sottili possono perdersi.&quot;

2. **t-SNE (t-Distributed Stochastic Neighbor Embedding)**: &quot;Sviluppato nel 2008, t-SNE ha rivoluzionato la visualizzazione di dati ad alta dimensionalit. A differenza di PCA, t-SNE si concentra sul preservare le relazioni di vicinanza locale: se due parole sono vicine nello spazio originale, cercher di mantenerle vicine anche nella proiezione 2D. Questo produce visualizzazioni dove i cluster di parole simili sono chiaramente visibili. Il rovescio della medaglia  che t-SNE pu distorcere le relazioni globali e richiede un'attenta regolazione dei parametri.&quot;

3. **UMAP (Uniform Manifold Approximation and Projection)**: &quot;UMAP  una tecnica pi recente (2018) che cerca di combinare il meglio di entrambi i mondi. Preserva sia la struttura locale (come t-SNE) che quella globale dei dati.  anche computazionalmente pi efficiente di t-SNE, permettendo di visualizzare dataset pi grandi. Nelle visualizzazioni di word embeddings con UMAP, possiamo spesso osservare sia cluster locali ben definiti che relazioni globali tra questi cluster.&quot;

Aggiungerei un'osservazione importante: &quot; fondamentale ricordare che queste visualizzazioni sono sempre approssimazioni. Quando proiettiamo da 300 a 2 dimensioni, inevitabilmente perdiamo informazioni. Diverse tecniche preservano diversi aspetti dei dati originali, quindi  spesso utile confrontare visualizzazioni ottenute con metodi diversi per una comprensione pi completa.&quot;

Domande stimolanti per l'audience:
- &quot;Quali tipi di relazioni semantiche pensate siano pi facili da preservare in una visualizzazione 2D? E quali potrebbero essere pi difficili?&quot;
- &quot;Come potremmo usare queste visualizzazioni per valutare la qualit di diversi modelli di embedding?&quot;

Concluderei con un'applicazione pratica: &quot;Queste visualizzazioni non sono solo esercizi accademici. Sono strumenti potenti per l'analisi esplorativa dei dati, il debugging dei modelli e la comunicazione dei risultati. Ad esempio, visualizzando gli embeddings possiamo identificare bias nei dati, scoprire cluster semantici inaspettati, o semplicemente ottenere intuizioni su come il nostro modello 'vede' il linguaggio. Nella prossima slide, vedremo alcuni esempi concreti di queste visualizzazioni e cosa possono rivelarci.&quot; </p></div><div class="bespoke-marp-note" data-index="20" tabindex="0"><p># Speaker Notes: Interpretazione delle dimensioni 

In questa slide affronto una domanda fondamentale che spesso sorge quando si lavora con i word embeddings: cosa rappresentano effettivamente le singole dimensioni di questi vettori? 

Inizierei con una chiarificazione importante: &quot;Una delle prime cose che molti si chiedono quando iniziano a lavorare con gli embeddings : 'Cosa rappresenta la dimensione 42 o la dimensione 157?' La risposta, forse sorprendente,  che nella maggior parte dei casi le singole dimensioni non hanno un'interpretazione semantica chiara e intuitiva. Non c' una dimensione dedicata agli 'animali' o ai 'colori' o alla 'formalit'. Gli algoritmi di embedding distribuiscono l'informazione semantica attraverso tutte le dimensioni in modo complesso e intrecciato.&quot;

Passerei poi al concetto di direzioni significative: &quot;Tuttavia, ci che  davvero affascinante  che possiamo identificare direzioni nello spazio vettoriale che corrispondono a concetti semantici interpretabili. Queste direzioni non coincidono con gli assi originali, ma sono vettori che attraversano lo spazio multidimensionale.&quot;

Spiegherei con esempi concreti:

1. **Direzione di genere**: &quot;L'esempio pi famoso  la direzione di genere. Se calcoliamo il vettore differenza tra 'uomo' e 'donna', o tra 're' e 'regina', otteniamo vettori molto simili tra loro. Questo vettore differenza rappresenta una 'direzione di genere' nello spazio. Possiamo usarlo per trasformare altre parole: aggiungendo questa direzione a 'attore' otteniamo un punto vicino ad 'attrice'.  come se avessimo isolato il concetto di 'maschile vs femminile' in un singolo vettore.&quot;

2. **Direzione di formalit/informalit**: &quot;Un'altra direzione interessante  quella della formalit. Calcolando la differenza tra coppie come 'ciao' e 'salve', o 'grazie' e 'grazie mille', possiamo identificare una direzione che rappresenta il grado di formalit del linguaggio. Questo pu essere estremamente utile in applicazioni come la generazione di testo con tono controllabile.&quot;

3. **Direzione di positivit/negativit**: &quot;Similmente, possiamo identificare una direzione di sentimento calcolando la differenza tra parole con connotazione positiva e negativa. Questa direzione pu essere usata per analisi del sentimento o per modificare il tono emotivo di un testo.&quot;

Aggiungerei un'osservazione metodologica: &quot;Per identificare queste direzioni in modo robusto, tipicamente si calcolano le differenze tra molte coppie di parole che rappresentano lo stesso contrasto (non solo 'uomo'-'donna', ma anche 'attore'-'attrice', 'zio'-'zia', ecc.) e poi si calcola la media o si applica PCA a questi vettori differenza.&quot;

Domande stimolanti per l'audience:
- &quot;Quali altre direzioni semantiche significative pensate potrebbero essere identificate negli spazi di embedding?&quot;
- &quot;Come potremmo utilizzare queste direzioni per migliorare applicazioni NLP specifiche?&quot;

Concluderei con un'implicazione importante: &quot;Questa propriet degli embeddings di codificare concetti semantici come direzioni nello spazio vettoriale  fondamentale non solo per comprendere come funzionano, ma anche per applicazioni pratiche. Ad esempio,  alla base di tecniche di debiasing, dove identifichiamo e rimuoviamo direzioni indesiderate (come stereotipi di genere) dagli embeddings.  anche cruciale per tecniche avanzate come la manipolazione controllata del testo generato. Stiamo essenzialmente imparando a 'parlare la lingua' dello spazio vettoriale.&quot; </p></div><div class="bespoke-marp-note" data-index="21" tabindex="0"><p> Come facciamo a sapere se un set di word embeddings  &quot;buono&quot;? Ci sono diversi metodi di valutazione, sia intrinseci che estrinseci:

- **Test di analogia**: verificano se il modello pu risolvere analogie del tipo &quot;a sta a b come c sta a ?&quot;. Per esempio, &quot;uomo sta a re come donna sta a ?&quot; (risposta attesa: regina).

- **Test di similarit**: misurano la correlazione tra la similarit coseno degli embeddings e i giudizi umani di similarit tra parole. Dataset come WordSim-353 o SimLex-999 contengono coppie di parole con punteggi di similarit assegnati da annotatori umani.

- **Valutazione estrinseca**: misura quanto bene gli embeddings funzionano quando utilizzati in compiti downstream come classificazione di testi, named entity recognition, o sentiment analysis.

 importante notare che diversi embeddings possono eccellere in diversi tipi di valutazione. Per esempio, alcuni potrebbero essere migliori per catturare relazioni sintattiche, altri per relazioni semantiche.

La scelta degli embeddings dovrebbe quindi essere guidata dal tipo di applicazione specifica che stiamo sviluppando.</p></div><div class="bespoke-marp-note" data-index="22" tabindex="0"><p># Speaker Notes: Applicazione Aziendale: Ricerca Semantica nei Documenti Legali 

In questa slide presento un caso d'uso concreto e ad alto impatto dei word embeddings nel settore legale, un ambito che sta vivendo una vera rivoluzione grazie a queste tecnologie. 

Inizierei con il contesto del problema: &quot;Il settore legale  caratterizzato da un volume enorme di documenti testuali: contratti, sentenze, pareri, leggi e regolamenti. Tradizionalmente, l'analisi di questi documenti richiedeva ore di lavoro manuale da parte di professionisti altamente qualificati. La ricerca si basava principalmente su parole chiave, con tutti i limiti che questo comporta quando concetti simili vengono espressi con terminologia diversa.&quot;

Spiegherei poi come i word embeddings trasformano questo scenario:

1. **Ricerca di concetti legali simili con terminologia diversa**: &quot;Uno dei maggiori vantaggi degli embeddings  la capacit di trovare documenti semanticamente simili anche quando usano parole diverse. Ad esempio, una ricerca su 'violazione contrattuale' pu trovare documenti che parlano di 'inadempimento dell'accordo' o 'mancato rispetto delle clausole', anche se queste frasi non condividono alcuna parola con la query originale.&quot;

2. **Identificazione di precedenti rilevanti**: &quot;Nel diritto, i precedenti giurisprudenziali sono fondamentali. Gli embeddings permettono di identificare sentenze precedenti semanticamente simili al caso in esame, anche quando i dettagli specifici o la terminologia differiscono. Questo amplia enormemente la capacit di ricerca rispetto ai sistemi tradizionali basati su parole chiave o categorizzazioni manuali.&quot;

3. **Organizzazione automatica di archivi**: &quot;Gli studi legali possono utilizzare clustering basato su embeddings per organizzare automaticamente migliaia di documenti in categorie semantiche, facilitando la navigazione e la ricerca in archivi enormi. Questo permette di scoprire connessioni tra documenti che potrebbero non essere evidenti a prima vista.&quot;

4. **Suggerimento di clausole contrattuali**: &quot;Durante la stesura di un contratto, sistemi basati su embeddings possono suggerire clausole pertinenti basandosi sul contesto semantico di ci che si sta scrivendo, accelerando il processo di redazione e riducendo il rischio di omissioni.&quot;

5. **Vector DB e RAG**: &quot;Un'applicazione particolarmente innovativa  l'uso di database vettoriali per memorizzare embeddings di documenti legali, che vengono poi utilizzati nei sistemi di Retrieval-Augmented Generation. Questi sistemi possono rispondere a domande complesse consultando automaticamente i documenti pi rilevanti e generando risposte precise basate su di essi.&quot;

Per l'esempio concreto: &quot;Immaginate uno studio legale che deve analizzare centinaia di contratti per una due diligence in un'acquisizione aziendale. Tradizionalmente, questo richiederebbe settimane di lavoro da parte di un team di avvocati. Con sistemi basati su embeddings,  possibile estrarre automaticamente clausole specifiche, identificare potenziali rischi o anomalie, e organizzare i risultati in modo strutturato in una frazione del tempo. Uno studio ha riportato una riduzione del 70% del tempo necessario per questo tipo di analisi.&quot;

Domande stimolanti per l'audience:
- &quot;Quali altri settori con grandi volumi di documenti specialistici potrebbero beneficiare di applicazioni simili?&quot;
- &quot;Quali sfide etiche o di privacy vedete nell'automazione dell'analisi di documenti legali sensibili?&quot;

Concluderei con un'osservazione sul futuro: &quot;Questa  solo la punta dell'iceberg. Man mano che le tecniche di NLP avanzano, stiamo vedendo l'emergere di assistenti legali AI sempre pi sofisticati che non solo cercano informazioni ma aiutano nell'interpretazione e nell'applicazione del diritto. Tuttavia,  importante sottolineare che questi strumenti sono progettati per potenziare il lavoro dei professionisti legali, non per sostituirli. Il giudizio umano, l'esperienza e la responsabilit professionale rimangono centrali in questo settore.&quot; </p></div><div class="bespoke-marp-note" data-index="24" tabindex="0"><p># Speaker Notes: Miglioramento della ricerca semantica 

In questa slide esploro un'applicazione dei word embeddings che tutti noi utilizziamo quotidianamente, spesso senza rendercene conto: la ricerca semantica. 

Inizierei con il problema tradizionale: &quot;La ricerca testuale classica, basata su corrispondenza esatta delle parole o su tecniche come TF-IDF, presenta un limite fondamentale: non comprende il significato delle parole, ma solo la loro forma. Se cerco 'auto economica', un sistema tradizionale non trover documenti che parlano di 'vettura a basso costo' a meno che non contengano esattamente le parole che ho usato.&quot;

Spiegherei poi il cambiamento di paradigma: &quot;I word embeddings hanno rivoluzionato questo scenario permettendo la ricerca semantica, dove il sistema comprende il significato della query, non solo le parole esatte. Come funziona? Sia la query dell'utente che i documenti vengono convertiti in vettori nello stesso spazio semantico, e la rilevanza viene calcolata come similarit (tipicamente coseno) tra questi vettori.&quot;

Sui benefici principali, enfatizzerei:

1. **Comprensione del significato delle query**: &quot;Quando un utente cerca 'problemi cardiaci', il sistema comprende che documenti su 'malattie del cuore', 'aritmie' o 'infarto' sono semanticamente correlati, anche se non condividono alcuna parola con la query originale. Questo  possibile perch nello spazio degli embeddings, questi concetti sono vicini tra loro.&quot;

2. **Risultati pertinenti con sinonimi o termini correlati**: &quot;La ricerca semantica supera il problema dei sinonimi e delle varianti terminologiche. Se cerco 'laptop economico', otterr risultati pertinenti anche se i documenti usano termini come 'notebook conveniente' o 'computer portatile a basso costo'. Questo migliora drasticamente l'esperienza utente e la qualit dei risultati.&quot;

Sulle applicazioni concrete:

1. **E-commerce**: &quot;Nel commercio elettronico, questo  particolarmente potente. Gli utenti spesso cercano prodotti con descrizioni generiche o non tecniche ('scarpe comode per camminare molto' invece di termini specifici come 'scarpe ergonomiche con supporto plantare'). La ricerca semantica permette di trovare prodotti pertinenti anche quando le descrizioni ufficiali usano terminologia diversa. Amazon, ad esempio, ha implementato sistemi di ricerca semantica che hanno aumentato significativamente la conversione delle ricerche in acquisti.&quot;

2. **Editoria digitale**: &quot;Per siti di notizie, blog o piattaforme di contenuti, la ricerca semantica permette di trovare articoli concettualmente rilevanti. Se cerco 'impatto ambientale delle energie rinnovabili', un buon sistema di ricerca semantica trover articoli pertinenti anche se parlano specificamente di 'conseguenze ecologiche dei pannelli solari' o 'sostenibilit delle turbine eoliche', migliorando la scoperta di contenuti e l'engagement degli utenti.&quot;

Aggiungerei un esempio tecnico: &quot;Un approccio comune  calcolare l'embedding della query e poi trovare i documenti con gli embedding pi simili utilizzando tecniche di ricerca di nearest neighbors. Per gestire grandi archivi, si utilizzano strutture dati specializzate come indici HNSW o FAISS che permettono ricerche approssimate ma estremamente veloci.&quot;

Domande stimolanti per l'audience:
- &quot;Quali esperienze avete avuto con sistemi di ricerca che sembravano 'capire' ci che stavate cercando, anche se non avete usato le parole esatte?&quot;
- &quot;Come pensate che la ricerca semantica potrebbe evolvere nei prossimi anni con l'avanzamento dei modelli linguistici?&quot;

Concluderei con un'osservazione sul futuro: &quot;La ricerca semantica sta diventando lo standard de facto in molti settori, e si sta evolvendo verso sistemi sempre pi sofisticati che combinano embeddings con altre tecniche di NLP come l'entity recognition e la query expansion. Con l'avvento di modelli linguistici sempre pi potenti, stiamo assistendo a una convergenza tra ricerca e comprensione del linguaggio naturale, dove i sistemi non solo trovano informazioni pertinenti ma le sintetizzano e le presentano in modo sempre pi utile per l'utente finale.&quot; </p></div><div class="bespoke-marp-note" data-index="25" tabindex="0"><p># Speaker Notes: Categorizzazione avanzata dei documenti 

In questa slide esploro un'altra applicazione fondamentale dei word embeddings: la categorizzazione automatica dei documenti, un'attivit che ha enormi implicazioni pratiche in molti settori. 

Inizierei con il problema tradizionale: &quot;La classificazione automatica dei documenti  un'esigenza critica per molte organizzazioni che gestiscono grandi volumi di testi. Prima dell'avvento dei word embeddings, i sistemi di categorizzazione si basavano principalmente su approcci bag-of-words o TF-IDF, che presentavano limiti significativi: erano sensibili alla scelta esatta delle parole e faticavano a generalizzare su documenti che esprimevano concetti simili con terminologie diverse.&quot;

Spiegherei poi il miglioramento portato dagli embeddings: &quot;I word embeddings hanno trasformato radicalmente questo scenario. Rappresentando le parole in uno spazio semantico continuo, permettono ai classificatori di comprendere le relazioni semantiche tra i termini e di generalizzare meglio su documenti mai visti prima.&quot;

Sui benefici principali, enfatizzerei:

1. **Maggiore accuratezza nella classificazione**: &quot;I classificatori basati su embeddings mostrano tipicamente un incremento significativo dell'accuratezza rispetto ai metodi tradizionali. Questo perch catturano meglio il significato complessivo del documento, non solo la presenza di specifiche parole chiave. Ad esempio, uno studio nel settore sanitario ha mostrato un miglioramento del 15-20% nell'accuratezza della classificazione di documenti clinici utilizzando embeddings rispetto a metodi basati su bag-of-words.&quot;

2. **Categorizzazione corretta con terminologie diverse**: &quot;Questo  forse il vantaggio pi importante. Un sistema basato su embeddings pu riconoscere che documenti che usano terminologie diverse ma semanticamente equivalenti appartengono alla stessa categoria. Ad esempio, pu capire che 'malfunzionamento del dispositivo' e 'guasto dell'apparecchiatura' si riferiscono allo stesso tipo di problema, anche se non condividono alcuna parola.&quot;

Sulle applicazioni concrete:

1. **Settore assicurativo**: &quot;Le compagnie assicurative ricevono migliaia di richieste di risarcimento ogni giorno, che devono essere rapidamente indirizzate ai reparti appropriati. Utilizzando embeddings, i sistemi automatici possono categorizzare accuratamente queste richieste (danni auto, danni alla propriet, infortuni, ecc.) anche quando sono scritte in linguaggio non tecnico o ambiguo. Questo riduce drasticamente i tempi di elaborazione e migliora l'esperienza del cliente. Una grande compagnia assicurativa ha riportato una riduzione del 60% nel tempo di instradamento delle richieste dopo l'implementazione di un sistema basato su embeddings.&quot;

2. **Analisi social media**: &quot;Nel monitoraggio dei social media, la capacit di categorizzare automaticamente i post per temi, sentiment o intenti  cruciale. Gli embeddings permettono di identificare discussioni su temi specifici anche quando usano slang, abbreviazioni o espressioni colloquiali. Ad esempio, un brand pu monitorare le menzioni dei suoi prodotti anche quando gli utenti non li nominano esplicitamente ma usano soprannomi o descrizioni generiche. Questo permette analisi di mercato pi accurate e una risposta pi rapida a trend emergenti o crisi potenziali.&quot;

Aggiungerei un dettaglio tecnico: &quot;Un approccio comune  calcolare l'embedding di un intero documento (ad esempio, facendo la media degli embeddings delle parole che lo compongono) e poi utilizzare questi vettori come input per algoritmi di classificazione come SVM, Random Forest o reti neurali. Tecniche pi avanzate combinano embeddings con architetture neurali come CNN o RNN per catturare anche strutture sequenziali nel testo.&quot;

Domande stimolanti per l'audience:
- &quot;Quali processi di categorizzazione manuale nella vostra organizzazione potrebbero beneficiare maggiormente dell'automazione basata su embeddings?&quot;
- &quot;Come potrebbe cambiare il workflow dei knowledge workers se i documenti venissero pre-categorizzati automaticamente con alta accuratezza?&quot;

Concluderei con un'osservazione sul futuro: &quot;La categorizzazione avanzata dei documenti sta evolvendo rapidamente con l'integrazione di modelli linguistici sempre pi sofisticati. Stiamo assistendo a sistemi che non solo classificano i documenti in categorie predefinite, ma possono anche scoprire autonomamente nuove categorie emergenti e adattarsi a domini in evoluzione. Questo apre la strada a sistemi di gestione della conoscenza molto pi dinamici e adattivi.&quot; </p></div><div class="bespoke-marp-note" data-index="30" tabindex="0"><p># Speaker Notes: Da word embeddings a sentence embeddings 

In questa slide affronto un passaggio cruciale nell'evoluzione delle rappresentazioni vettoriali: come passare dalle singole parole a frasi o interi documenti. 

Inizierei con il problema di base: &quot;Finora abbiamo visto come rappresentare singole parole come vettori densi in uno spazio semantico. Ma nella maggior parte delle applicazioni reali, abbiamo bisogno di rappresentare unit di testo pi grandi: frasi, paragrafi o interi documenti. Come possiamo farlo mantenendo le propriet semantiche che rendono cos utili i word embeddings?&quot;

Spiegherei poi gli approcci semplici: &quot;Il metodo pi intuitivo  calcolare la media o la somma dei word embeddings delle parole che compongono la frase. Ad esempio, per rappresentare la frase 'Il gatto dorme sul divano', potremmo semplicemente calcolare la media dei vettori di 'il', 'gatto', 'dorme', 'sul' e 'divano'. Questo approccio  sorprendentemente efficace per molte applicazioni di base e ha il vantaggio della semplicit. Possiamo anche introdurre pesi diversi per parole diverse, ad esempio dando meno importanza a parole funzionali come articoli e preposizioni.&quot;

Passerei poi agli approcci pi sofisticati:

1. **Smooth Inverse Frequency (SIF)**: &quot;Questo metodo, proposto da ricercatori di Princeton,  un'evoluzione intelligente della media pesata. L'idea chiave  che parole molto frequenti (come 'il', 'di', 'e') tendono ad essere meno informative sul significato della frase. SIF assegna pesi inversamente proporzionali alla frequenza delle parole: pi una parola  comune nel corpus, meno peso avr nel calcolo della media. Inoltre, SIF applica una fase di 'rimozione della componente comune' che migliora ulteriormente la qualit degli embeddings. Nonostante la sua semplicit, SIF ha mostrato prestazioni competitive con metodi molto pi complessi.&quot;

2. **Doc2Vec**: &quot;Sviluppato dagli stessi creatori di Word2Vec, Doc2Vec (o Paragraph Vector) estende l'idea originale per apprendere direttamente rappresentazioni di documenti. Oltre a predire parole dal loro contesto o viceversa, Doc2Vec introduce un ID di documento che viene trattato come un token aggiuntivo. Durante l'addestramento, il modello impara simultaneamente embeddings per parole e documenti. Il vantaggio principale  che cattura l'ordine e la semantica specifica del documento, non solo un aggregato delle sue parole.&quot;

3. **Universal Sentence Encoder (USE)**: &quot;Sviluppato da Google, USE  un modello pre-addestrato specificamente progettato per generare embeddings di frasi di alta qualit. Utilizza un'architettura pi complessa basata su transformer o deep averaging network, ed  stato addestrato su una variet di compiti per ottimizzare la similarit semantica. USE  particolarmente efficace per applicazioni come la ricerca semantica, il clustering di frasi e la classificazione di testi brevi.&quot;

Aggiungerei un'osservazione importante: &quot;Un limite fondamentale degli approcci basati su media  che perdono completamente l'ordine delle parole. Frasi come 'Il gatto insegue il topo' e 'Il topo insegue il gatto' produrrebbero esattamente lo stesso embedding. Modelli pi avanzati come USE o le moderne architetture transformer cercano di preservare queste informazioni strutturali.&quot;

Domande stimolanti per l'audience:
- &quot;Quali informazioni pensate vadano inevitabilmente perse quando aggreghiamo word embeddings in sentence embeddings?&quot;
- &quot;In quali applicazioni la perdita dell'ordine delle parole potrebbe essere particolarmente problematica?&quot;

Concluderei con uno sguardo al futuro: &quot;I sentence embeddings rappresentano un ponte tra i word embeddings tradizionali e i moderni modelli linguistici contestuali come BERT o GPT. Mentre i primi modelli di sentence embeddings erano semplici aggregazioni di word embeddings, i modelli pi recenti utilizzano architetture neurali sofisticate che catturano meglio le dipendenze contestuali tra le parole. Questa evoluzione continua con modelli sempre pi potenti che generano rappresentazioni sempre pi ricche e nuanced del linguaggio naturale.&quot; </p></div><div class="bespoke-marp-note" data-index="32" tabindex="0"><p># Speaker Notes: Modelli avanzati per sentence embeddings 

In questa slide entro nel territorio dei modelli pi all'avanguardia per la generazione di sentence embeddings, che rappresentano un salto qualitativo significativo rispetto agli approcci che abbiamo visto finora. 

Inizierei con il contesto: &quot;L'avvento dell'architettura Transformer nel 2017 ha rivoluzionato l'NLP, e questa rivoluzione ha toccato anche il campo degli embeddings. I modelli basati su Transformer come BERT hanno introdotto una caratteristica fondamentale: la contestualizzazione. A differenza dei word embeddings tradizionali, dove ogni parola ha sempre lo stesso vettore indipendentemente dal contesto, nei modelli Transformer la rappresentazione di una parola dipende dalle altre parole che la circondano.&quot;

Spiegherei poi i modelli specifici:

1. **BERT Sentence Embeddings**: &quot;BERT  stato addestrato per comprendere il linguaggio attraverso due compiti: predire parole mascherate e determinare se due frasi sono consecutive. Per generare un embedding di frase da BERT, ci sono principalmente due approcci: utilizzare la rappresentazione del token speciale [CLS] (Classification) che viene aggiunto all'inizio di ogni sequenza, oppure calcolare la media dei vettori di tutti i token. Il token [CLS]  particolarmente interessante perch BERT  stato addestrato per condensare in esso informazioni rilevanti per la classificazione dell'intera sequenza. Tuttavia, BERT 'vanilla' non  stato ottimizzato specificamente per generare embeddings di frasi di alta qualit.&quot;

2. **Sentence-BERT (SBERT)**: &quot;Sviluppato nel 2019, SBERT affronta direttamente questa limitazione.  una modificazione di BERT specificamente ottimizzata per produrre embeddings di frasi semanticamente significativi. SBERT utilizza una struttura siamese o triplet network e viene addestrato su coppie o triplette di frasi con vari gradi di similarit. L'obiettivo  che frasi semanticamente simili abbiano embeddings vicini nello spazio vettoriale. SBERT ha mostrato miglioramenti drammatici nelle prestazioni per compiti come la ricerca semantica o il clustering di frasi, ed  anche molto pi veloce di BERT per questi compiti specifici.&quot;

3. **SimCSE**: &quot;Ancora pi recente (2021), SimCSE utilizza tecniche di apprendimento contrastivo per migliorare ulteriormente la qualit degli embeddings. L'idea chiave  creare coppie positive passando la stessa frase attraverso il modello due volte con dropout diversi (creando cos due viste leggermente diverse della stessa frase), mentre le coppie negative sono semplicemente altre frasi del batch. Questo approccio elegante non richiede dati etichettati e ha stabilito nuovi state-of-the-art in molti benchmark di similarit semantica.&quot;

Sull'efficacia di questi modelli: &quot;La differenza di qualit tra questi modelli avanzati e gli approcci pi semplici come la media dei word embeddings  sostanziale. Ad esempio, in benchmark standard come STS (Semantic Textual Similarity), SBERT e SimCSE raggiungono correlazioni con il giudizio umano superiori all'80%, mentre approcci basati su media di word embeddings raramente superano il 60-65%. Questa differenza si traduce in applicazioni pratiche molto pi accurate e utili.&quot;

Aggiungerei un dettaglio tecnico importante: &quot;Un aspetto interessante  che questi modelli, nonostante la loro sofisticazione, producono comunque vettori di dimensione fissa (tipicamente 768 o 1024 dimensioni) che possono essere utilizzati con gli stessi algoritmi e le stesse tecniche che abbiamo visto per i word embeddings pi semplici. La differenza sta nella qualit e nella ricchezza semantica di questi vettori.&quot;

Domande stimolanti per l'audience:
- &quot;Quali applicazioni potrebbero beneficiare maggiormente di questa capacit migliorata di catturare il significato complessivo delle frasi?&quot;
- &quot;Considerando il costo computazionale maggiore di questi modelli, in quali scenari potrebbe essere preferibile utilizzare approcci pi semplici?&quot;

Concluderei con uno sguardo al futuro: &quot;Questi modelli rappresentano lo stato dell'arte attuale, ma il campo  in rapida evoluzione. Stiamo vedendo l'emergere di modelli ancora pi potenti che combinano diverse tecniche di apprendimento e architetture ibride. La frontiera della ricerca si sta spostando verso modelli multimodali che possono generare embeddings coerenti tra testo, immagini e altri tipi di dati, aprendo possibilit ancora pi ampie per applicazioni che integrano diverse modalit di informazione.&quot; </p></div><div class="bespoke-marp-note" data-index="35" tabindex="0"><p># Speaker Notes: Sfide e limitazioni dei word embeddings - Polisemia e ambiguit 

In questa slide inizio ad affrontare le limitazioni fondamentali dei word embeddings tradizionali, partendo da uno dei problemi pi significativi: la polisemia. 

Inizierei con una definizione chiara: &quot;Dopo aver esplorato i numerosi vantaggi e applicazioni dei word embeddings,  importante comprendere anche i loro limiti intrinseci. Il primo e forse pi evidente  la gestione della polisemia, ovvero la capacit di una parola di avere significati diversi in contesti diversi. Questo  un fenomeno estremamente comune in tutte le lingue naturali.&quot;

Spiegherei il problema tecnico: &quot;I word embeddings tradizionali come Word2Vec, GloVe o FastText assegnano un singolo vettore a ciascuna parola del vocabolario. Questo vettore  essenzialmente una media statistica di tutti i contesti in cui quella parola appare nel corpus di addestramento. Il problema  evidente: se una parola ha significati molto diversi tra loro, questa 'media' non rappresenter adeguatamente nessuno dei significati specifici.&quot;

Userei l'esempio nella slide, elaborandolo: &quot;Prendiamo la parola 'calcio' in italiano, un esempio perfetto di polisemia. Pu riferirsi allo sport del calcio, all'elemento chimico della tavola periodica, o all'azione fisica di colpire qualcosa con il piede. Questi significati sono completamente diversi tra loro, eppure nei word embeddings tradizionali, 'calcio' avr un unico vettore che cerca di bilanciare tutti questi usi. Il risultato  una rappresentazione che non  ottimale per nessuno dei significati specifici.&quot;

Sull'impatto pratico, enfatizzerei: &quot;Questa limitazione ha conseguenze concrete in molte applicazioni. Nella traduzione automatica, ad esempio, la parola 'calcio' dovrebbe essere tradotta in modi completamente diversi in inglese a seconda del contesto: 'soccer' per lo sport, 'calcium' per l'elemento chimico, 'kick' per l'azione. Un sistema che utilizza un singolo embedding per 'calcio' avr difficolt a scegliere la traduzione corretta. Similmente, in sistemi di ricerca o raccomandazione, questa ambiguit pu portare a risultati irrilevanti o confusi.&quot;

Aggiungerei un esempio visivo: &quot;Possiamo immaginare questo problema visualizzando lo spazio vettoriale. L'embedding di una parola polisemica come 'calcio' finir per essere posizionato in un punto intermedio tra i cluster di parole relative allo sport, alla chimica e alle azioni fisiche. Questo lo rende meno utile per inferenze semantiche precise.&quot;

Domande stimolanti per l'audience:
- &quot;Quali altre parole polisemiche in italiano potrebbero creare problemi significativi per i sistemi NLP?&quot;
- &quot;Come pensate che questa limitazione possa influenzare l'accuratezza di sistemi come chatbot o assistenti virtuali?&quot;

Concluderei con un'anticipazione: &quot;Questa limitazione fondamentale dei word embeddings tradizionali  stata una delle principali motivazioni dietro lo sviluppo di modelli contestuali come BERT, che vedremo pi avanti. Questi modelli pi avanzati generano rappresentazioni diverse per la stessa parola in contesti diversi, affrontando direttamente il problema della polisemia.  un esempio perfetto di come le limitazioni di un approccio guidino l'innovazione verso soluzioni pi sofisticate.&quot; </p></div><div class="bespoke-marp-note" data-index="36" tabindex="0"><p># Speaker Notes: Dipendenza dalla qualit e quantit dei dati 

In questa slide continuo l'analisi delle limitazioni dei word embeddings, concentrandomi su un aspetto fondamentale: la loro dipendenza critica dai dati di addestramento. 

Inizierei con un principio fondamentale: &quot;Gli embeddings sono essenzialmente una distillazione statistica dei pattern presenti nei dati di addestramento. Come recita il famoso detto nell'informatica: 'garbage in, garbage out' - se i dati di input sono di bassa qualit o non rappresentativi, anche gli embeddings risultanti saranno problematici. Questo crea una dipendenza diretta tra la qualit degli embeddings e la qualit e quantit dei dati utilizzati per addestrarli.&quot;

Spiegherei il problema dei domini specialistici: &quot;Gli embeddings pi utilizzati, come quelli di Word2Vec o GloVe, sono tipicamente addestrati su corpora generici come Wikipedia o Common Crawl. Questi funzionano bene per linguaggio quotidiano, ma possono fallire completamente quando si tratta di terminologia specialistica. Ad esempio, in ambito medico, termini come 'ablazione' o 'comorbidit' potrebbero essere assenti o mal rappresentati in embeddings generici, rendendo questi modelli poco utili per applicazioni in quel dominio specifico.&quot;

Sulle problematiche specifiche, enfatizzerei:

1. **Termini specialistici o acronimi mal rappresentati**: &quot;In domini come quello legale, medico, finanziario o tecnico, gran parte della terminologia chiave potrebbe essere rara o assente nei corpora generici. Gli acronimi sono particolarmente problematici: 'NLP' potrebbe riferirsi a 'Natural Language Processing' in informatica, ma a 'Neuro-Linguistic Programming' in psicologia. Senza dati di addestramento specifici per dominio, queste distinzioni vengono perse.&quot;

2. **Lingue con risorse limitate**: &quot;Esiste un'enorme disparit nella disponibilit di dati tra lingue diverse. Mentre per l'inglese abbiamo terabyte di testi disponibili, per lingue meno rappresentate online come il maltese, il basco o molte lingue africane, i dati disponibili sono ordini di grandezza inferiori. Questo si traduce direttamente in embeddings di qualit inferiore per queste lingue, creando un divario tecnologico che pu amplificare disuguaglianze esistenti.&quot;

Aggiungerei una considerazione pratica: &quot;Per mitigare questi problemi, una strategia comune  il fine-tuning: si parte da embeddings pre-addestrati su corpora generici e li si affina su dati specifici del dominio di interesse. Questo approccio ibrido permette di sfruttare la conoscenza generale acquisita dai grandi corpora, adattandola poi alle specificit del dominio target.&quot;

Domande stimolanti per l'audience:
- &quot;In quali domini specialistici pensate che gli embeddings generici potrebbero fallire pi drammaticamente?&quot;
- &quot;Come potremmo affrontare il problema delle lingue con risorse limitate in modo pi equo ed efficace?&quot;</p></div><div class="bespoke-marp-note" data-index="37" tabindex="0"><p># Speaker Notes: Mancanza di comprensione profonda 

In questa slide affronto forse la limitazione pi profonda dei word embeddings: la loro incapacit di catturare una vera comprensione semantica del linguaggio. 

Inizierei con una distinzione fondamentale: &quot; importante riconoscere che, nonostante la loro utilit, i word embeddings catturano principalmente associazioni statistiche tra parole, non una vera 'comprensione' del loro significato nel senso umano del termine. Riconoscono pattern di co-occorrenza, ma non hanno accesso a concetti astratti, relazioni logiche complesse o conoscenza del mondo reale.&quot;

Spiegherei il concetto con l'esempio nella slide: &quot;Prendiamo l'esempio di 'Parigi' e 'Francia'. In uno spazio di embedding tipico, questi termini saranno vicini tra loro, indicando una forte relazione semantica. Ma questa vicinanza non codifica la natura specifica della relazione - che Parigi  la capitale della Francia. Allo stesso modo, gli embeddings potrebbero mostrare che 'cane' e 'abbaiare' sono correlati, ma non codificano esplicitamente che abbaiare  il suono prodotto dai cani, non il contrario.&quot;

Approfondirei con altri esempi: &quot;Gli embeddings non catturano relazioni logiche come causalit, implicazione o esclusione. Non 'sanno' che se piove, il terreno  bagnato, o che se qualcuno  scapolo, non pu essere sposato. Non hanno un modello del mondo fisico che permetta loro di comprendere che gli oggetti cadono verso il basso o che gli esseri umani hanno bisogno di ossigeno per sopravvivere. Queste sono tutte conoscenze che noi umani diamo per scontate quando interpretiamo il linguaggio.&quot;

Sulle implicazioni pratiche: &quot;Questa limitazione diventa evidente in applicazioni che richiedono ragionamento o inferenza. Ad esempio, un sistema di risposta a domande basato solo su embeddings potrebbe riconoscere che una domanda su Parigi  correlata a informazioni sulla Francia, ma non sarebbe in grado di rispondere a domande che richiedono comprensione delle relazioni specifiche, come 'Qual  la capitale della Francia?' senza aver visto esplicitamente questa informazione nei dati di addestramento.&quot;

Aggiungerei una prospettiva storica: &quot;Questa limitazione  stata una delle principali motivazioni dietro lo sviluppo di approcci pi avanzati come i modelli linguistici di grandi dimensioni (LLM), che combinano rappresentazioni vettoriali con architetture pi complesse e enormi quantit di dati per approssimare meglio una comprensione pi profonda del linguaggio e della conoscenza del mondo.&quot;

Domande stimolanti per l'audience:
- &quot;Quali tipi di applicazioni NLP pensate siano pi limitate da questa mancanza di comprensione profonda?&quot;
- &quot;Credete che sia possibile sviluppare sistemi con vera comprensione semantica basandosi solo su pattern statistici nei dati, o  necessario un approccio fondamentalmente diverso?&quot;

Concluderei con una riflessione filosofica: &quot;Questa limitazione tocca questioni profonde in filosofia del linguaggio e intelligenza artificiale. Quanto della nostra comprensione linguistica  basata su associazioni statistiche e quanto invece richiede un'interazione con il mondo reale e un'architettura cognitiva pi complessa? I progressi recenti nei modelli linguistici stanno sfumando questi confini, ma rimane una domanda aperta se un sistema puramente basato su testo possa mai raggiungere una comprensione veramente umana del linguaggio.&quot; </p></div><div class="bespoke-marp-note" data-index="38" tabindex="0"><p># Speaker Notes: Evoluzione verso embeddings contestuali 

In questa slide concludo la discussione sulle limitazioni dei word embeddings tradizionali presentando la loro naturale evoluzione: gli embeddings contestuali, che rappresentano un salto paradigmatico nell'NLP. 

Inizierei con il collegamento alle limitazioni precedenti: &quot;Abbiamo visto come i word embeddings tradizionali, nonostante la loro utilit, presentino limitazioni significative: non gestiscono la polisemia, dipendono fortemente dalla qualit dei dati e mancano di una comprensione profonda. La domanda naturale : come possiamo superare queste limitazioni? La risposta  arrivata con l'avvento degli embeddings contestuali.&quot;

Spiegherei il concetto fondamentale: &quot;A differenza dei word embeddings tradizionali, dove ogni parola ha un unico vettore fisso indipendentemente dal contesto, negli embeddings contestuali la rappresentazione di una parola dipende specificamente dal contesto in cui appare. In altre parole, la stessa parola in frasi diverse avr rappresentazioni vettoriali diverse. Questo approccio riflette molto meglio il funzionamento del linguaggio naturale, dove il significato delle parole  intrinsecamente legato al loro contesto.&quot;

Sui modelli specifici, darei un'overview storica: &quot;Questa evoluzione  stata guidata da modelli come ELMo (2018), seguito rapidamente da BERT e GPT. ELMo (Embeddings from Language Models)  stato il pioniere, utilizzando reti neurali bidirezionali per generare rappresentazioni contestuali. BERT ha poi rivoluzionato il campo con la sua architettura Transformer bidirezionale, mentre GPT ha adottato un approccio auto-regressivo. Tutti questi modelli condividono l'idea fondamentale di generare embeddings dinamici che cambiano in base al contesto specifico.&quot;

Sull'esempio nella slide: &quot;Prendiamo l'esempio della parola 'calcio' nelle due frasi: 'Io gioco a calcio' e 'Giocando mi hanno dato un calcio'. In un modello come BERT, la rappresentazione vettoriale di 'calcio' sar completamente diversa nelle due frasi. Nella prima, sar pi vicina a concetti come 'sport', 'pallone', 'squadra', mentre nella seconda sar pi vicina a concetti come 'colpo', 'piede', 'dolore'. Questa capacit di disambiguazione contestuale risolve direttamente uno dei problemi principali dei word embeddings tradizionali.&quot;

Aggiungerei un dettaglio tecnico importante: &quot; interessante notare che questi modelli non solo generano embeddings contestuali, ma lo fanno a pi livelli di profondit. I livelli inferiori tendono a catturare informazioni pi sintattiche e morfologiche, mentre i livelli superiori catturano informazioni pi semantiche e dipendenti dal contesto. Questo ha portato a pratiche sofisticate di estrazione e combinazione di rappresentazioni da diversi livelli per compiti specifici.&quot;

Domande stimolanti per l'audience:
- &quot;Quali applicazioni NLP pensate possano beneficiare maggiormente di questa capacit di distinguere i significati in base al contesto?&quot;
- &quot;Come potrebbe questa evoluzione influenzare il modo in cui interagiamo con i sistemi di intelligenza artificiale nel quotidiano?&quot;

Concluderei con uno sguardo al futuro: &quot;Gli embeddings contestuali hanno rappresentato un punto di svolta nell'NLP, aprendo la strada ai moderni Large Language Models come GPT-4 e Claude. Questi modelli portano l'idea degli embeddings contestuali a un livello completamente nuovo, con architetture enormi addestrate su quantit di dati senza precedenti. Nel prossimo modulo, esploreremo pi a fondo questi modelli avanzati e come hanno trasformato radicalmente il panorama dell'NLP e dell'intelligenza artificiale in generale.&quot; </p></div><div class="bespoke-marp-note" data-index="41" tabindex="0"><p># Speaker Notes: Embeddings pre-addestrati vs addestramento custom 

In questa slide affronto una decisione pratica fondamentale che ogni professionista NLP deve affrontare: utilizzare embeddings pre-addestrati o addestrare modelli custom per la propria applicazione specifica. 

Inizierei con un'introduzione al concetto: &quot;Una delle prime decisioni da prendere quando si implementa un sistema basato su embeddings  se utilizzare modelli pre-addestrati, disponibili pubblicamente, o investire risorse nell'addestramento di modelli personalizzati. Questa decisione ha implicazioni significative in termini di tempo di sviluppo, costi, performance e manutenzione.&quot;

Sui modelli pre-addestrati, darei dettagli specifici:

1. **Word2Vec su Google News**: &quot;Questi embeddings, rilasciati da Google, sono stati addestrati su circa 100 miliardi di parole dal corpus Google News. Contengono vettori per 3 milioni di parole ed entit, con dimensionalit 300. Sono particolarmente buoni per l'inglese generale e per testi giornalistici, ma possono essere datati (risalgono al 2013) e mancano di terminologia pi recente.&quot;

2. **GloVe su Wikipedia e Gigaword**: &quot;Sviluppati da Stanford, questi embeddings sono disponibili in diverse dimensionalit (50d, 100d, 200d, 300d) e addestrati su combinazioni di Wikipedia, Gigaword e Common Crawl. La versione pi grande contiene 2.2 milioni di termini. Sono particolarmente apprezzati per la loro capacit di catturare relazioni semantiche e analogie.&quot;

3. **FastText su Wikipedia, Common Crawl**: &quot;Sviluppati da Facebook, questi embeddings hanno il vantaggio unico di gestire parole fuori vocabolario grazie al loro approccio basato su n-grammi di caratteri. Sono disponibili per 157 lingue, rendendoli una scelta eccellente per applicazioni multilingue. La versione inglese contiene 2 milioni di parole.&quot;

Aggiungerei un'osservazione importante: &quot;Oltre a questi, esistono numerosi altri embeddings pre-addestrati, inclusi quelli basati su modelli contestuali come BERT, RoBERTa o GPT. Hugging Face's Model Hub, ad esempio, offre centinaia di modelli pre-addestrati per diverse lingue e domini.&quot;

Sui vantaggi dell'addestramento custom, approfondirei ciascun punto:

1. **Terminologia di dominio molto specifica**: &quot;Se lavorate in un settore con gergo specialistico, acronimi o terminologia tecnica, gli embeddings generici potrebbero non coprire adeguatamente il vostro vocabolario. Ad esempio, in ambito farmaceutico, nomi di farmaci, composti chimici o procedure mediche specifiche potrebbero essere assenti o mal rappresentati in modelli generici. In questi casi, addestrare su un corpus di dominio pu migliorare drasticamente le performance.&quot;

2. **Grandi quantit di dati proprietari**: &quot;Se la vostra organizzazione possiede grandi volumi di testi proprietari (come email interne, documenti tecnici, report, conversazioni con clienti), questi rappresentano una risorsa preziosa che potrebbe contenere pattern linguistici unici rilevanti per il vostro business. Addestrare embeddings su questi dati pu catturare queste specificit, offrendo un vantaggio competitivo.&quot;

3. **Necessit di ottimizzazione per compiti specifici**: &quot;Alcuni compiti beneficiano particolarmente di embeddings ottimizzati. Ad esempio, per sistemi di raccomandazione, potreste voler addestrare embeddings che massimizzano la similarit tra prodotti spesso acquistati insieme. Per sentiment analysis in un dominio specifico, potreste voler enfatizzare la separazione tra termini positivi e negativi nel vostro contesto particolare.&quot;

Aggiungerei considerazioni pratiche: &quot;L'addestramento custom richiede competenze tecniche, risorse computazionali e, soprattutto, dati sufficienti. Una regola empirica suggerisce che servono almeno centinaia di migliaia di esempi per ottenere embeddings di qualit. Un approccio ibrido spesso efficace  il fine-tuning: partire da embeddings pre-addestrati e affinarli sul proprio corpus specifico, combinando cos conoscenza generale e specifica del dominio.&quot;

Domande stimolanti per l'audience:
- &quot;Quali caratteristiche specifiche del vostro dominio potrebbero non essere ben rappresentate in embeddings generici?&quot;
- &quot;Come bilancereste il trade-off tra tempo di sviluppo (pi rapido con modelli pre-addestrati) e performance potenzialmente migliori (con addestramento custom)?&quot;

Concluderei con un consiglio pragmatico: &quot;Un approccio pragmatico  iniziare con embeddings pre-addestrati per un prototipo rapido, misurare le performance, identificare le limitazioni specifiche e solo allora decidere se l'investimento in addestramento custom  giustificato dal miglioramento atteso. Spesso, la combinazione di modelli pre-addestrati con tecniche di adattamento leggero offre il miglior compromesso tra costi e benefici.&quot; </p></div><div class="bespoke-marp-note" data-index="42" tabindex="0"><p># Speaker Notes: Integrazione nelle pipeline NLP 

In questa slide affronto un aspetto molto pratico: come integrare concretamente gli embeddings nelle pipeline di elaborazione del linguaggio naturale. Questo  il punto in cui la teoria si trasforma in implementazioni reali. 

Inizierei con una panoramica: &quot;Una volta scelto il modello di embedding appropriato, il passo successivo  integrarlo efficacemente nel flusso di lavoro NLP. Esistono diverse modalit di integrazione, ciascuna adatta a scenari applicativi diversi. La scelta dipende dall'architettura complessiva del sistema, dal tipo di compito da svolgere e dalle risorse disponibili.&quot;

Sulle modalit di integrazione, approfondirei ciascun punto:

1. **Feature engineering**: &quot;Questo  l'approccio pi diretto e spesso il punto di partenza. Gli embeddings vengono utilizzati come features di input per algoritmi di machine learning tradizionali come SVM, Random Forest o Gradient Boosting. Ad esempio, per classificare documenti, potremmo calcolare l'embedding medio di tutte le parole nel documento e utilizzare questo vettore come input per un classificatore. Questo approccio  particolarmente utile quando si hanno vincoli computazionali o quando si desidera combinare embeddings con altre features strutturate. Un vantaggio  la semplicit e interpretabilit, ma si perde l'informazione sequenziale del testo.&quot;

2. **Layer di embedding in reti neurali**: &quot;Nelle architetture neurali, gli embeddings vengono tipicamente utilizzati come primo layer della rete. Una pratica comune  inizializzare questo layer con embeddings pre-addestrati e poi, a seconda del caso, congelarlo (freeze) o permettere un fine-tuning durante l'addestramento. Il congelamento  preferibile quando si hanno pochi dati di addestramento, per evitare overfitting, mentre il fine-tuning pu migliorare le performance quando si hanno dati sufficienti. Questo approccio  alla base di molte architetture avanzate come CNN o RNN per l'NLP, e permette alla rete di adattare gli embeddings al compito specifico.&quot;

3. **Calcolo di similarit**: &quot;Un'applicazione diretta degli embeddings  il calcolo di similarit tra parole, frasi o documenti, tipicamente utilizzando la similarit coseno. Questo  il fondamento di applicazioni come la ricerca semantica, i sistemi di raccomandazione basati su contenuto, o il clustering di documenti. Ad esempio, per implementare una funzionalit 'articoli simili' su un sito di notizie, potremmo calcolare l'embedding di ciascun articolo e trovare quelli con la maggiore similarit coseno. Questa modalit sfrutta direttamente la propriet degli embeddings di posizionare entit semanticamente simili vicine nello spazio vettoriale.&quot;

Aggiungerei un esempio concreto di pipeline completa: &quot;Una pipeline NLP tipica potrebbe combinare queste modalit. Ad esempio, in un sistema di assistenza clienti automatizzato, potremmo: (1) utilizzare embeddings e similarit coseno per trovare domande simili a quella dell'utente in un database di FAQ; (2) utilizzare un modello neurale con layer di embedding per classificare l'intento dell'utente; e (3) utilizzare embeddings come features per un modello di sentiment analysis che determina se il cliente  frustrato. Questa combinazione di approcci permette di affrontare diversi aspetti del problema.&quot;

Aggiungerei un dettaglio tecnico importante: &quot;Un aspetto pratico da considerare  la gestione di testi di lunghezza variabile. Quando si lavora con frasi o documenti,  necessario aggregare gli embeddings delle singole parole. Oltre alla semplice media, esistono approcci pi sofisticati come la media pesata (ad esempio con TF-IDF), l'uso di attention mechanisms, o l'addestramento di modelli specifici per sentence embeddings come abbiamo visto in precedenza.&quot;

Domande stimolanti per l'audience:
- &quot;Quali vantaggi e svantaggi vedete nell'utilizzare embeddings congelati vs permettere il fine-tuning in una rete neurale?&quot;
- &quot;Come potrebbe cambiare la vostra strategia di integrazione se state lavorando con testi molto lunghi come documenti legali o articoli scientifici?&quot;

Concluderei con un'osservazione sul futuro: &quot;Con l'evoluzione dei modelli linguistici, stiamo assistendo a un'integrazione sempre pi profonda degli embeddings nelle architetture NLP. I moderni transformer come BERT o GPT non solo utilizzano embeddings come input, ma generano rappresentazioni contestuali a pi livelli che possono essere estratte e utilizzate in modi diversi. Questa flessibilit sta portando a pipeline sempre pi sofisticate dove i confini tra le diverse modalit di integrazione diventano sempre pi sfumati.&quot; </p></div><div class="bespoke-marp-note" data-index="43" tabindex="0"><p># Speaker Notes: Tecniche di debiasing 

In questa slide affronto un tema cruciale sia dal punto di vista tecnico che etico: come mitigare i bias negli embeddings, un problema sempre pi rilevante nell'NLP responsabile. 

Inizierei con il contesto del problema: &quot;Gli embeddings, essendo addestrati su corpora di testo del mondo reale, tendono inevitabilmente ad assorbire e amplificare i bias e gli stereotipi presenti in questi dati. Ad esempio,  stato dimostrato che in molti modelli di embedding, 'uomo'  associato a 'programmatore' mentre 'donna' a 'casalinga', o che nomi tipicamente associati a persone di colore sono correlati a concetti pi negativi rispetto a nomi tipicamente associati a persone bianche. Questi bias possono propagarsi e amplificarsi nelle applicazioni downstream, portando a discriminazioni algoritmiche.&quot;

Spiegherei poi perch  importante affrontare questo problema: &quot;Mitigare questi bias non  solo una questione etica, ma anche pratica. Sistemi biased possono alienare utenti, violare normative sulla non-discriminazione, e portare a decisioni automatizzate problematiche in ambiti sensibili come assunzioni, prestiti o giustizia penale. Fortunatamente, sono state sviluppate diverse tecniche per affrontare questo problema.&quot;

Sulle tecniche specifiche, approfondirei:

1. **Hard debiasing**: &quot;Questo approccio, proposto inizialmente da Bolukbasi et al. nel 2016, interviene direttamente sullo spazio vettoriale degli embeddings gi addestrati. L'idea  identificare esplicitamente le 'direzioni di bias' nello spazio vettoriale (ad esempio, la direzione che va da 'uomo' a 'donna') e poi neutralizzare queste componenti per concetti che non dovrebbero essere gender-specific. Ad esempio, 'programmatore' o 'dottore' verrebbero proiettati in uno spazio neutrale rispetto al genere. Questo metodo  diretto ed efficace, ma richiede l'identificazione esplicita delle direzioni di bias, che potrebbero essere molteplici e non sempre evidenti.&quot;

2. **Soft debiasing**: &quot;A differenza dell'hard debiasing che interviene post-addestramento, il soft debiasing agisce durante la fase di addestramento degli embeddings. Viene implementato aggiungendo termini di regolarizzazione alla funzione obiettivo che penalizzano l'emergere di associazioni biased. Ad esempio, si pu aggiungere un termine che scoraggia la correlazione tra professioni e genere. Questo approccio  pi integrato nel processo di apprendimento e pu catturare forme di bias pi sottili, ma richiede di riaddestrate il modello da zero.&quot;

3. **Augmentation dei dati**: &quot;Questo approccio affronta il problema alla radice: i dati di addestramento. L'idea  arricchire il corpus con esempi che contrastano esplicitamente gli stereotipi esistenti. Ad esempio, aggiungere testi che parlano di 'infermieri uomini' o 'ingegnere donna', o che associano nomi di diverse etnie a contesti positivi in modo bilanciato. Questo metodo ha il vantaggio di essere pi naturale e pu portare a miglioramenti pi sostanziali e duraturi, ma richiede un intervento significativo sui dati e potrebbe non essere sempre praticabile con corpora molto grandi.&quot;

Aggiungerei una considerazione importante: &quot; fondamentale notare che nessuna di queste tecniche  perfetta o risolutiva. I bias linguistici sono profondamente radicati e multidimensionali. Spesso, la mitigazione di un tipo di bias pu involontariamente rafforzarne un altro o compromettere altre propriet utili degli embeddings. Per questo, un approccio combinato e iterativo, con continuo monitoraggio e valutazione,  generalmente raccomandato.&quot;

Domande stimolanti per l'audience:
- &quot;Quali tipi di bias pensate siano pi difficili da identificare e mitigare negli embeddings?&quot;
- &quot;Come bilancereste la necessit di rimuovere bias dannosi con quella di preservare informazioni culturali e linguistiche legittime?&quot;

Concluderei con una riflessione pi ampia: &quot;Il debiasing degli embeddings si inserisce in un contesto pi ampio di AI etica e responsabile.  importante ricordare che gli embeddings riflettono i bias presenti nella societ e nei dati che produciamo. Mentre lavoriamo per migliorare i nostri modelli, dobbiamo anche riconoscere che la tecnologia da sola non pu risolvere problemi sociali profondi. Un approccio olistico richiede consapevolezza, diversit nei team di sviluppo, e un dialogo continuo con le comunit potenzialmente impattate dalle nostre tecnologie.&quot; </p></div><div class="bespoke-marp-note" data-index="44" tabindex="0"><p>word embeddings hanno rivoluzionato il campo del Natural Language Processing, fornendo rappresentazioni vettoriali dense e semanticamente significative che catturano relazioni linguistiche in modo sorprendentemente efficace. Dalla loro introduzione con Word2Vec nel 2013, hanno trasformato praticamente ogni aspetto dell'NLP, migliorando significativamente le prestazioni in compiti come la classificazione dei testi, l'analisi del sentiment, la ricerca semantica e molti altri.

In questo modulo, abbiamo esplorato il concetto di rappresentazione del testo, dalle tecniche tradizionali come Bag-of-Words e TF-IDF fino ai moderni word embeddings. Abbiamo approfondito i principi di funzionamento di Word2Vec, GloVe e FastText, e abbiamo esaminato come queste rappresentazioni possano essere visualizzate e interpretate. Abbiamo discusso numerose applicazioni pratiche in vari settori aziendali, evidenziando come i word embeddings stiano trasformando processi e creando valore in contesti diversi.

Abbiamo anche riconosciuto le limitazioni dei word embeddings tradizionali, in particolare riguardo alla polisemia, ai bias e alla mancanza di comprensione profonda. Queste limitazioni hanno spinto l'evoluzione verso modelli contestuali come BERT e GPT, che saranno esplorati nei moduli successivi.

La comprensione dei word embeddings fornisce una base essenziale per apprezzare i modelli pi avanzati che dominano l'NLP contemporaneo. Mentre i Large Language Models e i Transformer hanno portato le capacit NLP a nuovi livelli, i principi fondamentali della rappresentazione vettoriale del linguaggio introdotti dai word embeddings rimangono centrali nel funzionamento di questi sistemi pi sofisticati.

Nel prossimo modulo, esploreremo la classificazione del testo e l'analisi del sentiment, due applicazioni fondamentali che beneficiano significativamente dell'uso dei word embeddings e che hanno numerose applicazioni pratiche nel mondo aziendale.</p></div><script>/*!! License: https://unpkg.com/@marp-team/marp-cli@4.1.2/lib/bespoke.js.LICENSE.txt */
!function(){"use strict";function e(e){return e&&e.__esModule&&Object.prototype.hasOwnProperty.call(e,"default")?e.default:e}var t,n,r=(n||(n=1,t={from:function(e,t){var n,r=1===(e.parent||e).nodeType?e.parent||e:document.querySelector(e.parent||e),o=[].filter.call("string"==typeof e.slides?r.querySelectorAll(e.slides):e.slides||r.children,(function(e){return"SCRIPT"!==e.nodeName})),a={},i=function(e,t){return(t=t||{}).index=o.indexOf(e),t.slide=e,t},s=function(e,t){a[e]=(a[e]||[]).filter((function(e){return e!==t}))},c=function(e,t){return(a[e]||[]).reduce((function(e,n){return e&&!1!==n(t)}),!0)},l=function(e,t){o[e]&&(n&&c("deactivate",i(n,t)),n=o[e],c("activate",i(n,t)))},d=function(e,t){var r=o.indexOf(n)+e;c(e>0?"next":"prev",i(n,t))&&l(r,t)},u={off:s,on:function(e,t){return(a[e]||(a[e]=[])).push(t),s.bind(null,e,t)},fire:c,slide:function(e,t){if(!arguments.length)return o.indexOf(n);c("slide",i(o[e],t))&&l(e,t)},next:d.bind(null,1),prev:d.bind(null,-1),parent:r,slides:o,destroy:function(e){c("destroy",i(n,e)),a={}}};return(t||[]).forEach((function(e){e(u)})),n||l(0),u}}),t),o=e(r);const a=document.body,i=(...e)=>history.replaceState(...e),s="",c="presenter",l="next",d=["",c,l],u="bespoke-marp-",f=`data-${u}`,m=(e,{protocol:t,host:n,pathname:r,hash:o}=location)=>{const a=e.toString();return`${t}//${n}${r}${a?"?":""}${a}${o}`},g=()=>a.dataset.bespokeView,p=e=>new URLSearchParams(location.search).get(e),v=(e,t={})=>{const n={location,setter:i,...t},r=new URLSearchParams(n.location.search);for(const t of Object.keys(e)){const n=e[t];"string"==typeof n?r.set(t,n):r.delete(t)}try{n.setter({...window.history.state??{}},"",m(r,n.location))}catch(e){console.error(e)}},h=(()=>{const e="bespoke-marp";try{return localStorage.setItem(e,e),localStorage.removeItem(e),!0}catch{return!1}})(),y=e=>{try{return localStorage.getItem(e)}catch{return null}},b=(e,t)=>{try{return localStorage.setItem(e,t),!0}catch{return!1}},w=e=>{try{return localStorage.removeItem(e),!0}catch{return!1}},x=(e,t)=>{const n="aria-hidden";t?e.setAttribute(n,"true"):e.removeAttribute(n)},k=e=>{e.parent.classList.add(`${u}parent`),e.slides.forEach((e=>e.classList.add(`${u}slide`))),e.on("activate",(t=>{const n=`${u}active`,r=t.slide,o=r.classList,a=!o.contains(n);if(e.slides.forEach((e=>{e.classList.remove(n),x(e,!0)})),o.add(n),x(r,!1),a){const e=`${n}-ready`;o.add(e),document.body.clientHeight,o.remove(e)}}))},$=e=>{let t=0,n=0;Object.defineProperty(e,"fragments",{enumerable:!0,value:e.slides.map((e=>[null,...e.querySelectorAll("[data-marpit-fragment]")]))});const r=r=>void 0!==e.fragments[t][n+r],o=(r,o)=>{t=r,n=o,e.fragments.forEach(((e,t)=>{e.forEach(((e,n)=>{if(null==e)return;const a=t<r||t===r&&n<=o;e.setAttribute(`${f}fragment`,(a?"":"in")+"active");const i=`${f}current-fragment`;t===r&&n===o?e.setAttribute(i,"current"):e.removeAttribute(i)}))})),e.fragmentIndex=o;const a={slide:e.slides[r],index:r,fragments:e.fragments[r],fragmentIndex:o};e.fire("fragment",a)};e.on("next",(({fragment:a=!0})=>{if(a){if(r(1))return o(t,n+1),!1;const a=t+1;e.fragments[a]&&o(a,0)}else{const r=e.fragments[t].length;if(n+1<r)return o(t,r-1),!1;const a=e.fragments[t+1];a&&o(t+1,a.length-1)}})),e.on("prev",(({fragment:a=!0})=>{if(r(-1)&&a)return o(t,n-1),!1;const i=t-1;e.fragments[i]&&o(i,e.fragments[i].length-1)})),e.on("slide",(({index:t,fragment:n})=>{let r=0;if(void 0!==n){const o=e.fragments[t];if(o){const{length:e}=o;r=-1===n?e-1:Math.min(Math.max(n,0),e-1)}}o(t,r)})),o(0,0)},E=document,L=()=>!(!E.fullscreenEnabled&&!E.webkitFullscreenEnabled),S=()=>!(!E.fullscreenElement&&!E.webkitFullscreenElement),P=e=>{e.fullscreen=()=>{L()&&(async()=>{S()?(E.exitFullscreen||E.webkitExitFullscreen)?.call(E):((e=E.body)=>{(e.requestFullscreen||e.webkitRequestFullscreen)?.call(e)})()})()},document.addEventListener("keydown",(t=>{"f"!==t.key&&"F11"!==t.key||t.altKey||t.ctrlKey||t.metaKey||!L()||(e.fullscreen(),t.preventDefault())}))},_=`${u}inactive`,T=(e=2e3)=>({parent:t,fire:n})=>{const r=t.classList,o=e=>n(`marp-${e?"":"in"}active`);let a;const i=()=>{a&&clearTimeout(a),a=setTimeout((()=>{r.add(_),o()}),e),r.contains(_)&&(r.remove(_),o(!0))};for(const e of["mousedown","mousemove","touchend"])document.addEventListener(e,i);setTimeout(i,0)},I=["AUDIO","BUTTON","INPUT","SELECT","TEXTAREA","VIDEO"],M=e=>{e.parent.addEventListener("keydown",(e=>{if(!e.target)return;const t=e.target;(I.includes(t.nodeName)||"true"===t.contentEditable)&&e.stopPropagation()}))},O=e=>{window.addEventListener("load",(()=>{for(const t of e.slides){const e=t.querySelector("marp-auto-scaling, [data-auto-scaling], [data-marp-fitting]");t.setAttribute(`${f}load`,e?"":"hideable")}}))},A=({interval:e=250}={})=>t=>{document.addEventListener("keydown",(e=>{if(" "===e.key&&e.shiftKey)t.prev();else if("ArrowLeft"===e.key||"ArrowUp"===e.key||"PageUp"===e.key)t.prev({fragment:!e.shiftKey});else if(" "!==e.key||e.shiftKey)if("ArrowRight"===e.key||"ArrowDown"===e.key||"PageDown"===e.key)t.next({fragment:!e.shiftKey});else if("End"===e.key)t.slide(t.slides.length-1,{fragment:-1});else{if("Home"!==e.key)return;t.slide(0)}else t.next();e.preventDefault()}));let n,r,o=0;t.parent.addEventListener("wheel",(a=>{let i=!1;const s=(e,t)=>{e&&(i=i||((e,t)=>((e,t)=>{const n="X"===t?"Width":"Height";return e[`client${n}`]<e[`scroll${n}`]})(e,t)&&((e,t)=>{const{overflow:n}=e,r=e[`overflow${t}`];return"auto"===n||"scroll"===n||"auto"===r||"scroll"===r})(getComputedStyle(e),t))(e,t)),e?.parentElement&&s(e.parentElement,t)};if(0!==a.deltaX&&s(a.target,"X"),0!==a.deltaY&&s(a.target,"Y"),i)return;a.preventDefault();const c=Math.sqrt(a.deltaX**2+a.deltaY**2);if(void 0!==a.wheelDelta){if(void 0===a.webkitForce&&Math.abs(a.wheelDelta)<40)return;if(a.deltaMode===a.DOM_DELTA_PIXEL&&c<4)return}else if(a.deltaMode===a.DOM_DELTA_PIXEL&&c<12)return;r&&clearTimeout(r),r=setTimeout((()=>{n=0}),e);const l=Date.now()-o<e,d=c<=n;if(n=c,l||d)return;let u;(a.deltaX>0||a.deltaY>0)&&(u="next"),(a.deltaX<0||a.deltaY<0)&&(u="prev"),u&&(t[u](),o=Date.now())}))},C=(e=`.${u}osc`)=>{const t=document.querySelector(e);if(!t)return()=>{};const n=(e,n)=>{t.querySelectorAll(`[${f}osc=${JSON.stringify(e)}]`).forEach(n)};return L()||n("fullscreen",(e=>e.style.display="none")),h||n("presenter",(e=>{e.disabled=!0,e.title="Presenter view is disabled due to restricted localStorage."})),e=>{t.addEventListener("click",(t=>{if(t.target instanceof HTMLElement){const{bespokeMarpOsc:n}=t.target.dataset;n&&t.target.blur();const r={fragment:!t.shiftKey};"next"===n?e.next(r):"prev"===n?e.prev(r):"fullscreen"===n?e?.fullscreen():"presenter"===n&&e.openPresenterView()}})),e.parent.appendChild(t),e.on("activate",(({index:t})=>{n("page",(n=>n.textContent=`Page ${t+1} of ${e.slides.length}`))})),e.on("fragment",(({index:t,fragments:r,fragmentIndex:o})=>{n("prev",(e=>e.disabled=0===t&&0===o)),n("next",(n=>n.disabled=t===e.slides.length-1&&o===r.length-1))})),e.on("marp-active",(()=>x(t,!1))),e.on("marp-inactive",(()=>x(t,!0))),L()&&(e=>{for(const t of["","webkit"])E.addEventListener(t+"fullscreenchange",e)})((()=>n("fullscreen",(e=>e.classList.toggle("exit",L()&&S())))))}},D=e=>{window.addEventListener("message",(t=>{if(t.origin!==window.origin)return;const[n,r]=t.data.split(":");if("navigate"===n){const[t,n]=r.split(",");let o=Number.parseInt(t,10),a=Number.parseInt(n,10)+1;a>=e.fragments[o].length&&(o+=1,a=0),e.slide(o,{fragment:a})}}))};var N,B,q,K,j,F,V,U={exports:{}},X=(N||(N=1,U.exports=(B=["area","base","br","col","command","embed","hr","img","input","keygen","link","meta","param","source","track","wbr"],q=function(e){return String(e).replace(/[&<>"']/g,(function(e){return"&"+K[e]+";"}))},K={"&":"amp","<":"lt",">":"gt",'"':"quot","'":"apos"},j="dangerouslySetInnerHTML",F={className:"class",htmlFor:"for"},V={},function(e,t){var n=[],r="";t=t||{};for(var o=arguments.length;o-- >2;)n.push(arguments[o]);if("function"==typeof e)return t.children=n.reverse(),e(t);if(e){if(r+="<"+e,t)for(var a in t)!1!==t[a]&&null!=t[a]&&a!==j&&(r+=" "+(F[a]?F[a]:q(a))+'="'+q(t[a])+'"');r+=">"}if(-1===B.indexOf(e)){if(t[j])r+=t[j].__html;else for(;n.length;){var i=n.pop();if(i)if(i.pop)for(var s=i.length;s--;)n.push(i[s]);else r+=!0===V[i]?i:q(i)}r+=e?"</"+e+">":""}return V[r]=!0,r})),U.exports),H=e(X);const R=({children:e})=>H(null,null,...e),W=`${u}presenter-`,J={container:`${W}container`,dragbar:`${W}dragbar-container`,next:`${W}next`,nextContainer:`${W}next-container`,noteContainer:`${W}note-container`,noteWrapper:`${W}note-wrapper`,noteButtons:`${W}note-buttons`,infoContainer:`${W}info-container`,infoPage:`${W}info-page`,infoPageText:`${W}info-page-text`,infoPagePrev:`${W}info-page-prev`,infoPageNext:`${W}info-page-next`,noteButtonsBigger:`${W}note-bigger`,noteButtonsSmaller:`${W}note-smaller`,infoTime:`${W}info-time`,infoTimer:`${W}info-timer`},Y=e=>{const{title:t}=document;document.title="[Presenter view]"+(t?` - ${t}`:"");const n={},r=e=>(n[e]=n[e]||document.querySelector(`.${e}`),n[e]);document.body.appendChild((e=>{const t=document.createElement("div");return t.className=J.container,t.appendChild(e),t.insertAdjacentHTML("beforeend",H(R,null,H("div",{class:J.nextContainer},H("iframe",{class:J.next,src:"?view=next"})),H("div",{class:J.dragbar}),H("div",{class:J.noteContainer},H("div",{class:J.noteWrapper}),H("div",{class:J.noteButtons},H("button",{class:J.noteButtonsSmaller,tabindex:"-1",title:"Smaller notes font size"},"Smaller notes font size"),H("button",{class:J.noteButtonsBigger,tabindex:"-1",title:"Bigger notes font size"},"Bigger notes font size"))),H("div",{class:J.infoContainer},H("div",{class:J.infoPage},H("button",{class:J.infoPagePrev,tabindex:"-1",title:"Previous"},"Previous"),H("span",{class:J.infoPageText}),H("button",{class:J.infoPageNext,tabindex:"-1",title:"Next"},"Next")),H("time",{class:J.infoTime,title:"Current time"}),H("time",{class:J.infoTimer,title:"Timer"})))),t})(e.parent)),(e=>{let t=!1;r(J.dragbar).addEventListener("mousedown",(()=>{t=!0,r(J.dragbar).classList.add("active")})),window.addEventListener("mouseup",(()=>{t=!1,r(J.dragbar).classList.remove("active")})),window.addEventListener("mousemove",(e=>{if(!t)return;const n=e.clientX/document.documentElement.clientWidth*100;r(J.container).style.setProperty("--bespoke-marp-presenter-split-ratio",`${Math.max(0,Math.min(100,n))}%`)})),r(J.nextContainer).addEventListener("click",(()=>e.next()));const n=r(J.next),o=(a=n,(e,t)=>a.contentWindow?.postMessage(`navigate:${e},${t}`,"null"===window.origin?"*":window.origin));var a;n.addEventListener("load",(()=>{r(J.nextContainer).classList.add("active"),o(e.slide(),e.fragmentIndex),e.on("fragment",(({index:e,fragmentIndex:t})=>o(e,t)))}));const i=document.querySelectorAll(".bespoke-marp-note");i.forEach((e=>{e.addEventListener("keydown",(e=>e.stopPropagation())),r(J.noteWrapper).appendChild(e)})),e.on("activate",(()=>i.forEach((t=>t.classList.toggle("active",t.dataset.index==e.slide())))));let s=0;const c=e=>{s=Math.max(-5,s+e),r(J.noteContainer).style.setProperty("--bespoke-marp-note-font-scale",(1.2**s).toFixed(4))},l=()=>c(1),d=()=>c(-1),u=r(J.noteButtonsBigger),f=r(J.noteButtonsSmaller);u.addEventListener("click",(()=>{u.blur(),l()})),f.addEventListener("click",(()=>{f.blur(),d()})),document.addEventListener("keydown",(e=>{"+"===e.key&&l(),"-"===e.key&&d()}),!0),e.on("activate",(({index:t})=>{r(J.infoPageText).textContent=`${t+1} / ${e.slides.length}`}));const m=r(J.infoPagePrev),g=r(J.infoPageNext);m.addEventListener("click",(t=>{m.blur(),e.prev({fragment:!t.shiftKey})})),g.addEventListener("click",(t=>{g.blur(),e.next({fragment:!t.shiftKey})})),e.on("fragment",(({index:t,fragments:n,fragmentIndex:r})=>{m.disabled=0===t&&0===r,g.disabled=t===e.slides.length-1&&r===n.length-1}));let p=new Date;const v=()=>{const e=new Date,t=e=>`${Math.floor(e)}`.padStart(2,"0"),n=e.getTime()-p.getTime(),o=t(n/1e3%60),a=t(n/1e3/60%60),i=t(n/36e5%24);r(J.infoTime).textContent=e.toLocaleTimeString(),r(J.infoTimer).textContent=`${i}:${a}:${o}`};v(),setInterval(v,250),r(J.infoTimer).addEventListener("click",(()=>{p=new Date}))})(e)},z=e=>{if(!(e=>e.syncKey&&"string"==typeof e.syncKey)(e))throw new Error("The current instance of Bespoke.js is invalid for Marp bespoke presenter plugin.");Object.defineProperties(e,{openPresenterView:{enumerable:!0,value:G},presenterUrl:{enumerable:!0,get:Q}}),h&&document.addEventListener("keydown",(t=>{"p"!==t.key||t.altKey||t.ctrlKey||t.metaKey||(t.preventDefault(),e.openPresenterView())}))};function G(){const{max:e,floor:t}=Math,n=e(t(.85*window.innerWidth),640),r=e(t(.85*window.innerHeight),360);return window.open(this.presenterUrl,W+this.syncKey,`width=${n},height=${r},menubar=no,toolbar=no`)}function Q(){const e=new URLSearchParams(location.search);return e.set("view","presenter"),e.set("sync",this.syncKey),m(e)}const Z=e=>{const t=g();return t===l&&e.appendChild(document.createElement("span")),{[s]:z,[c]:Y,[l]:D}[t]},ee=e=>{e.on("activate",(t=>{document.querySelectorAll(".bespoke-progress-parent > .bespoke-progress-bar").forEach((n=>{n.style.flexBasis=100*t.index/(e.slides.length-1)+"%"}))}))},te=e=>{const t=Number.parseInt(e,10);return Number.isNaN(t)?null:t},ne=(e={})=>{const t={history:!0,...e};return e=>{let n=!0;const r=e=>{const t=n;try{return n=!0,e()}finally{n=t}},o=(t={fragment:!0})=>{let n=t.fragment?te(p("f")||""):null;((t,n)=>{const{min:r,max:o}=Math,{fragments:a,slides:i}=e,s=o(0,r(t,i.length-1)),c=o(0,r(n||0,a[s].length-1));s===e.slide()&&c===e.fragmentIndex||e.slide(s,{fragment:c})})((()=>{if(location.hash){const[t]=location.hash.slice(1).split(":~:");if(/^\d+$/.test(t))return(te(t)??1)-1;const r=document.getElementById(t)||document.querySelector(`a[name="${CSS.escape(t)}"]`);if(r){const{length:t}=e.slides;for(let o=0;o<t;o+=1)if(e.slides[o].contains(r)){const t=e.fragments?.[o],a=r.closest("[data-marpit-fragment]");if(t&&a){const e=t.indexOf(a);e>=0&&(n=e)}return o}}}return 0})(),n)};e.on("fragment",(({index:e,fragmentIndex:r})=>{n||v({f:0===r||r.toString()},{location:{...location,hash:`#${e+1}`},setter:(...e)=>t.history?history.pushState(...e):history.replaceState(...e)})})),setTimeout((()=>{o(),window.addEventListener("hashchange",(()=>r((()=>{o({fragment:!1}),v({f:void 0})})))),window.addEventListener("popstate",(()=>{n||r((()=>o()))})),n=!1}),0)}},re=(e={})=>{const t=e.key||window.history.state?.marpBespokeSyncKey||Math.random().toString(36).slice(2),n=`bespoke-marp-sync-${t}`;var r;r={marpBespokeSyncKey:t},v({},{setter:(e,...t)=>i({...e,...r},...t)});const o=()=>{const e=y(n);return e?JSON.parse(e):Object.create(null)},a=e=>{const t=o(),r={...t,...e(t)};return b(n,JSON.stringify(r)),r},s=()=>{window.removeEventListener("pageshow",s),a((e=>({reference:(e.reference||0)+1})))};return e=>{s(),Object.defineProperty(e,"syncKey",{value:t,enumerable:!0});let r=!0;setTimeout((()=>{e.on("fragment",(e=>{r&&a((()=>({index:e.index,fragmentIndex:e.fragmentIndex})))}))}),0),window.addEventListener("storage",(t=>{if(t.key===n&&t.oldValue&&t.newValue){const n=JSON.parse(t.oldValue),o=JSON.parse(t.newValue);if(n.index!==o.index||n.fragmentIndex!==o.fragmentIndex)try{r=!1,e.slide(o.index,{fragment:o.fragmentIndex,forSync:!0})}finally{r=!0}}}));const i=()=>{const{reference:e}=o();void 0===e||e<=1?w(n):a((()=>({reference:e-1})))};window.addEventListener("pagehide",(e=>{e.persisted&&window.addEventListener("pageshow",s),i()})),e.on("destroy",i)}},{PI:oe,abs:ae,sqrt:ie,atan2:se}=Math,ce={passive:!0},le=({slope:e=-.7,swipeThreshold:t=30}={})=>n=>{let r;const o=n.parent,a=e=>{const t=o.getBoundingClientRect();return{x:e.pageX-(t.left+t.right)/2,y:e.pageY-(t.top+t.bottom)/2}};o.addEventListener("touchstart",(({touches:e})=>{r=1===e.length?a(e[0]):void 0}),ce),o.addEventListener("touchmove",(e=>{if(r)if(1===e.touches.length){e.preventDefault();const t=a(e.touches[0]),n=t.x-r.x,o=t.y-r.y;r.delta=ie(ae(n)**2+ae(o)**2),r.radian=se(n,o)}else r=void 0})),o.addEventListener("touchend",(o=>{if(r){if(r.delta&&r.delta>=t&&r.radian){const t=(r.radian-e+oe)%(2*oe)-oe;n[t<0?"next":"prev"](),o.stopPropagation()}r=void 0}}),ce)},de=new Map;de.clear(),de.set("none",{backward:{both:void 0,incoming:void 0,outgoing:void 0},forward:{both:void 0,incoming:void 0,outgoing:void 0}});const ue={both:"",outgoing:"outgoing-",incoming:"incoming-"},fe={forward:"",backward:"-backward"},me=e=>`--marp-bespoke-transition-animation-${e}`,ge=e=>`--marp-transition-${e}`,pe=me("name"),ve=me("duration"),he=e=>new Promise((t=>{const n={},r=document.createElement("div"),o=e=>{r.remove(),t(e)};r.addEventListener("animationstart",(()=>o(n))),Object.assign(r.style,{animationName:e,animationDuration:"1s",animationFillMode:"both",animationPlayState:"paused",position:"absolute",pointerEvents:"none"}),document.body.appendChild(r);const a=getComputedStyle(r).getPropertyValue(ge("duration"));a&&(n.defaultDuration=a),((e,t)=>{requestAnimationFrame((()=>{e.style.animationPlayState="running",requestAnimationFrame((()=>t(void 0)))}))})(r,o)})),ye=async e=>de.has(e)?de.get(e):(e=>{const t={},n=[];for(const[r,o]of Object.entries(ue))for(const[a,i]of Object.entries(fe)){const s=`marp-${o}transition${i}-${e}`;n.push(he(s).then((e=>{t[a]=t[a]||{},t[a][r]=e?{...e,name:s}:void 0})))}return Promise.all(n).then((()=>t))})(e).then((t=>(de.set(e,t),t))),be=e=>Object.values(e).flatMap(Object.values).every((e=>!e)),we=(e,{type:t,backward:n})=>{const r=e[n?"backward":"forward"],o=(()=>{const e=r[t],n=e=>({[pe]:e.name});if(e)return n(e);if(r.both){const e=n(r.both);return"incoming"===t&&(e[me("direction")]="reverse"),e}})();return!o&&n?we(e,{type:t,backward:!1}):o||{[pe]:"__bespoke_marp_transition_no_animation__"}},xe=e=>{if(e)try{const t=JSON.parse(e);if((e=>{if("object"!=typeof e)return!1;const t=e;return"string"==typeof t.name&&(void 0===t.duration||"string"==typeof t.duration)})(t))return t}catch{}},ke="_tSId",$e="_tA",Ee="bespoke-marp-transition-warming-up",Le=window.matchMedia("(prefers-reduced-motion: reduce)"),Se="__bespoke_marp_transition_reduced_outgoing__",Pe="__bespoke_marp_transition_reduced_incoming__",_e={forward:{both:void 0,incoming:{name:Pe},outgoing:{name:Se}},backward:{both:void 0,incoming:{name:Pe},outgoing:{name:Se}}},Te=e=>{if(!document.startViewTransition)return;const t=t=>(void 0!==t&&(e._tD=t),e._tD);let n;t(!1),((...e)=>{const t=[...new Set(e).values()];return Promise.all(t.map((e=>ye(e)))).then()})(...Array.from(document.querySelectorAll("section[data-transition], section[data-transition-back]")).flatMap((e=>[e.dataset.transition,e.dataset.transitionBack].flatMap((e=>{const t=xe(e);return[t?.name,t?.builtinFallback?`__builtin__${t.name}`:void 0]})).filter((e=>!!e))))).then((()=>{document.querySelectorAll("style").forEach((e=>{e.innerHTML=e.innerHTML.replace(/--marp-transition-duration:[^;}]*[;}]/g,(e=>e.slice(0,-1)+"!important"+e.slice(-1)))}))}));const r=(n,{back:r,cond:o})=>a=>{const i=t();if(i)return!!a[$e]||!("object"!=typeof i||(i.skipTransition(),!a.forSync));if(!o(a))return!0;const s=e.slides[e.slide()],c=()=>a.back??r,l="data-transition"+(c()?"-back":""),d=s.querySelector(`section[${l}]`);if(!d)return!0;const u=xe(d.getAttribute(l)??void 0);return!u||((async(e,{builtinFallback:t=!0}={})=>{let n=await ye(e);if(be(n)){if(!t)return;return n=await ye(`__builtin__${e}`),be(n)?void 0:n}return n})(u.name,{builtinFallback:u.builtinFallback}).then((e=>{if(!e){t(!0);try{n(a)}finally{t(!1)}return}let r=e;Le.matches&&(console.warn("Use a constant animation to transition because preferring reduced motion by viewer has detected."),r=_e);const o=document.getElementById(ke);o&&o.remove();const i=document.createElement("style");i.id=ke,document.head.appendChild(i),((e,t)=>{const n=[`:root{${ge("direction")}:${t.backward?-1:1};}`,":root:has(.bespoke-marp-inactive){cursor:none;}"],r=t=>{const n=e[t].both?.defaultDuration||e[t].outgoing?.defaultDuration||e[t].incoming?.defaultDuration;return"forward"===t?n:n||r("forward")},o=t.duration||r(t.backward?"backward":"forward");void 0!==o&&n.push(`::view-transition-group(*){${ve}:${o};}`);const a=e=>Object.entries(e).map((([e,t])=>`${e}:${t};`)).join("");return n.push(`::view-transition-old(root){${a(we(e,{...t,type:"outgoing"}))}}`,`::view-transition-new(root){${a(we(e,{...t,type:"incoming"}))}}`),n})(r,{backward:c(),duration:u.duration}).forEach((e=>i.sheet?.insertRule(e)));const s=document.documentElement.classList;s.add(Ee);let l=!1;const d=()=>{l||(n(a),l=!0,s.remove(Ee))},f=()=>{t(!1),i.remove(),s.remove(Ee)};try{t(!0);const e=document.startViewTransition(d);t(e),e.finished.finally(f)}catch(e){console.error(e),d(),f()}})),!1)};e.on("prev",r((t=>e.prev({...t,[$e]:!0})),{back:!0,cond:e=>e.index>0&&!((e.fragment??1)&&n.fragmentIndex>0)})),e.on("next",r((t=>e.next({...t,[$e]:!0})),{cond:t=>t.index+1<e.slides.length&&!(n.fragmentIndex+1<n.fragments.length)})),setTimeout((()=>{e.on("slide",r((t=>e.slide(t.index,{...t,[$e]:!0})),{cond:t=>{const n=e.slide();return t.index!==n&&(t.back=t.index<n,!0)}}))}),0),e.on("fragment",(e=>{n=e}))};let Ie;const Me=()=>(void 0===Ie&&(Ie="wakeLock"in navigator&&navigator.wakeLock),Ie),Oe=async()=>{const e=Me();if(e)try{return await e.request("screen")}catch(e){console.warn(e)}return null},Ae=async()=>{if(!Me())return;let e;const t=()=>{e&&"visible"===document.visibilityState&&Oe()};for(const e of["visibilitychange","fullscreenchange"])document.addEventListener(e,t);return e=await Oe(),e};((e=document.getElementById(":$p"))=>{(()=>{const e=p("view");a.dataset.bespokeView=e===l||e===c?e:""})();const t=(e=>{const t=p(e);return v({[e]:void 0}),t})("sync")||void 0;o.from(e,((...e)=>{const t=d.findIndex((e=>g()===e));return e.map((([e,n])=>e[t]&&n)).filter((e=>e))})([[1,1,0],re({key:t})],[[1,1,1],Z(e)],[[1,1,0],M],[[1,1,1],k],[[1,0,0],T()],[[1,1,1],O],[[1,1,1],ne({history:!1})],[[1,1,0],A()],[[1,1,0],P],[[1,0,0],ee],[[1,1,0],le()],[[1,0,0],C()],[[1,0,0],Te],[[1,1,1],$],[[1,1,0],Ae]))})()}();</script></body></html>